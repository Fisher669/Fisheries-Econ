{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d37a4e22",
   "metadata": {},
   "source": [
    "# POI Extractor\n",
    "\n",
    "This code extracts the points of interest (POIs) from the Amap API based on the user's input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e73b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"fe7011c045b61849c928b90bacf7dd3d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f1beca2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrderedDict\n",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrderedDict\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Fisher Man\\anaconda3\\envs\\py39\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Fisher Man\\anaconda3\\envs\\py39\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List\n",
    "\n",
    "class PrecisionAMapGeocoder:\n",
    "    \"\"\"精密版逆地理编码处理器\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://restapi.amap.com/v3/geocode/regeo\"\n",
    "        self.cache = OrderedDict()\n",
    "        self.max_cache_size = 200\n",
    "        self.road_hierarchy = {0: '主干道', 1: '次干道', 2: '支路'}\n",
    "\n",
    "    def _get_cache_key(self, params: Dict) -> tuple:\n",
    "        \"\"\"生成精确缓存键\"\"\"\n",
    "        return tuple((k, str(v)) for k, v in sorted(params.items()))\n",
    "\n",
    "    def _cache_management(self, key: tuple, data: Dict):\n",
    "        \"\"\"智能缓存管理\"\"\"\n",
    "        if key in self.cache:\n",
    "            self.cache.move_to_end(key)\n",
    "            return\n",
    "        if len(self.cache) >= self.max_cache_size:\n",
    "            self.cache.popitem(last=False)\n",
    "        self.cache[key] = data\n",
    "\n",
    "    def _enhance_poi(self, poi_data: List) -> List[Dict]:\n",
    "        \"\"\"POI数据精密化处理\"\"\"\n",
    "        enhanced = []\n",
    "        for p in poi_data:\n",
    "            loc = p.get('location', '').split(',')\n",
    "            enhanced.append({\n",
    "                'id': p.get('id'),\n",
    "                'name': p.get('name'),\n",
    "                'type': p.get('type'),\n",
    "                'distance': round(float(p.get('distance', 9999)), 3),\n",
    "                'weight': float(p.get('poiweight', 0)),\n",
    "                'address': p.get('address'),\n",
    "                'lng': loc[0] if len(loc)==2 else None,\n",
    "                'lat': loc[1] if len(loc)==2 else None,\n",
    "                'business_area': p.get('businessarea'),\n",
    "                'tel': p.get('tel')\n",
    "            })\n",
    "        return sorted(enhanced, key=lambda x: x['distance'])\n",
    "\n",
    "    def _refine_roads(self, road_data: List) -> List[Dict]:\n",
    "        \"\"\"道路数据精细化处理\"\"\"\n",
    "        refined = []\n",
    "        for r in road_data:\n",
    "            loc = r.get('location', '').split(',')\n",
    "            refined.append({\n",
    "                'id': r.get('id'),\n",
    "                'name': r.get('name'),\n",
    "                'level': int(r.get('level', 0)),\n",
    "                'level_desc': self.road_hierarchy.get(int(r.get('level', 0)), '未知'),\n",
    "                'distance': round(float(r.get('distance', 9999)), 3),\n",
    "                'direction': r.get('direction'),\n",
    "                'lng': loc[0] if len(loc)==2 else None,\n",
    "                'lat': loc[1] if len(loc)==2 else None\n",
    "            })\n",
    "        return sorted(refined, key=lambda x: x['distance'])\n",
    "\n",
    "    def get_location_info(self, lng: float, lat: float, **kwargs) -> Dict:\n",
    "        \"\"\"\n",
    "        精确地理信息查询\n",
    "        :param lng: 经度\n",
    "        :param lat: 纬度\n",
    "        :param kwargs: 扩展参数\n",
    "          - radius: 搜索半径(米)\n",
    "          - poitype: POI类型代码\n",
    "          - roadlevel: 道路等级\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            'key': self.api_key,\n",
    "            'location': f\"{lng},{lat}\",\n",
    "            'radius': kwargs.get('radius', 1000),\n",
    "            'poitype': kwargs.get('poitype'),\n",
    "            'roadlevel': kwargs.get('roadlevel', 0),\n",
    "            'extensions': 'all',\n",
    "            'output': 'json'\n",
    "        }\n",
    "        \n",
    "        cache_key = self._get_cache_key(params)\n",
    "        if cache_key in self.cache:\n",
    "            return self.cache[cache_key]\n",
    "\n",
    "        try:\n",
    "            resp = requests.get(self.base_url, params=params, timeout=10)\n",
    "            resp.raise_for_status()\n",
    "            raw = resp.json()\n",
    "\n",
    "            result = {\n",
    "                'status': int(raw.get('status', 0)),\n",
    "                'info': raw.get('info', ''),\n",
    "                'infocode': raw.get('infocode', ''),\n",
    "                'address': {},\n",
    "                'pois': [],\n",
    "                'roads': [],\n",
    "                'quality': {}\n",
    "            }\n",
    "\n",
    "            if result['status'] == 1:\n",
    "                regeocode = raw.get('regeocode', {})\n",
    "                addr_comp = regeocode.get('addressComponent', {})\n",
    "                \n",
    "                # 精密地址处理\n",
    "                result['address'] = {\n",
    "                    'formatted': regeocode.get('formatted_address', ''),\n",
    "                    'country': addr_comp.get('country'),\n",
    "                    'province': addr_comp.get('province'),\n",
    "                    'city': addr_comp.get('city') or addr_comp.get('citycode', ''),\n",
    "                    'district': addr_comp.get('district'),\n",
    "                    'street': addr_comp.get('streetNumber', {}).get('street'),\n",
    "                    'number': addr_comp.get('streetNumber', {}).get('number'),\n",
    "                    'township': addr_comp.get('township')\n",
    "                }\n",
    "\n",
    "                # POI精密处理\n",
    "                result['pois'] = self._enhance_poi(regeocode.get('pois', []))\n",
    "                \n",
    "                # 道路精密处理\n",
    "                result['roads'] = self._refine_roads(regeocode.get('roads', []))\n",
    "                \n",
    "                # 质量评估\n",
    "                main_roads = [r for r in result['roads'] if r['level'] == 0]\n",
    "                total_poi = len(result['pois'])\n",
    "                search_area = (params['radius']/1000)**2  # 平方公里\n",
    "                \n",
    "                result['quality'] = {\n",
    "                    'poi_density': total_poi/search_area if search_area>0 else 0,\n",
    "                    'main_road_ratio': len(main_roads)/len(result['roads']) if result['roads'] else 0,\n",
    "                    'poi_coverage': min(total_poi/50, 1.0)  # 标准化覆盖率\n",
    "                }\n",
    "\n",
    "            self._cache_management(cache_key, result)\n",
    "            return result\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return {'status': 0, 'info': f\"网络异常: {str(e)}\"}\n",
    "        except json.JSONDecodeError:\n",
    "            return {'status': 0, 'info': '响应数据解析失败'}\n",
    "        except Exception as e:\n",
    "            return {'status': 0, 'info': f\"系统错误: {str(e)}\"}\n",
    "\n",
    "# 验证测试\n",
    "if __name__ == \"__main__\":\n",
    "    # 需替换真实API Key\n",
    "    # AMAP_KEY = \"your_amap_key_here\"\n",
    "    \n",
    "    # 初始化处理器\n",
    "    processor = PrecisionAMapGeocoder(API_KEY)\n",
    "    \n",
    "    # 测试坐标（示例中的坐标）\n",
    "    test_lng = 106.508308\n",
    "    test_lat = 29.53811\n",
    "    \n",
    "    # 执行查询\n",
    "    data = processor.get_location_info(\n",
    "        lng=test_lng,\n",
    "        lat=test_lat,\n",
    "        poitype=\"加油站\",\n",
    "        radius=2000,\n",
    "        roadlevel=0\n",
    "    )\n",
    "    \n",
    "    # 结构验证\n",
    "    assert data.keys() == {'status', 'info', 'infocode', 'address', 'pois', 'roads', 'quality'}, \"结构验证失败\"\n",
    "    assert isinstance(data['pois'], list), \"POI数据异常\"\n",
    "    assert isinstance(data['roads'], list), \"道路数据异常\"\n",
    "    print(\"数据结构验证通过\")\n",
    "    \n",
    "    # 打印示例数据\n",
    "    import pprint\n",
    "    pprint.pprint(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "469c51ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd,time\n",
    "from operator import itemgetter\n",
    "\n",
    "def extract_poi_data(result: dict,poi_type: str) -> dict:\n",
    "    \"\"\"从逆地理编码结果中提取结构化POI信息\"\"\"\n",
    "    output = {}\n",
    "    \n",
    "    # 提取加油站信息（按距离排序）\n",
    "    pois = sorted(\n",
    "        [p for p in result.get('pois', []) if poi_type in p['type']],\n",
    "        key=itemgetter('distance')\n",
    "    )\n",
    "    for idx, poi in enumerate(pois[:5], 1):  # 保留前5个最近加油站\n",
    "        output.update({\n",
    "            # f'Distance{poi_type}_{idx}_id': poi['id'],\n",
    "            # f'Distance{poi_type}_{idx}_name': poi['name'],\n",
    "            f'{poi_type}_{idx}_distance': poi['distance']\n",
    "        })\n",
    "    \n",
    "    # 提取主干道信息（按距离排序）\n",
    "    roads = sorted(result.get('roads', []), key=itemgetter('distance'))\n",
    "    for idx, road in enumerate(roads[:3], 1):  # 保留前3条最近道路\n",
    "        output.update({\n",
    "            # f'Road_{idx}_id': road['id'],\n",
    "            # f'Road_{idx}_name': road['name'],\n",
    "            f'Road_{idx}_distance': road['distance']\n",
    "        })\n",
    "    \n",
    "    # 提取基础地理信息\n",
    "    addr = result['address']\n",
    "    output.update({\n",
    "        'province': addr['province'],\n",
    "        'city': addr['city'][0] if addr['city'] else '',\n",
    "        'district': addr['district'],\n",
    "        'street': addr['street'],\n",
    "        # 'nearest_poi_name': result['nearest_poi']['name'],\n",
    "        # 'nearest_road_distance': result['nearest_road']['distance']\n",
    "        # f'nearest_{poi_type}_distance':result\n",
    "    })\n",
    "    \n",
    "    # 提取其他POI元数据\n",
    "    output['poi_count'] = len(result.get('pois', []))\n",
    "    output['road_count'] = len(result.get('roads', []))\n",
    "    \n",
    "    return output\n",
    "\n",
    "# 使用示例\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # 进度条支持，可选\n",
    "\n",
    "def process_poi_batch(input_df: pd.DataFrame, poi_type: str, batch_size=100):\n",
    "    \"\"\"带批次处理的POI数据增强\"\"\"\n",
    "    # 创建存储目录\n",
    "    output_dir = f\"poi_output/{poi_type}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 初始化缓冲\n",
    "    buffer = []\n",
    "    batch_num = 0\n",
    "    \n",
    "    # 处理进度条\n",
    "    for _, row in tqdm(input_df.iterrows(), total=len(input_df)):\n",
    "        # 调用地理编码接口\n",
    "        time.sleep(0.4)  # 限制请求频率\n",
    "        result = processor.get_location_info(\n",
    "            lng=row['gcj02_lng'],\n",
    "            lat=row['gcj02_lat'],\n",
    "            poitype=poi_type,\n",
    "            radius=3000\n",
    "        )\n",
    "        \n",
    "        # 合并数据\n",
    "        merged = {\n",
    "            **row.to_dict(),\n",
    "            'poi_count': len(result.get('pois', [])),\n",
    "            'road_count': len(result.get('roads', []))\n",
    "        }\n",
    "        \n",
    "        # 添加POI距离\n",
    "        for i in range(5):\n",
    "            key = f'{poi_type}_{i+1}_distance'\n",
    "            merged[key] = result['pois'][i]['distance'] if len(result['pois'])>i else None\n",
    "        \n",
    "        # 添加道路距离\n",
    "        for i in range(3):\n",
    "            key = f'Road_{i+1}_distance'\n",
    "            merged[key] = result['roads'][i]['distance'] if len(result['roads'])>i else None\n",
    "        \n",
    "        buffer.append(merged)\n",
    "        \n",
    "        # 批次写入\n",
    "        if len(buffer) >= batch_size:\n",
    "            save_batch(buffer, batch_num, output_dir, poi_type)\n",
    "            batch_num += 1\n",
    "            buffer = []\n",
    "    \n",
    "    # 写入剩余数据\n",
    "    if buffer:\n",
    "        save_batch(buffer, batch_num, output_dir, poi_type)\n",
    "\n",
    "def save_batch(data: list, batch_num: int, output_dir: str, poi_type: str):\n",
    "    \"\"\"保存批次文件\"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    file_path = f\"{output_dir}/{poi_type}_batch_{batch_num}.csv\"\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec94eb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3602 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [33:38<00:00,  1.78it/s]\n",
      "100%|██████████| 3602/3602 [33:49<00:00,  1.77it/s]\n",
      "100%|██████████| 3602/3602 [33:44<00:00,  1.78it/s]\n",
      "100%|██████████| 3602/3602 [34:35<00:00,  1.74it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('小区地理位置POI预处理版本.csv')\n",
    "amuse_list = [\"银行\", \"餐饮服务\", \"风景名胜\", \"体育休闲服务\"]\n",
    "for amuse_name in amuse_list:\n",
    "    process_poi_batch(df,poi_type=amuse_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9787d452",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "    \"交通\": [\"地铁站\", \"公交站\"],\n",
    "    \"教育\": [\"幼儿园\", \"小学\", \"中学\", \"大学\"],\n",
    "    \"医疗\": [\"医院\", \"药店\"],\n",
    "    \"购物\": [\"商场\", \"超市\", \"市场\"],\n",
    "    \"生活\": [\"银行\", \"ATM\", \"餐厅\", \"咖啡馆\"],\n",
    "    \"娱乐\": [\"公园\", \"电影院\", \"健身房\", \"体育馆\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36914689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [33:49<00:00,  1.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# process_poi_batch(df,r\"便民商店\")\n",
    "process_poi_batch(df,\"政府机关\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84876b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 幼儿园...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [34:02<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 中学...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [33:30<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 小学...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [33:41<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 综合医院...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [33:40<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 诊所...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [34:03<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 超级市场...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [33:42<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 商场...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3602/3602 [33:42<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 便民商店/便利店...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 99/3602 [00:56<33:34,  1.74it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'poi_output\\便民商店\\便利店\\便民商店'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m request \u001b[38;5;129;01min\u001b[39;00m request_list:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mprocess_poi_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 94\u001b[0m, in \u001b[0;36mprocess_poi_batch\u001b[1;34m(input_df, poi_type, batch_size)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# 批次写入\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size:\n\u001b[1;32m---> 94\u001b[0m     \u001b[43msave_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoi_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m     batch_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     96\u001b[0m     buffer \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[27], line 106\u001b[0m, in \u001b[0;36msave_batch\u001b[1;34m(data, batch_num, output_dir, poi_type)\u001b[0m\n\u001b[0;32m    104\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m    105\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpoi_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_batch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 106\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Fisher Man\\anaconda3\\envs\\py39\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Fisher Man\\anaconda3\\envs\\py39\\lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Fisher Man\\anaconda3\\envs\\py39\\lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\Fisher Man\\anaconda3\\envs\\py39\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\Fisher Man\\anaconda3\\envs\\py39\\lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Fisher Man\\anaconda3\\envs\\py39\\lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'poi_output\\便民商店\\便利店\\便民商店'"
     ]
    }
   ],
   "source": [
    "edu_list = [\"幼儿园\", \"中学\", \"小学\"]\n",
    "medic_list = [\"综合医院\", \"诊所\"]\n",
    "shopping_list = [\"超级市场\", \"商场\", \"便民商店/便利店\"]\n",
    "\n",
    "request_list = edu_list + medic_list + shopping_list\n",
    "\n",
    "for request in request_list:\n",
    "    print(f\"Processing {request}...\")\n",
    "    process_poi_batch(df,request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9fff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poi_dict = {\n",
    "#     \"交通\": [\"加油站\", \"充电站\"],\n",
    "#     \"教育\": [\"幼儿园\", \"中学\", \"小学\"],\n",
    "#     \"医疗\": [\"综合医院\", \"诊所\"],\n",
    "#     \"购物\": [\"超级市场\", \"商场\", \"便民商店/便利店\"],\n",
    "#     \"生活娱乐\": [\"银行\", \"餐饮服务\", \"风景名胜\", \"体育休闲服务\"]\n",
    "# }\n",
    "['中学', '体育休闲服务', '便民商店', '商场', '地铁站', '小学', '幼儿园', '政府机关', '综合医院', '诊所', '超级市场', '银行', '风景名胜', '餐饮服务']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b279cb3",
   "metadata": {},
   "source": [
    "# Combine the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f10d4341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['input_name', 'input_address', 'output_address', 'gcj02_lng',\n",
      "       'gcj02_lat', 'poi_count', 'road_count', '综合医院_1_distance',\n",
      "       '综合医院_2_distance', '综合医院_3_distance', '综合医院_4_distance',\n",
      "       '综合医院_5_distance', 'Road_1_distance', 'Road_2_distance',\n",
      "       'Road_3_distance'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "total_df = pd.read_csv(r\"C:\\Users\\Fisher Man\\OneDrive\\Desktop\\Work Sheet\\Py\\Some Projects\\Urban_Econ\\Eassay3\\HousingPriceCrawler\\poi_output\\综合医院\\综合医院_batch_23.csv\")\n",
    "print(total_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9487cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['中学', '体育休闲服务', '便民商店', '商场', '地铁站', '小学', '幼儿园', '政府机关', '综合医院', '诊所', '超级市场', '银行', '风景名胜', '餐饮服务']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd,os\n",
    "file_path = r\"C:\\Users\\Fisher Man\\OneDrive\\Desktop\\Work Sheet\\Py\\Some Projects\\Urban_Econ\\Eassay3\\HousingPriceCrawler\\poi_output\"\n",
    "sample_cols = Index(['input_name', 'input_address', 'output_address', 'gcj02_lng',\n",
    "       'gcj02_lat', 'poi_count', 'road_count', '综合医院_1_distance',\n",
    "       '综合医院_2_distance', '综合医院_3_distance', '综合医院_4_distance',\n",
    "       '综合医院_5_distance', 'Road_1_distance', 'Road_2_distance',\n",
    "       'Road_3_distance'],\n",
    "      dtype='object')\n",
    "common_cols = ['input_name', 'input_address', 'output_address', 'gcj02_lng',\n",
    "       'gcj02_lat', 'poi_count', 'road_count',  'Road_1_distance', 'Road_2_distance','Road_3_distance']\n",
    "# 获取所有POI类型文件夹名称（需确保 poi_output 下只有文件夹）\n",
    "poi_categories = [item for item in os.listdir(file_path) \n",
    "                  if os.path.isdir(os.path.join(file_path, item))]\n",
    "print(poi_categories)\n",
    "# 遍历每个POI类型（如\"中学\"、\"加油站\"）\n",
    "for poi_name in poi_categories:\n",
    "    # 构建POI文件夹路径（例如 .../poi_output/中学）\n",
    "    combined_df = pd.DataFrame()\n",
    "    poi_folder = os.path.join(file_path, poi_name)\n",
    "    \n",
    "    # 遍历该POI文件夹内的所有CSV文件\n",
    "    for file in os.listdir(poi_folder):\n",
    "        if file.endswith(\".csv\") and file.startswith(f\"{poi_name}_batch_\"):\n",
    "            full_path = os.path.join(poi_folder, file)\n",
    "            df = pd.read_csv(full_path)\n",
    "            combined_df = pd.concat([combined_df, df], axis=0, ignore_index=True)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7db3e413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检测到 14 个类别： ['中学', '体育休闲服务', '便民商店', '商场', '地铁站', '小学', '幼儿园', '政府机关', '综合医院', '诊所', '超级市场', '银行', '风景名胜', '餐饮服务']\n",
      "\n",
      "合并成功，文件保存至：output\\final_combined_POI_distances.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file_path = r\"C:\\Users\\Fisher Man\\OneDrive\\Desktop\\Work Sheet\\Py\\Some Projects\\Urban_Econ\\Eassay3\\HousingPriceCrawler\\poi_output\"\n",
    "\n",
    "# 公共字段用于横向合并\n",
    "merge_keys = ['input_name', 'input_address', 'output_address', 'gcj02_lng', 'gcj02_lat','road_count',  'Road_1_distance', 'Road_2_distance','Road_3_distance']\n",
    "\n",
    "# 获取所有 POI 类别的文件夹\n",
    "poi_categories = [item for item in os.listdir(file_path) if os.path.isdir(os.path.join(file_path, item))]\n",
    "print(f\"检测到 {len(poi_categories)} 个类别：\", poi_categories)\n",
    "\n",
    "# 初始化主表（用于存放全部合并结果）\n",
    "final_df = None\n",
    "\n",
    "for poi_name in poi_categories:\n",
    "    poi_folder = os.path.join(file_path, poi_name)\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    # 纵向合并该类别下所有批次文件\n",
    "    for file in os.listdir(poi_folder):\n",
    "        if file.endswith(\".csv\") and file.startswith(f\"{poi_name}_batch_\"):\n",
    "            df = pd.read_csv(os.path.join(poi_folder, file), encoding='utf-8')\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    \n",
    "    # 提取要合并的列\n",
    "    if not set(merge_keys).issubset(set(combined_df.columns)):\n",
    "        print(f\"警告：{poi_name} 缺失合并关键列，跳过\")\n",
    "        continue\n",
    "\n",
    "    # 提取 distance 相关列\n",
    "    distance_cols = [col for col in combined_df.columns if 'distance' in col and col not in merge_keys]\n",
    "    poi_df = combined_df[merge_keys + distance_cols]\n",
    "\n",
    "    # 避免列名冲突：加上 POI 类别前缀\n",
    "    # rename_dict = {col: f\"{poi_name}_{col}\" for col in distance_cols}\n",
    "    \n",
    "    # poi_df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "    # 横向合并（左连接）\n",
    "    if final_df is None:\n",
    "        final_df = poi_df\n",
    "    else:\n",
    "        final_df = pd.merge(final_df, poi_df, on=merge_keys, how='outer')\n",
    "\n",
    "# 输出\n",
    "# output_path = os.path.join(file_path, 'final_combined_POI_distances.csv')\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "output_path = os.path.join(\"output\", 'final_combined_POI_distances.csv')\n",
    "final_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\n合并成功，文件保存至：{output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1f6c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\Fisher Man\\OneDrive\\Desktop\\Work Sheet\\Py\\Some Projects\\Urban_Econ\\Eassay3\\HousingPriceCrawler\\xiaoqu_data\"\n",
    "xiaoqu_df = pd.DataFrame()\n",
    "for file in os.listdir(file_path):\n",
    "    # os.listdir(file_path)\n",
    "    if file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(os.path.join(file_path, file))\n",
    "        xiaoqu_df = pd.concat([xiaoqu_df, df],axis = 0)\n",
    "xiaoqu_out = os.path.join(\"output\",\"xiaoqu_data.csv\")\n",
    "xiaoqu_df.to_csv(xiaoqu_out,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "464ba8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape for xiaoqu_list: (3853, 5)\t shape for poi_df: (3602, 79)\t shape for xiaoqu_df: (3753, 23) \n",
      " cols for xiaoqu_list: Index(['district', 'community', 'link', 'district_CN', 'location'], dtype='object')\t cols for poi_df: Index(['input_name', 'input_address', 'output_address', 'gcj02_lng',\n",
      "       'gcj02_lat', 'road_count', 'Road_1_distance', 'Road_2_distance',\n",
      "       'Road_3_distance', '中学_1_distance', '中学_2_distance', '中学_3_distance',\n",
      "       '中学_4_distance', '中学_5_distance', '体育休闲服务_1_distance',\n",
      "       '体育休闲服务_2_distance', '体育休闲服务_3_distance', '体育休闲服务_4_distance',\n",
      "       '体育休闲服务_5_distance', '便民商店_1_distance', '便民商店_2_distance',\n",
      "       '便民商店_3_distance', '便民商店_4_distance', '便民商店_5_distance',\n",
      "       '商场_1_distance', '商场_2_distance', '商场_3_distance', '商场_4_distance',\n",
      "       '商场_5_distance', '地铁站_1_distance', '地铁站_2_distance', '地铁站_3_distance',\n",
      "       '地铁站_4_distance', '地铁站_5_distance', '小学_1_distance', '小学_2_distance',\n",
      "       '小学_3_distance', '小学_4_distance', '小学_5_distance', '幼儿园_1_distance',\n",
      "       '幼儿园_2_distance', '幼儿园_3_distance', '幼儿园_4_distance', '幼儿园_5_distance',\n",
      "       '政府机关_1_distance', '政府机关_2_distance', '政府机关_3_distance',\n",
      "       '政府机关_4_distance', '政府机关_5_distance', '综合医院_1_distance',\n",
      "       '综合医院_2_distance', '综合医院_3_distance', '综合医院_4_distance',\n",
      "       '综合医院_5_distance', '诊所_1_distance', '诊所_2_distance', '诊所_3_distance',\n",
      "       '诊所_4_distance', '诊所_5_distance', '超级市场_1_distance', '超级市场_2_distance',\n",
      "       '超级市场_3_distance', '超级市场_4_distance', '超级市场_5_distance',\n",
      "       '银行_1_distance', '银行_2_distance', '银行_3_distance', '银行_4_distance',\n",
      "       '银行_5_distance', '风景名胜_1_distance', '风景名胜_2_distance',\n",
      "       '风景名胜_3_distance', '风景名胜_4_distance', '风景名胜_5_distance',\n",
      "       '餐饮服务_1_distance', '餐饮服务_2_distance', '餐饮服务_3_distance',\n",
      "       '餐饮服务_4_distance', '餐饮服务_5_distance'],\n",
      "      dtype='object')\t cols for xiaoqu_df: Index(['小区名称', '参考均价', '在售房源数', '关注人数', '小区ID', '经度', '纬度', '建筑类型', '房屋总数',\n",
      "       '楼栋总数', '绿化率', '容积率', '交易权属', '建成年代', '供暖类型', '用水类型', '用电类型', '物业费',\n",
      "       '附近门店', '物业公司', '开发商', '页面URL', '数据更新时间'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "xiaoqu_list = pd.read_csv(r\"C:\\Users\\Fisher Man\\OneDrive\\Desktop\\Work Sheet\\Py\\Some Projects\\Urban_Econ\\Eassay3\\HousingPriceCrawler\\community_list.csv\")\n",
    "\n",
    "poi_df = pd.read_csv(r\"C:\\Users\\Fisher Man\\OneDrive\\Desktop\\Work Sheet\\Py\\Some Projects\\Urban_Econ\\Eassay3\\HousingPriceCrawler\\output\\final_combined_POI_distances.csv\")\n",
    "\n",
    "xiaoqu_df = pd.read_csv(r\"C:\\Users\\Fisher Man\\OneDrive\\Desktop\\Work Sheet\\Py\\Some Projects\\Urban_Econ\\Eassay3\\HousingPriceCrawler\\output\\xiaoqu_data.csv\")\n",
    "\n",
    "print(f\" shape for xiaoqu_list: {xiaoqu_list.shape}\\t shape for poi_df: {poi_df.shape}\\t shape for xiaoqu_df: {xiaoqu_df.shape} \\n cols for xiaoqu_list: {xiaoqu_list.columns}\\t cols for poi_df: {poi_df.columns}\\t cols for xiaoqu_df: {xiaoqu_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8557eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape of merged df :(3853, 84) shape of final merged dataframe: (3859, 107) \n",
      " \n"
     ]
    }
   ],
   "source": [
    "merged_1 = xiaoqu_list.merge(poi_df, left_on='location', right_on='input_name', how='left')\n",
    "final_merged = merged_1.merge(xiaoqu_df, left_on='community', right_on='小区名称', how='left')\n",
    "final_merged_path = os.path.join(\"output\",\"final_merged.csv\")   \n",
    "# xiaoqu_out = os.path.join(\"output\",\"xiaoqu_data.csv\")\n",
    "final_merged.to_csv(final_merged_path, index=False,encoding='utf-8-sig')\n",
    "print(f\" shape of merged df :{merged_1.shape} shape of final merged dataframe: {final_merged.shape} \\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cd066d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   district  community                                             link  \\\n",
      "0  jinjiang      皇经楼一期     https://cd.lianjia.com/xiaoqu/3011052976570/   \n",
      "1  jinjiang       上东家园     https://cd.lianjia.com/xiaoqu/3011053437765/   \n",
      "2  jinjiang  皇经楼新居二期B区     https://cd.lianjia.com/xiaoqu/1611061607677/   \n",
      "3  jinjiang  绿地中心468星朗  https://cd.lianjia.com/xiaoqu/1620024208685305/   \n",
      "4  jinjiang   皇经楼二街68号     https://cd.lianjia.com/xiaoqu/3011052642927/   \n",
      "\n",
      "  district_CN      location  \n",
      "0         锦江区      锦江区皇经楼一期  \n",
      "1         锦江区       锦江区上东家园  \n",
      "2         锦江区  锦江区皇经楼新居二期B区  \n",
      "3         锦江区  锦江区绿地中心468星朗  \n",
      "4         锦江区   锦江区皇经楼二街68号  \n",
      "        小区名称      参考均价  在售房源数  关注人数              小区ID          经度         纬度  \\\n",
      "0      皇经楼一期   9819元/㎡    NaN    92     3011052976570  104.114738  30.599153   \n",
      "1       上东家园  11030元/㎡    NaN   451     3011053437765  104.114559  30.605445   \n",
      "2  皇经楼新居二期B区  11347元/㎡    NaN   158     1611061607677  104.114660  30.596701   \n",
      "3  绿地中心468星朗  11365元/㎡    NaN   140  1620024208685305  104.162103  30.608843   \n",
      "4   皇经楼二街68号  11540元/㎡    NaN    39     3011052642927  104.115732  30.598106   \n",
      "\n",
      "      建筑类型   房屋总数 楼栋总数  ...        建成年代  供暖类型   用水类型   用电类型             物业费  \\\n",
      "0       板楼   313户  12栋  ...       2008年  暂无信息   暂无信息     民电     0.5至1元/平米/月   \n",
      "1       板楼   595户   8栋  ...       2006年   自采暖  商水/民水  商电/民电   0.5至0.6元/平米/月   \n",
      "2       板楼  2370户   6栋  ...  2012-2014年   无供暖     民水     民电    0.25至1元/平米/月   \n",
      "3  塔板结合/平房  1467户   2栋  ...  2019-2021年  暂无信息     商水  商电/民电  3.9至3.98元/平米/月   \n",
      "4  板楼/塔板结合   430户   3栋  ...  2012-2016年   无供暖     民水     民电  1.1至1.36元/平米/月   \n",
      "\n",
      "                                                附近门店            物业公司  \\\n",
      "0                                           /楠丰路200号            首东置业   \n",
      "1                                            /经天里24号          业主自筹物业   \n",
      "2                                           /楠丰路200号            首东置业   \n",
      "3  /成都市锦江区成龙路街办粮丰村一 二 四 五 六 七 十组，龙泉驿区东洪村十组 洪柳村一组 ...  成都嘉诚新悦物业管理有限公司   \n",
      "4                                           /楠丰路200号   成都恒远房地产有限责任公司   \n",
      "\n",
      "                 开发商                                            页面URL 数据更新时间  \n",
      "0               暂无信息     https://cd.lianjia.com/xiaoqu/3011052976570/     5月  \n",
      "1       成都千和物业发展有限公司     https://cd.lianjia.com/xiaoqu/3011053437765/     5月  \n",
      "2               暂无信息     https://cd.lianjia.com/xiaoqu/1611061607677/     5月  \n",
      "3  绿地集团成都蜀峰房地产开发有限公司  https://cd.lianjia.com/xiaoqu/1620024208685305/     5月  \n",
      "4               无开发商     https://cd.lianjia.com/xiaoqu/3011052642927/     5月  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "   input_name input_address     output_address   gcj02_lng  gcj02_lat  \\\n",
      "0     双流区万景蓉元       双流区万景蓉元     四川省成都市双流区万景·蓉元  104.012297  30.562537   \n",
      "1  双流区万科第五城三期    双流区万科第五城三期  四川省成都市双流区万科·第五城三期  103.930599  30.627729   \n",
      "2  双流区万科第五城二期    双流区万科第五城二期  四川省成都市双流区万科·第五城二期  103.926837  30.629855   \n",
      "3  双流区万科第五城四期    双流区万科第五城四期  四川省成都市双流区万科·第五城四期  103.926387  30.627686   \n",
      "4     双流区万象公寓       双流区万象公寓          四川省成都市双流区  103.923420  30.574884   \n",
      "\n",
      "   road_count  Road_1_distance  Road_2_distance  Road_3_distance  \\\n",
      "0           3           86.692          133.559          332.249   \n",
      "1           3          103.429          151.187          158.271   \n",
      "2           3          131.715          138.602          155.587   \n",
      "3           3          100.129          169.427          236.814   \n",
      "4           3           40.067           95.488          103.488   \n",
      "\n",
      "   中学_1_distance  ...  风景名胜_1_distance  风景名胜_2_distance  风景名胜_3_distance  \\\n",
      "0       1101.470  ...         1427.260          1780.74          2416.03   \n",
      "1        444.588  ...         1941.620          2168.91          2438.43   \n",
      "2        261.225  ...         2083.580          2365.75          2868.81   \n",
      "3        324.070  ...         2244.730          2318.41          2789.42   \n",
      "4        474.496  ...          309.494           651.86          2259.44   \n",
      "\n",
      "   风景名胜_4_distance  风景名胜_5_distance  餐饮服务_1_distance  餐饮服务_2_distance  \\\n",
      "0          2442.54          2862.42              0.0          108.942   \n",
      "1          2542.43          2965.00              0.0           87.604   \n",
      "2          2898.64              NaN              0.0          100.088   \n",
      "3          2945.05              NaN              0.0          111.869   \n",
      "4              NaN              NaN              0.0            0.000   \n",
      "\n",
      "   餐饮服务_3_distance  餐饮服务_4_distance  餐饮服务_5_distance  \n",
      "0          137.146          227.565          264.616  \n",
      "1          127.725          131.549          133.026  \n",
      "2          118.670          124.123          127.291  \n",
      "3          130.414          136.995          144.356  \n",
      "4           50.354           50.354           55.129  \n",
      "\n",
      "[5 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "print(xiaoqu_list.head())\n",
    "print(xiaoqu_df.head())\n",
    "print(poi_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
