{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "'''Load data'''\n",
    "temp_Qd = np.load('Data_processed/Qd_100.npy',allow_pickle=True).item()\n",
    "temp_life = np.load('Data_processed/cycle_life.npy',allow_pickle=True).item()\n",
    "all_capacity = np.load('Data_processed/all_capacity.npy',allow_pickle=True).item()\n",
    "temp_Qd_all = []\n",
    "temp_life_all = []\n",
    "all_capacity_all = []\n",
    "\n",
    "for key in temp_Qd.keys():\n",
    "    temp_life_all.append(temp_life[key])\n",
    "    all_capacity_all.append(all_capacity[key])\n",
    "    temp_Qd_list = []\n",
    "    for item in temp_Qd[key]:\n",
    "        temp_Qd_list.append(item)\n",
    "    temp_Qd_arr = np.asarray(temp_Qd_list)\n",
    "    temp_Qd_all.append(temp_Qd_arr)\n",
    "all_Qd_arr = np.asarray(temp_Qd_all)\n",
    "cycle_life_arr = np.asarray(temp_life_all)    \n",
    "\n",
    "\n",
    "'''Divide the dataset as the original paper stated'''\n",
    "test_ind = np.hstack((np.arange(0,(41+43),2),83))\n",
    "train_ind = np.arange(1,(41+43-1),2)\n",
    "secondary_test_ind = np.arange(124-40,124)\n",
    "\n",
    "all_keys = list(temp_Qd.keys())\n",
    "train_keys = [all_keys[inx] for inx in train_ind]\n",
    "test_keys = [all_keys[inx] for inx in test_ind]\n",
    "secondary_test_keys = [all_keys[inx] for inx in secondary_test_ind]\n",
    "\n",
    "cycle_life_arr=np.asarray(cycle_life_arr).reshape(-1,1)\n",
    "max_label=np.max(cycle_life_arr)\n",
    "cycle_life_arr=cycle_life_arr/max_label\n",
    "\n",
    "\n",
    "train_Qds = np.asarray(all_Qd_arr)[train_ind]\n",
    "train_cycle_lifes = np.asarray(cycle_life_arr)[train_ind]\n",
    "\n",
    "test_Qd_a = np.asarray(all_Qd_arr)[test_ind]\n",
    "test_cycle_life_a = np.asarray(cycle_life_arr)[test_ind]\n",
    "\n",
    "test_Qd_b = np.asarray(all_Qd_arr)[secondary_test_ind]\n",
    "test_cycle_life_b = np.asarray(cycle_life_arr)[secondary_test_ind]\n",
    "\n",
    "train_Qd, _, train_cycle_life, _ = train_test_split(train_Qds, train_cycle_lifes, test_size=0.36, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "\n",
    "def to_3d(x):\n",
    "    return rearrange(x, 'b c h w -> b (h w) c')\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class SEbox(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, stride, padding):\n",
    "        super(SEbox, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channel)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se = SELayer(out_channel)\n",
    "        self.cbam = CBAM(out_channel)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = x + self.se(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.cbam(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channel, reduction=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(output_size=1)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_features=in_channel, out_features=in_channel // reduction, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=in_channel // reduction, out_features=in_channel, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.conv = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=kernel_size, stride=1, padding=kernel_size // 2, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        maxout = self.max_pool(x)\n",
    "        avgout = self.avg_pool(x)\n",
    "        channel_out = self.sigmoid(self.mlp(maxout.view(maxout.size(0), -1)) + self.mlp(avgout.view(avgout.size(0), -1)))\n",
    "        channel_out = channel_out.view(x.size(0), x.size(1), 1, 1) * x\n",
    "        max_out = torch.max(channel_out, dim=1, keepdim=True)[0]\n",
    "        mean_out = torch.mean(channel_out, dim=1, keepdim=True)\n",
    "        out = self.sigmoid(self.conv(torch.cat((max_out, mean_out), dim=1))) * channel_out\n",
    "        return out\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=(50, 50), stride=(5, 40)),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv2d(8, 16, kernel_size=(2, 3)),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv2d(16, 32, kernel_size=(2, 3)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2),\n",
    "        )\n",
    "        self.se = SELayer(32)\n",
    "        self.ebam1 = CBAM(32)\n",
    "        \n",
    "        self.sebox1 = SEbox(32, 64, kernel_size=2, stride=1, padding=0)\n",
    "        self.sebox2 = SEbox(64, 128, kernel_size=1, stride=1, padding=0)\n",
    "        self.sebox3 = SEbox(128, 256, kernel_size=1, stride=1, padding=0)\n",
    "        self.sebox4 = SEbox(256, 256, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.lstm = nn.LSTM(256, 256, num_layers=2, bidirectional=True, batch_first=True)\n",
    "        self.fc1 = nn.Linear(512, 1)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        try:\n",
    "            x = self.layers1(x)\n",
    "            # print(f\"层1输出形状: {x.shape}\")\n",
    "            \n",
    "            x = CBAM(32)(x)\n",
    "            # print(f\"CBAM后输出形状: {x.shape}\")\n",
    "            \n",
    "            x = self.sebox1(x)\n",
    "            # print(f\"sebox1输出形状: {x.shape}\")\n",
    "            \n",
    "            x = self.sebox2(x)\n",
    "            # print(f\"sebox2输出形状: {x.shape}\")\n",
    "            \n",
    "            x = self.sebox3(x)\n",
    "            # print(f\"sebox3输出形状: {x.shape}\")\n",
    "            \n",
    "            x = self.sebox4(x)\n",
    "            # print(f\"sebox4输出形状: {x.shape}\")\n",
    "            \n",
    "            x = to_3d(x)\n",
    "            # print(f\"to_3d后输出形状: {x.shape}\")\n",
    "            \n",
    "            x, _ = self.lstm(x)\n",
    "            # print(f\"LSTM后输出形状: {x.shape}\")\n",
    "            return torch.sigmoid(self.fc1(x[:, -1, :]))\n",
    "        except RuntimeError as e:\n",
    "            print(f\"运行时错误：{e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"发生意外错误：{e}\")\n",
    "            raise  # 重新抛出异常，以便进一步处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layers1): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(50, 50), stride=(5, 40))\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Conv2d(8, 16, kernel_size=(2, 3), stride=(1, 1))\n",
      "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (8): Dropout(p=0.2, inplace=False)\n",
      "    (9): Conv2d(16, 32, kernel_size=(2, 3), stride=(1, 1))\n",
      "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (12): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (se): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=2, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=2, out_features=32, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (ebam1): CBAM(\n",
      "    (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=2, bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=2, out_features=32, bias=False)\n",
      "    )\n",
      "    (sigmoid): Sigmoid()\n",
      "    (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "  )\n",
      "  (sebox1): SEbox(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (se): SELayer(\n",
      "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "        (3): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (cbam): CBAM(\n",
      "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      )\n",
      "      (sigmoid): Sigmoid()\n",
      "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (sebox2): SEbox(\n",
      "    (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (se): SELayer(\n",
      "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=8, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Linear(in_features=8, out_features=128, bias=False)\n",
      "        (3): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (cbam): CBAM(\n",
      "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=8, bias=False)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=8, out_features=128, bias=False)\n",
      "      )\n",
      "      (sigmoid): Sigmoid()\n",
      "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (sebox3): SEbox(\n",
      "    (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (se): SELayer(\n",
      "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "        (3): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (cbam): CBAM(\n",
      "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "      )\n",
      "      (sigmoid): Sigmoid()\n",
      "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (sebox4): SEbox(\n",
      "    (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (se): SELayer(\n",
      "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "        (3): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (cbam): CBAM(\n",
      "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "      )\n",
      "      (sigmoid): Sigmoid()\n",
      "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (lstm): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (fc1): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "net = Net()     # define the network\n",
    "print(net)      # net architecture\n",
    "# summary(net,(1,100,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step = 0 train_loss: 0.06003601 val_loss: 0.055417836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fisher Man\\AppData\\Local\\Temp\\ipykernel_5240\\2213074592.py:95: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  history = pd.concat([history, new_entry], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step = 1 train_loss: 0.058585353 val_loss: 0.0546887\n",
      "Step = 2 train_loss: 0.057520106 val_loss: 0.053956553\n",
      "Step = 3 train_loss: 0.056438446 val_loss: 0.05321342\n",
      "Step = 4 train_loss: 0.055308305 val_loss: 0.052445494\n",
      "Step = 5 train_loss: 0.054043233 val_loss: 0.05166967\n",
      "Step = 6 train_loss: 0.053195577 val_loss: 0.05087987\n",
      "Step = 7 train_loss: 0.05226296 val_loss: 0.050066676\n",
      "Step = 8 train_loss: 0.050848916 val_loss: 0.04922878\n",
      "Step = 9 train_loss: 0.049757954 val_loss: 0.048365097\n",
      "Step = 10 train_loss: 0.047990777 val_loss: 0.047472335\n",
      "Step = 11 train_loss: 0.047000475 val_loss: 0.046546545\n",
      "Step = 12 train_loss: 0.04702218 val_loss: 0.045587055\n",
      "Step = 13 train_loss: 0.046740696 val_loss: 0.044592056\n",
      "Step = 14 train_loss: 0.0450032 val_loss: 0.043531314\n",
      "Step = 15 train_loss: 0.04160075 val_loss: 0.04242216\n",
      "Step = 16 train_loss: 0.042685196 val_loss: 0.0412877\n",
      "Step = 17 train_loss: 0.041674178 val_loss: 0.040127147\n",
      "Step = 18 train_loss: 0.04006578 val_loss: 0.038843088\n",
      "Step = 19 train_loss: 0.037815098 val_loss: 0.03748188\n",
      "Step = 20 train_loss: 0.034580003 val_loss: 0.03608914\n",
      "Step = 21 train_loss: 0.035138853 val_loss: 0.034700885\n",
      "Step = 22 train_loss: 0.033042558 val_loss: 0.033234257\n",
      "Step = 23 train_loss: 0.03208257 val_loss: 0.03173615\n",
      "Step = 24 train_loss: 0.033296563 val_loss: 0.030291535\n",
      "Step = 25 train_loss: 0.030293025 val_loss: 0.028753312\n",
      "Step = 26 train_loss: 0.03086011 val_loss: 0.02726528\n",
      "Step = 27 train_loss: 0.030374505 val_loss: 0.025912546\n",
      "Step = 28 train_loss: 0.033377953 val_loss: 0.024646379\n",
      "Step = 29 train_loss: 0.028849013 val_loss: 0.02375451\n",
      "Step = 30 train_loss: 0.028756274 val_loss: 0.023068005\n",
      "Step = 31 train_loss: 0.031180454 val_loss: 0.022505349\n",
      "Step = 32 train_loss: 0.030804524 val_loss: 0.022226477\n",
      "Step = 33 train_loss: 0.03235611 val_loss: 0.022067955\n",
      "Step = 34 train_loss: 0.029235592 val_loss: 0.022035342\n",
      "Step = 35 train_loss: 0.03123467 val_loss: 0.021980839\n",
      "Step = 36 train_loss: 0.03042874 val_loss: 0.02193917\n",
      "Step = 37 train_loss: 0.030270543 val_loss: 0.022063173\n",
      "Step = 38 train_loss: 0.027813712 val_loss: 0.022117786\n",
      "Step = 39 train_loss: 0.02889402 val_loss: 0.022151627\n",
      "Step = 40 train_loss: 0.02812579 val_loss: 0.022178931\n",
      "Step = 41 train_loss: 0.029624803 val_loss: 0.022280779\n",
      "Step = 42 train_loss: 0.029122233 val_loss: 0.022400124\n",
      "Step = 43 train_loss: 0.028340649 val_loss: 0.022515943\n",
      "Step = 44 train_loss: 0.029134365 val_loss: 0.022566658\n",
      "Step = 45 train_loss: 0.029189916 val_loss: 0.022489823\n",
      "Step = 46 train_loss: 0.028238084 val_loss: 0.022386793\n",
      "Step = 47 train_loss: 0.028792448 val_loss: 0.022328274\n",
      "Step = 48 train_loss: 0.028898627 val_loss: 0.022315314\n",
      "Step = 49 train_loss: 0.02852789 val_loss: 0.022289662\n",
      "Step = 50 train_loss: 0.029705765 val_loss: 0.022227973\n",
      "Step = 51 train_loss: 0.02895425 val_loss: 0.022105921\n",
      "Step = 52 train_loss: 0.029414233 val_loss: 0.022069644\n",
      "Step = 53 train_loss: 0.026469946 val_loss: 0.022058165\n",
      "Step = 54 train_loss: 0.029712144 val_loss: 0.022033473\n",
      "Step = 55 train_loss: 0.030816963 val_loss: 0.022020955\n",
      "Step = 56 train_loss: 0.027801834 val_loss: 0.022186866\n",
      "Step = 57 train_loss: 0.028210592 val_loss: 0.021982536\n",
      "Step = 58 train_loss: 0.028663801 val_loss: 0.021893311\n",
      "Step = 59 train_loss: 0.028970242 val_loss: 0.021843936\n",
      "Step = 60 train_loss: 0.030797562 val_loss: 0.021698164\n",
      "Step = 61 train_loss: 0.030542947 val_loss: 0.021618098\n",
      "Step = 62 train_loss: 0.029323515 val_loss: 0.021747747\n",
      "Step = 63 train_loss: 0.031049151 val_loss: 0.021704547\n",
      "Step = 64 train_loss: 0.02819878 val_loss: 0.021704912\n",
      "Step = 65 train_loss: 0.030070908 val_loss: 0.021611292\n",
      "Step = 66 train_loss: 0.028854562 val_loss: 0.021659112\n",
      "Step = 67 train_loss: 0.029535843 val_loss: 0.021646716\n",
      "Step = 68 train_loss: 0.02836135 val_loss: 0.021661066\n",
      "Step = 69 train_loss: 0.027771529 val_loss: 0.021588374\n",
      "Step = 70 train_loss: 0.028221536 val_loss: 0.021890678\n",
      "Step = 71 train_loss: 0.029086072 val_loss: 0.021643745\n",
      "Step = 72 train_loss: 0.029046388 val_loss: 0.021769235\n",
      "Step = 73 train_loss: 0.027528953 val_loss: 0.021698544\n",
      "Step = 74 train_loss: 0.029239647 val_loss: 0.021634176\n",
      "Step = 75 train_loss: 0.027989585 val_loss: 0.021626702\n",
      "Step = 76 train_loss: 0.02882332 val_loss: 0.021554468\n",
      "Step = 77 train_loss: 0.027848221 val_loss: 0.021555167\n",
      "Step = 78 train_loss: 0.028127007 val_loss: 0.021575414\n",
      "Step = 79 train_loss: 0.029608877 val_loss: 0.021498961\n",
      "Step = 80 train_loss: 0.028546652 val_loss: 0.02155564\n",
      "Step = 81 train_loss: 0.028944226 val_loss: 0.021705816\n",
      "Step = 82 train_loss: 0.029269781 val_loss: 0.021443468\n",
      "Step = 83 train_loss: 0.02941268 val_loss: 0.021494118\n",
      "Step = 84 train_loss: 0.029370977 val_loss: 0.021395536\n",
      "Step = 85 train_loss: 0.028891811 val_loss: 0.021542221\n",
      "Step = 86 train_loss: 0.02917443 val_loss: 0.021495823\n",
      "Step = 87 train_loss: 0.028605375 val_loss: 0.021501675\n",
      "Step = 88 train_loss: 0.027542047 val_loss: 0.021484466\n",
      "Step = 89 train_loss: 0.02907614 val_loss: 0.021457508\n",
      "Step = 90 train_loss: 0.028737824 val_loss: 0.021415312\n",
      "Step = 91 train_loss: 0.027720349 val_loss: 0.021673148\n",
      "Step = 92 train_loss: 0.029180747 val_loss: 0.021381125\n",
      "Step = 93 train_loss: 0.02969457 val_loss: 0.021316325\n",
      "Step = 94 train_loss: 0.029052831 val_loss: 0.021404568\n",
      "Step = 95 train_loss: 0.028406011 val_loss: 0.021534193\n",
      "Step = 96 train_loss: 0.029271793 val_loss: 0.021565227\n",
      "Step = 97 train_loss: 0.027933696 val_loss: 0.021528047\n",
      "Step = 98 train_loss: 0.029129453 val_loss: 0.021472966\n",
      "Step = 99 train_loss: 0.029813994 val_loss: 0.021438425\n",
      "Step = 100 train_loss: 0.029900175 val_loss: 0.021403283\n",
      "Step = 101 train_loss: 0.028896915 val_loss: 0.021349434\n",
      "Step = 102 train_loss: 0.029602416 val_loss: 0.021572884\n",
      "Step = 103 train_loss: 0.030107154 val_loss: 0.02174593\n",
      "Step = 104 train_loss: 0.029152505 val_loss: 0.021625249\n",
      "Step = 105 train_loss: 0.02769653 val_loss: 0.021493757\n",
      "Step = 106 train_loss: 0.02959647 val_loss: 0.021549046\n",
      "Step = 107 train_loss: 0.029104738 val_loss: 0.02165667\n",
      "Step = 108 train_loss: 0.029636813 val_loss: 0.021734651\n",
      "Step = 109 train_loss: 0.028306117 val_loss: 0.021569302\n",
      "Step = 110 train_loss: 0.029041687 val_loss: 0.021575846\n",
      "Step = 111 train_loss: 0.027927201 val_loss: 0.021552036\n",
      "Step = 112 train_loss: 0.031810008 val_loss: 0.021460017\n",
      "Step = 113 train_loss: 0.029670138 val_loss: 0.021503432\n",
      "Step = 114 train_loss: 0.030364241 val_loss: 0.021556573\n",
      "Step = 115 train_loss: 0.031501982 val_loss: 0.021547798\n",
      "Step = 116 train_loss: 0.028606486 val_loss: 0.021566393\n",
      "Step = 117 train_loss: 0.028573375 val_loss: 0.02150329\n",
      "Step = 118 train_loss: 0.029773895 val_loss: 0.02162681\n",
      "Step = 119 train_loss: 0.031964704 val_loss: 0.021455519\n",
      "Step = 120 train_loss: 0.030717738 val_loss: 0.0214395\n",
      "Step = 121 train_loss: 0.030956613 val_loss: 0.021499254\n",
      "Step = 122 train_loss: 0.029871421 val_loss: 0.021464271\n",
      "Step = 123 train_loss: 0.029969739 val_loss: 0.021341715\n",
      "Step = 124 train_loss: 0.028672684 val_loss: 0.021604177\n",
      "Step = 125 train_loss: 0.029164046 val_loss: 0.021571098\n",
      "Step = 126 train_loss: 0.029002842 val_loss: 0.021432357\n",
      "Step = 127 train_loss: 0.02910577 val_loss: 0.021409908\n",
      "Step = 128 train_loss: 0.03255926 val_loss: 0.021435045\n",
      "Step = 129 train_loss: 0.030041626 val_loss: 0.02139177\n",
      "Step = 130 train_loss: 0.029985856 val_loss: 0.021418568\n",
      "Step = 131 train_loss: 0.030568987 val_loss: 0.02143021\n",
      "Step = 132 train_loss: 0.030211342 val_loss: 0.021409145\n",
      "Step = 133 train_loss: 0.029250741 val_loss: 0.021464534\n",
      "Step = 134 train_loss: 0.03271017 val_loss: 0.021337016\n",
      "Step = 135 train_loss: 0.030184817 val_loss: 0.02144786\n",
      "Step = 136 train_loss: 0.029165037 val_loss: 0.021457555\n",
      "Step = 137 train_loss: 0.02941929 val_loss: 0.021555347\n",
      "Step = 138 train_loss: 0.028788019 val_loss: 0.021565149\n",
      "Step = 139 train_loss: 0.029251115 val_loss: 0.021564174\n",
      "Step = 140 train_loss: 0.030614423 val_loss: 0.021467991\n",
      "Step = 141 train_loss: 0.02921431 val_loss: 0.021570072\n",
      "Step = 142 train_loss: 0.029200304 val_loss: 0.021565787\n",
      "Step = 143 train_loss: 0.028758118 val_loss: 0.021471614\n",
      "Step = 144 train_loss: 0.028271679 val_loss: 0.021484824\n",
      "Step = 145 train_loss: 0.028997382 val_loss: 0.021408217\n",
      "Step = 146 train_loss: 0.029072942 val_loss: 0.021450968\n",
      "Step = 147 train_loss: 0.029582473 val_loss: 0.021413984\n",
      "Step = 148 train_loss: 0.029866727 val_loss: 0.021241482\n",
      "Step = 149 train_loss: 0.029599776 val_loss: 0.021234065\n",
      "Step = 150 train_loss: 0.028702743 val_loss: 0.02126115\n",
      "Step = 151 train_loss: 0.028654475 val_loss: 0.021201212\n",
      "Step = 152 train_loss: 0.030949427 val_loss: 0.021224704\n",
      "Step = 153 train_loss: 0.030066464 val_loss: 0.02118683\n",
      "Step = 154 train_loss: 0.029850177 val_loss: 0.021150963\n",
      "Step = 155 train_loss: 0.028586255 val_loss: 0.021077994\n",
      "Step = 156 train_loss: 0.030142754 val_loss: 0.02116941\n",
      "Step = 157 train_loss: 0.030344745 val_loss: 0.021166839\n",
      "Step = 158 train_loss: 0.029714938 val_loss: 0.021267975\n",
      "Step = 159 train_loss: 0.031230174 val_loss: 0.021395972\n",
      "Step = 160 train_loss: 0.027869882 val_loss: 0.021412198\n",
      "Step = 161 train_loss: 0.028982801 val_loss: 0.021444354\n",
      "Step = 162 train_loss: 0.028542105 val_loss: 0.021445353\n",
      "Step = 163 train_loss: 0.029314177 val_loss: 0.02148572\n",
      "Step = 164 train_loss: 0.028390449 val_loss: 0.021393862\n",
      "Step = 165 train_loss: 0.02871543 val_loss: 0.021415481\n",
      "Step = 166 train_loss: 0.029130746 val_loss: 0.021349477\n",
      "Step = 167 train_loss: 0.028314458 val_loss: 0.021158751\n",
      "Step = 168 train_loss: 0.02937727 val_loss: 0.021069238\n",
      "Step = 169 train_loss: 0.03055005 val_loss: 0.021245362\n",
      "Step = 170 train_loss: 0.028539497 val_loss: 0.020794448\n",
      "Step = 171 train_loss: 0.029188188 val_loss: 0.021024672\n",
      "Step = 172 train_loss: 0.030666577 val_loss: 0.020859828\n",
      "Step = 173 train_loss: 0.02912562 val_loss: 0.021100232\n",
      "Step = 174 train_loss: 0.029448204 val_loss: 0.02090317\n",
      "Step = 175 train_loss: 0.03022648 val_loss: 0.021318551\n",
      "Step = 176 train_loss: 0.029999994 val_loss: 0.020796066\n",
      "Step = 177 train_loss: 0.028884627 val_loss: 0.021609753\n",
      "Step = 178 train_loss: 0.02977599 val_loss: 0.021855341\n",
      "Step = 179 train_loss: 0.029380918 val_loss: 0.022441085\n",
      "Step = 180 train_loss: 0.029886939 val_loss: 0.022254054\n",
      "Step = 181 train_loss: 0.027138306 val_loss: 0.022416038\n",
      "Step = 182 train_loss: 0.029643396 val_loss: 0.02254277\n",
      "Step = 183 train_loss: 0.029271571 val_loss: 0.022265498\n",
      "Step = 184 train_loss: 0.029254148 val_loss: 0.022116352\n",
      "Step = 185 train_loss: 0.029773401 val_loss: 0.022025937\n",
      "Step = 186 train_loss: 0.030322226 val_loss: 0.02186032\n",
      "Step = 187 train_loss: 0.029934926 val_loss: 0.021651667\n",
      "Step = 188 train_loss: 0.030243639 val_loss: 0.021565538\n",
      "Step = 189 train_loss: 0.02840795 val_loss: 0.021682601\n",
      "Step = 190 train_loss: 0.028903732 val_loss: 0.021112468\n",
      "Step = 191 train_loss: 0.03019572 val_loss: 0.021114448\n",
      "Step = 192 train_loss: 0.028561048 val_loss: 0.021086553\n",
      "Step = 193 train_loss: 0.029777754 val_loss: 0.021015218\n",
      "Step = 194 train_loss: 0.030084651 val_loss: 0.020936336\n",
      "Step = 195 train_loss: 0.030003043 val_loss: 0.020941753\n",
      "Step = 196 train_loss: 0.029006986 val_loss: 0.020872964\n",
      "Step = 197 train_loss: 0.029792083 val_loss: 0.020866198\n",
      "Step = 198 train_loss: 0.028053146 val_loss: 0.020919846\n",
      "Step = 199 train_loss: 0.0294995 val_loss: 0.020871675\n",
      "Step = 200 train_loss: 0.028585874 val_loss: 0.02093846\n",
      "Step = 201 train_loss: 0.028391166 val_loss: 0.020974992\n",
      "Step = 202 train_loss: 0.029163787 val_loss: 0.021029277\n",
      "Step = 203 train_loss: 0.028615467 val_loss: 0.021008063\n",
      "Step = 204 train_loss: 0.029500095 val_loss: 0.021029217\n",
      "Step = 205 train_loss: 0.02948302 val_loss: 0.02105529\n",
      "Step = 206 train_loss: 0.029422542 val_loss: 0.021137409\n",
      "Step = 207 train_loss: 0.029403094 val_loss: 0.021143844\n",
      "Step = 208 train_loss: 0.028619044 val_loss: 0.021173408\n",
      "Step = 209 train_loss: 0.02846423 val_loss: 0.021150926\n",
      "Step = 210 train_loss: 0.0298126 val_loss: 0.02117109\n",
      "Step = 211 train_loss: 0.030345459 val_loss: 0.021109995\n",
      "Step = 212 train_loss: 0.028393222 val_loss: 0.02115113\n",
      "Step = 213 train_loss: 0.027978787 val_loss: 0.021270566\n",
      "Step = 214 train_loss: 0.030084087 val_loss: 0.021125354\n",
      "Step = 215 train_loss: 0.028333886 val_loss: 0.0210278\n",
      "Step = 216 train_loss: 0.027689718 val_loss: 0.020970507\n",
      "Step = 217 train_loss: 0.028155293 val_loss: 0.021020079\n",
      "Step = 218 train_loss: 0.029346434 val_loss: 0.020952445\n",
      "Step = 219 train_loss: 0.029101092 val_loss: 0.020944722\n",
      "Step = 220 train_loss: 0.028524358 val_loss: 0.020973988\n",
      "Step = 221 train_loss: 0.030117193 val_loss: 0.02100629\n",
      "Step = 222 train_loss: 0.029572306 val_loss: 0.021015916\n",
      "Step = 223 train_loss: 0.02898995 val_loss: 0.021107472\n",
      "Step = 224 train_loss: 0.029409043 val_loss: 0.020995222\n",
      "Step = 225 train_loss: 0.028179018 val_loss: 0.021145128\n",
      "Step = 226 train_loss: 0.028666655 val_loss: 0.020972017\n",
      "Step = 227 train_loss: 0.029699732 val_loss: 0.021104103\n",
      "Step = 228 train_loss: 0.02982771 val_loss: 0.021057066\n",
      "Step = 229 train_loss: 0.029807921 val_loss: 0.020971017\n",
      "Step = 230 train_loss: 0.029422622 val_loss: 0.021016974\n",
      "Step = 231 train_loss: 0.029068934 val_loss: 0.021278914\n",
      "Step = 232 train_loss: 0.029323716 val_loss: 0.021285484\n",
      "Step = 233 train_loss: 0.028503964 val_loss: 0.021075705\n",
      "Step = 234 train_loss: 0.029407464 val_loss: 0.021647785\n",
      "Step = 235 train_loss: 0.028123256 val_loss: 0.02170443\n",
      "Step = 236 train_loss: 0.028764518 val_loss: 0.021247318\n",
      "Step = 237 train_loss: 0.030006321 val_loss: 0.021200659\n",
      "Step = 238 train_loss: 0.028862078 val_loss: 0.02114138\n",
      "Step = 239 train_loss: 0.02819579 val_loss: 0.021188708\n",
      "Step = 240 train_loss: 0.02922877 val_loss: 0.021377042\n",
      "Step = 241 train_loss: 0.03043371 val_loss: 0.02106583\n",
      "Step = 242 train_loss: 0.028229488 val_loss: 0.020928089\n",
      "Step = 243 train_loss: 0.029403178 val_loss: 0.02098972\n",
      "Step = 244 train_loss: 0.028685996 val_loss: 0.021219235\n",
      "Step = 245 train_loss: 0.028495234 val_loss: 0.020958923\n",
      "Step = 246 train_loss: 0.029260032 val_loss: 0.020896433\n",
      "Step = 247 train_loss: 0.029351642 val_loss: 0.020972064\n",
      "Step = 248 train_loss: 0.029215148 val_loss: 0.020959022\n",
      "Step = 249 train_loss: 0.029021828 val_loss: 0.020950332\n",
      "Step = 250 train_loss: 0.027866205 val_loss: 0.021013219\n",
      "Step = 251 train_loss: 0.029154925 val_loss: 0.020994736\n",
      "Step = 252 train_loss: 0.028972384 val_loss: 0.02094617\n",
      "Step = 253 train_loss: 0.029715486 val_loss: 0.021000257\n",
      "Step = 254 train_loss: 0.028384821 val_loss: 0.020958275\n",
      "Step = 255 train_loss: 0.02877916 val_loss: 0.020934304\n",
      "Step = 256 train_loss: 0.029177444 val_loss: 0.020903813\n",
      "Step = 257 train_loss: 0.029655306 val_loss: 0.020892894\n",
      "Step = 258 train_loss: 0.028752714 val_loss: 0.020924488\n",
      "Step = 259 train_loss: 0.02867632 val_loss: 0.020888451\n",
      "Step = 260 train_loss: 0.028417816 val_loss: 0.020848548\n",
      "Step = 261 train_loss: 0.029633937 val_loss: 0.020860957\n",
      "Step = 262 train_loss: 0.028280497 val_loss: 0.020843128\n",
      "Step = 263 train_loss: 0.029674994 val_loss: 0.020866321\n",
      "Step = 264 train_loss: 0.029262828 val_loss: 0.020876952\n",
      "Step = 265 train_loss: 0.02881021 val_loss: 0.020934027\n",
      "Step = 266 train_loss: 0.028426148 val_loss: 0.020824866\n",
      "Step = 267 train_loss: 0.02903528 val_loss: 0.020886814\n",
      "Step = 268 train_loss: 0.029591529 val_loss: 0.020917235\n",
      "Step = 269 train_loss: 0.028882083 val_loss: 0.020871148\n",
      "Step = 270 train_loss: 0.028985579 val_loss: 0.020845111\n",
      "Step = 271 train_loss: 0.027328748 val_loss: 0.020831788\n",
      "Step = 272 train_loss: 0.029676517 val_loss: 0.020817405\n",
      "Step = 273 train_loss: 0.028139004 val_loss: 0.020772658\n",
      "Step = 274 train_loss: 0.029831158 val_loss: 0.020772092\n",
      "Step = 275 train_loss: 0.028754588 val_loss: 0.020820372\n",
      "Step = 276 train_loss: 0.02898102 val_loss: 0.020793518\n",
      "Step = 277 train_loss: 0.029456714 val_loss: 0.02078466\n",
      "Step = 278 train_loss: 0.030303331 val_loss: 0.020842332\n",
      "Step = 279 train_loss: 0.028166685 val_loss: 0.020793865\n",
      "Step = 280 train_loss: 0.028366338 val_loss: 0.020897014\n",
      "Step = 281 train_loss: 0.02951749 val_loss: 0.020783227\n",
      "Step = 282 train_loss: 0.029301006 val_loss: 0.020779192\n",
      "Step = 283 train_loss: 0.029078778 val_loss: 0.020761859\n",
      "Step = 284 train_loss: 0.027739393 val_loss: 0.02078992\n",
      "Step = 285 train_loss: 0.028880127 val_loss: 0.020804977\n",
      "Step = 286 train_loss: 0.028531436 val_loss: 0.02078079\n",
      "Step = 287 train_loss: 0.028443046 val_loss: 0.020840462\n",
      "Step = 288 train_loss: 0.029738413 val_loss: 0.0207938\n",
      "Step = 289 train_loss: 0.028924324 val_loss: 0.020736301\n",
      "Step = 290 train_loss: 0.028860329 val_loss: 0.020755826\n",
      "Step = 291 train_loss: 0.028183116 val_loss: 0.020743055\n",
      "Step = 292 train_loss: 0.028981457 val_loss: 0.020822795\n",
      "Step = 293 train_loss: 0.029792778 val_loss: 0.020813778\n",
      "Step = 294 train_loss: 0.029484076 val_loss: 0.020819815\n",
      "Step = 295 train_loss: 0.028986616 val_loss: 0.020814076\n",
      "Step = 296 train_loss: 0.029458834 val_loss: 0.02081695\n",
      "Step = 297 train_loss: 0.028978009 val_loss: 0.020829601\n",
      "Step = 298 train_loss: 0.029011818 val_loss: 0.020812487\n",
      "Step = 299 train_loss: 0.029016204 val_loss: 0.02077427\n",
      "Step = 300 train_loss: 0.029004594 val_loss: 0.020831408\n",
      "Step = 301 train_loss: 0.028503466 val_loss: 0.020824078\n",
      "Step = 302 train_loss: 0.0281058 val_loss: 0.020837078\n",
      "Step = 303 train_loss: 0.029414061 val_loss: 0.020792468\n",
      "Step = 304 train_loss: 0.02840055 val_loss: 0.020827051\n",
      "Step = 305 train_loss: 0.028652359 val_loss: 0.02083706\n",
      "Step = 306 train_loss: 0.02912099 val_loss: 0.02080207\n",
      "Step = 307 train_loss: 0.028319586 val_loss: 0.020811899\n",
      "Step = 308 train_loss: 0.029257348 val_loss: 0.02083035\n",
      "Step = 309 train_loss: 0.028613044 val_loss: 0.020805737\n",
      "Step = 310 train_loss: 0.030129613 val_loss: 0.020808205\n",
      "Step = 311 train_loss: 0.029997451 val_loss: 0.020769984\n",
      "Step = 312 train_loss: 0.029192258 val_loss: 0.020800564\n",
      "Step = 313 train_loss: 0.029054025 val_loss: 0.020797411\n",
      "Step = 314 train_loss: 0.029661814 val_loss: 0.020835513\n",
      "Step = 315 train_loss: 0.029360015 val_loss: 0.020774404\n",
      "Step = 316 train_loss: 0.02845466 val_loss: 0.020775393\n",
      "Step = 317 train_loss: 0.02868531 val_loss: 0.0207275\n",
      "Step = 318 train_loss: 0.02941092 val_loss: 0.020804157\n",
      "Step = 319 train_loss: 0.029141787 val_loss: 0.02081671\n",
      "Step = 320 train_loss: 0.0287084 val_loss: 0.020792365\n",
      "Step = 321 train_loss: 0.029067876 val_loss: 0.020841172\n",
      "Step = 322 train_loss: 0.02957242 val_loss: 0.020841822\n",
      "Step = 323 train_loss: 0.028778652 val_loss: 0.02081613\n",
      "Step = 324 train_loss: 0.029451797 val_loss: 0.02081645\n",
      "Step = 325 train_loss: 0.028285913 val_loss: 0.020872107\n",
      "Step = 326 train_loss: 0.028820643 val_loss: 0.020805307\n",
      "Step = 327 train_loss: 0.029698102 val_loss: 0.020837165\n",
      "Step = 328 train_loss: 0.028137067 val_loss: 0.020834666\n",
      "Step = 329 train_loss: 0.02871574 val_loss: 0.020818323\n",
      "Step = 330 train_loss: 0.028244378 val_loss: 0.020817619\n",
      "Step = 331 train_loss: 0.02879818 val_loss: 0.02079762\n",
      "Step = 332 train_loss: 0.029157104 val_loss: 0.020806305\n",
      "Step = 333 train_loss: 0.028188314 val_loss: 0.020831833\n",
      "Step = 334 train_loss: 0.028804101 val_loss: 0.020924743\n",
      "Step = 335 train_loss: 0.028998805 val_loss: 0.020821117\n",
      "Step = 336 train_loss: 0.029711088 val_loss: 0.020777268\n",
      "Step = 337 train_loss: 0.029670648 val_loss: 0.020796556\n",
      "Step = 338 train_loss: 0.029052844 val_loss: 0.020916648\n",
      "Step = 339 train_loss: 0.029541781 val_loss: 0.020799998\n",
      "Step = 340 train_loss: 0.028050123 val_loss: 0.020777542\n",
      "Step = 341 train_loss: 0.029577363 val_loss: 0.020798542\n",
      "Step = 342 train_loss: 0.02936205 val_loss: 0.020801337\n",
      "Step = 343 train_loss: 0.029022504 val_loss: 0.020802144\n",
      "Step = 344 train_loss: 0.028924707 val_loss: 0.020842068\n",
      "Step = 345 train_loss: 0.028237728 val_loss: 0.020856107\n",
      "Step = 346 train_loss: 0.029101688 val_loss: 0.020841347\n",
      "Step = 347 train_loss: 0.028120514 val_loss: 0.020849695\n",
      "Step = 348 train_loss: 0.028249446 val_loss: 0.020772958\n",
      "Step = 349 train_loss: 0.028533112 val_loss: 0.020750254\n",
      "Step = 350 train_loss: 0.028628277 val_loss: 0.020860145\n",
      "Step = 351 train_loss: 0.027376125 val_loss: 0.02086106\n",
      "Step = 352 train_loss: 0.028810266 val_loss: 0.020862237\n",
      "Step = 353 train_loss: 0.028881622 val_loss: 0.02085183\n",
      "Step = 354 train_loss: 0.028200822 val_loss: 0.020792851\n",
      "Step = 355 train_loss: 0.029662315 val_loss: 0.02088517\n",
      "Step = 356 train_loss: 0.028188618 val_loss: 0.02080361\n",
      "Step = 357 train_loss: 0.028551642 val_loss: 0.020800568\n",
      "Step = 358 train_loss: 0.029128036 val_loss: 0.02081458\n",
      "Step = 359 train_loss: 0.02908891 val_loss: 0.020754328\n",
      "Step = 360 train_loss: 0.029847832 val_loss: 0.0206988\n",
      "Step = 361 train_loss: 0.029259382 val_loss: 0.020708688\n",
      "Step = 362 train_loss: 0.028546494 val_loss: 0.020735588\n",
      "Step = 363 train_loss: 0.029076299 val_loss: 0.020770242\n",
      "Step = 364 train_loss: 0.030935563 val_loss: 0.020812009\n",
      "Step = 365 train_loss: 0.028076254 val_loss: 0.02083331\n",
      "Step = 366 train_loss: 0.028621571 val_loss: 0.02082776\n",
      "Step = 367 train_loss: 0.029236574 val_loss: 0.020830007\n",
      "Step = 368 train_loss: 0.028399479 val_loss: 0.02091603\n",
      "Step = 369 train_loss: 0.028507741 val_loss: 0.02088813\n",
      "Step = 370 train_loss: 0.02874627 val_loss: 0.020861093\n",
      "Step = 371 train_loss: 0.028734881 val_loss: 0.020818396\n",
      "Step = 372 train_loss: 0.028249325 val_loss: 0.020785362\n",
      "Step = 373 train_loss: 0.029200958 val_loss: 0.020817872\n",
      "Step = 374 train_loss: 0.029207878 val_loss: 0.020709598\n",
      "Step = 375 train_loss: 0.02919665 val_loss: 0.020736765\n",
      "Step = 376 train_loss: 0.028634269 val_loss: 0.020765347\n",
      "Step = 377 train_loss: 0.028697683 val_loss: 0.02069483\n",
      "Step = 378 train_loss: 0.029190393 val_loss: 0.02068065\n",
      "Step = 379 train_loss: 0.028445877 val_loss: 0.020758254\n",
      "Step = 380 train_loss: 0.029177567 val_loss: 0.020717165\n",
      "Step = 381 train_loss: 0.028896917 val_loss: 0.020708162\n",
      "Step = 382 train_loss: 0.028622828 val_loss: 0.020715145\n",
      "Step = 383 train_loss: 0.02808886 val_loss: 0.020764071\n",
      "Step = 384 train_loss: 0.029058404 val_loss: 0.020821655\n",
      "Step = 385 train_loss: 0.028279934 val_loss: 0.020748284\n",
      "Step = 386 train_loss: 0.029382316 val_loss: 0.02074501\n",
      "Step = 387 train_loss: 0.028498743 val_loss: 0.020716809\n",
      "Step = 388 train_loss: 0.028910507 val_loss: 0.020701768\n",
      "Step = 389 train_loss: 0.027709119 val_loss: 0.020769224\n",
      "Step = 390 train_loss: 0.026804792 val_loss: 0.020723669\n",
      "Step = 391 train_loss: 0.028494528 val_loss: 0.020697301\n",
      "Step = 392 train_loss: 0.027948907 val_loss: 0.021172924\n",
      "Step = 393 train_loss: 0.028695373 val_loss: 0.02168549\n",
      "Step = 394 train_loss: 0.029268814 val_loss: 0.022590965\n",
      "Step = 395 train_loss: 0.029672783 val_loss: 0.022605203\n",
      "Step = 396 train_loss: 0.029769294 val_loss: 0.022487517\n",
      "Step = 397 train_loss: 0.028851284 val_loss: 0.022211261\n",
      "Step = 398 train_loss: 0.029587952 val_loss: 0.022726856\n",
      "Step = 399 train_loss: 0.030537369 val_loss: 0.021761417\n",
      "Step = 400 train_loss: 0.027846912 val_loss: 0.022529298\n",
      "Step = 401 train_loss: 0.02735018 val_loss: 0.02404934\n",
      "Step = 402 train_loss: 0.029257786 val_loss: 0.021867748\n",
      "Step = 403 train_loss: 0.028281678 val_loss: 0.021892998\n",
      "Step = 404 train_loss: 0.028739033 val_loss: 0.021999924\n",
      "Step = 405 train_loss: 0.029446714 val_loss: 0.022623338\n",
      "Step = 406 train_loss: 0.029125314 val_loss: 0.021574005\n",
      "Step = 407 train_loss: 0.027885137 val_loss: 0.021254929\n",
      "Step = 408 train_loss: 0.027546318 val_loss: 0.021232596\n",
      "Step = 409 train_loss: 0.027597917 val_loss: 0.021566698\n",
      "Step = 410 train_loss: 0.028147966 val_loss: 0.020859776\n",
      "Step = 411 train_loss: 0.028090885 val_loss: 0.021345146\n",
      "Step = 412 train_loss: 0.02764785 val_loss: 0.020735439\n",
      "Step = 413 train_loss: 0.028995203 val_loss: 0.020810071\n",
      "Step = 414 train_loss: 0.02807166 val_loss: 0.02060401\n",
      "Step = 415 train_loss: 0.02845842 val_loss: 0.020390209\n",
      "Step = 416 train_loss: 0.027590431 val_loss: 0.02035432\n",
      "Step = 417 train_loss: 0.02875937 val_loss: 0.020712972\n",
      "Step = 418 train_loss: 0.027394813 val_loss: 0.020367997\n",
      "Step = 419 train_loss: 0.029695293 val_loss: 0.020123843\n",
      "Step = 420 train_loss: 0.02747697 val_loss: 0.020252278\n",
      "Step = 421 train_loss: 0.02811679 val_loss: 0.02060566\n",
      "Step = 422 train_loss: 0.026237898 val_loss: 0.020404419\n",
      "Step = 423 train_loss: 0.030000709 val_loss: 0.020517817\n",
      "Step = 424 train_loss: 0.02897084 val_loss: 0.020506626\n",
      "Step = 425 train_loss: 0.029050227 val_loss: 0.020534793\n",
      "Step = 426 train_loss: 0.026257664 val_loss: 0.020611139\n",
      "Step = 427 train_loss: 0.025965143 val_loss: 0.020017568\n",
      "Step = 428 train_loss: 0.025530327 val_loss: 0.020344883\n",
      "Step = 429 train_loss: 0.027475204 val_loss: 0.020557811\n",
      "Step = 430 train_loss: 0.027439438 val_loss: 0.019767903\n",
      "Step = 431 train_loss: 0.025690649 val_loss: 0.01906013\n",
      "Step = 432 train_loss: 0.025170157 val_loss: 0.02418569\n",
      "Step = 433 train_loss: 0.028282117 val_loss: 0.025766607\n",
      "Step = 434 train_loss: 0.026507301 val_loss: 0.026027223\n",
      "Step = 435 train_loss: 0.024834651 val_loss: 0.025926663\n",
      "Step = 436 train_loss: 0.02346302 val_loss: 0.028112411\n",
      "Step = 437 train_loss: 0.024383385 val_loss: 0.028890884\n",
      "Step = 438 train_loss: 0.023374071 val_loss: 0.028277127\n",
      "Step = 439 train_loss: 0.026882939 val_loss: 0.030852452\n",
      "Step = 440 train_loss: 0.02635528 val_loss: 0.03080428\n",
      "Step = 441 train_loss: 0.022948444 val_loss: 0.030205524\n",
      "Step = 442 train_loss: 0.024291286 val_loss: 0.030879788\n",
      "Step = 443 train_loss: 0.027337495 val_loss: 0.03159484\n",
      "Step = 444 train_loss: 0.029389309 val_loss: 0.03220703\n",
      "Step = 445 train_loss: 0.027068432 val_loss: 0.033126008\n",
      "Step = 446 train_loss: 0.02868701 val_loss: 0.033998415\n",
      "Step = 447 train_loss: 0.02404678 val_loss: 0.033802282\n",
      "Step = 448 train_loss: 0.02718385 val_loss: 0.033652578\n",
      "Step = 449 train_loss: 0.024402378 val_loss: 0.03203234\n",
      "Step = 450 train_loss: 0.023696257 val_loss: 0.031537455\n",
      "Step = 451 train_loss: 0.023250807 val_loss: 0.03081542\n",
      "Step = 452 train_loss: 0.019804887 val_loss: 0.03003736\n",
      "Step = 453 train_loss: 0.024033079 val_loss: 0.028290406\n",
      "Step = 454 train_loss: 0.020851849 val_loss: 0.02585266\n",
      "Step = 455 train_loss: 0.021827916 val_loss: 0.019330496\n",
      "Step = 456 train_loss: 0.022277545 val_loss: 0.01916936\n",
      "Step = 457 train_loss: 0.020423837 val_loss: 0.01761042\n",
      "Step = 458 train_loss: 0.021600528 val_loss: 0.016371915\n",
      "Step = 459 train_loss: 0.019550173 val_loss: 0.01834889\n",
      "Step = 460 train_loss: 0.02263735 val_loss: 0.015660042\n",
      "Step = 461 train_loss: 0.022915225 val_loss: 0.015239685\n",
      "Step = 462 train_loss: 0.021149691 val_loss: 0.015375218\n",
      "Step = 463 train_loss: 0.02194468 val_loss: 0.020368373\n",
      "Step = 464 train_loss: 0.01844987 val_loss: 0.027351549\n",
      "Step = 465 train_loss: 0.018845536 val_loss: 0.019651154\n",
      "Step = 466 train_loss: 0.024249587 val_loss: 0.024047585\n",
      "Step = 467 train_loss: 0.018449914 val_loss: 0.038904265\n",
      "Step = 468 train_loss: 0.018879376 val_loss: 0.03715957\n",
      "Step = 469 train_loss: 0.021299541 val_loss: 0.04470078\n",
      "Step = 470 train_loss: 0.022155406 val_loss: 0.045472287\n",
      "Step = 471 train_loss: 0.017484035 val_loss: 0.04830687\n",
      "Step = 472 train_loss: 0.01877581 val_loss: 0.04720796\n",
      "Step = 473 train_loss: 0.020001922 val_loss: 0.044769105\n",
      "Step = 474 train_loss: 0.017677324 val_loss: 0.0460967\n",
      "Step = 475 train_loss: 0.017072389 val_loss: 0.044148505\n",
      "Step = 476 train_loss: 0.017483372 val_loss: 0.043899685\n",
      "Step = 477 train_loss: 0.016422901 val_loss: 0.04525769\n",
      "Step = 478 train_loss: 0.018054904 val_loss: 0.045661505\n",
      "Step = 479 train_loss: 0.022874203 val_loss: 0.04221343\n",
      "Step = 480 train_loss: 0.01905172 val_loss: 0.043953937\n",
      "Step = 481 train_loss: 0.016407322 val_loss: 0.044395424\n",
      "Step = 482 train_loss: 0.017231867 val_loss: 0.033706956\n",
      "Step = 483 train_loss: 0.020017643 val_loss: 0.042082082\n",
      "Step = 484 train_loss: 0.016891228 val_loss: 0.041191988\n",
      "Step = 485 train_loss: 0.020432018 val_loss: 0.040259533\n",
      "Step = 486 train_loss: 0.01871887 val_loss: 0.040470682\n",
      "Step = 487 train_loss: 0.017066114 val_loss: 0.039142236\n",
      "Step = 488 train_loss: 0.01808547 val_loss: 0.037425455\n",
      "Step = 489 train_loss: 0.015338775 val_loss: 0.042778954\n",
      "Step = 490 train_loss: 0.016118944 val_loss: 0.042175155\n",
      "Step = 491 train_loss: 0.01643412 val_loss: 0.042837076\n",
      "Step = 492 train_loss: 0.01734004 val_loss: 0.043276403\n",
      "Step = 493 train_loss: 0.017134558 val_loss: 0.042029593\n",
      "Step = 494 train_loss: 0.015788032 val_loss: 0.04421988\n",
      "Step = 495 train_loss: 0.015045389 val_loss: 0.042183023\n",
      "Step = 496 train_loss: 0.014581548 val_loss: 0.040948324\n",
      "Step = 497 train_loss: 0.015436797 val_loss: 0.043329798\n",
      "Step = 498 train_loss: 0.01737256 val_loss: 0.04163494\n",
      "Step = 499 train_loss: 0.016288029 val_loss: 0.04077402\n",
      "Step = 500 train_loss: 0.014930172 val_loss: 0.040808152\n",
      "Step = 501 train_loss: 0.01678712 val_loss: 0.0419002\n",
      "Step = 502 train_loss: 0.016281689 val_loss: 0.03746902\n",
      "Step = 503 train_loss: 0.018078255 val_loss: 0.037550177\n",
      "Step = 504 train_loss: 0.015721586 val_loss: 0.039662898\n",
      "Step = 505 train_loss: 0.0153377885 val_loss: 0.039741363\n",
      "Step = 506 train_loss: 0.015352264 val_loss: 0.040273286\n",
      "Step = 507 train_loss: 0.0158946 val_loss: 0.035591226\n",
      "Step = 508 train_loss: 0.014524738 val_loss: 0.03778564\n",
      "Step = 509 train_loss: 0.01624624 val_loss: 0.039924636\n",
      "Step = 510 train_loss: 0.01615123 val_loss: 0.02720274\n",
      "Step = 511 train_loss: 0.01687384 val_loss: 0.029283939\n",
      "Step = 512 train_loss: 0.015126217 val_loss: 0.019444795\n",
      "Step = 513 train_loss: 0.016148208 val_loss: 0.02020438\n",
      "Step = 514 train_loss: 0.014593274 val_loss: 0.010531178\n",
      "Step = 515 train_loss: 0.01517703 val_loss: 0.010733755\n",
      "Step = 516 train_loss: 0.015299649 val_loss: 0.013802448\n",
      "Step = 517 train_loss: 0.013733083 val_loss: 0.011162279\n",
      "Step = 518 train_loss: 0.014403923 val_loss: 0.010956029\n",
      "Step = 519 train_loss: 0.015627451 val_loss: 0.017664058\n",
      "Step = 520 train_loss: 0.015286475 val_loss: 0.032903712\n",
      "Step = 521 train_loss: 0.015931046 val_loss: 0.028684117\n",
      "Step = 522 train_loss: 0.015932836 val_loss: 0.014426179\n",
      "Step = 523 train_loss: 0.017748348 val_loss: 0.011388813\n",
      "Step = 524 train_loss: 0.016103256 val_loss: 0.03749223\n",
      "Step = 525 train_loss: 0.015468269 val_loss: 0.047057234\n",
      "Step = 526 train_loss: 0.015806552 val_loss: 0.04462015\n",
      "Step = 527 train_loss: 0.014731023 val_loss: 0.048821904\n",
      "Step = 528 train_loss: 0.017898547 val_loss: 0.04495994\n",
      "Step = 529 train_loss: 0.017140662 val_loss: 0.04561317\n",
      "Step = 530 train_loss: 0.01739832 val_loss: 0.040089376\n",
      "Step = 531 train_loss: 0.016499253 val_loss: 0.03864164\n",
      "Step = 532 train_loss: 0.014528232 val_loss: 0.041838482\n",
      "Step = 533 train_loss: 0.015967991 val_loss: 0.038184993\n",
      "Step = 534 train_loss: 0.017277759 val_loss: 0.041616324\n",
      "Step = 535 train_loss: 0.016985126 val_loss: 0.038422037\n",
      "Step = 536 train_loss: 0.017455526 val_loss: 0.04007681\n",
      "Step = 537 train_loss: 0.016391406 val_loss: 0.040886484\n",
      "Step = 538 train_loss: 0.014339571 val_loss: 0.03600027\n",
      "Step = 539 train_loss: 0.014985244 val_loss: 0.018004037\n",
      "Step = 540 train_loss: 0.01847562 val_loss: 0.033834085\n",
      "Step = 541 train_loss: 0.01412758 val_loss: 0.033878427\n",
      "Step = 542 train_loss: 0.013868203 val_loss: 0.033617564\n",
      "Step = 543 train_loss: 0.01319241 val_loss: 0.029370867\n",
      "Step = 544 train_loss: 0.01240365 val_loss: 0.03132912\n",
      "Step = 545 train_loss: 0.013088483 val_loss: 0.031553276\n",
      "Step = 546 train_loss: 0.014535582 val_loss: 0.01879906\n",
      "Step = 547 train_loss: 0.016077058 val_loss: 0.019468829\n",
      "Step = 548 train_loss: 0.013221722 val_loss: 0.028874844\n",
      "Step = 549 train_loss: 0.015056955 val_loss: 0.031825442\n",
      "Step = 550 train_loss: 0.01339984 val_loss: 0.03022958\n",
      "Step = 551 train_loss: 0.012529755 val_loss: 0.030944576\n",
      "Step = 552 train_loss: 0.023095557 val_loss: 0.029410431\n",
      "Step = 553 train_loss: 0.012016548 val_loss: 0.056360338\n",
      "Step = 554 train_loss: 0.013065974 val_loss: 0.08828731\n",
      "Step = 555 train_loss: 0.016255338 val_loss: 0.096565545\n",
      "Step = 556 train_loss: 0.014685022 val_loss: 0.07876063\n",
      "Step = 557 train_loss: 0.018857278 val_loss: 0.054928966\n",
      "Step = 558 train_loss: 0.022195987 val_loss: 0.061471585\n",
      "Step = 559 train_loss: 0.028485281 val_loss: 0.066159286\n",
      "Step = 560 train_loss: 0.017040947 val_loss: 0.074580245\n",
      "Step = 561 train_loss: 0.01551585 val_loss: 0.066098064\n",
      "Step = 562 train_loss: 0.01787619 val_loss: 0.079645485\n",
      "Step = 563 train_loss: 0.026640398 val_loss: 0.080276094\n",
      "Step = 564 train_loss: 0.02037041 val_loss: 0.06867088\n",
      "Step = 565 train_loss: 0.020199796 val_loss: 0.07306434\n",
      "Step = 566 train_loss: 0.01995479 val_loss: 0.06325445\n",
      "Step = 567 train_loss: 0.023719527 val_loss: 0.069335505\n",
      "Step = 568 train_loss: 0.022500485 val_loss: 0.06448842\n",
      "Step = 569 train_loss: 0.024859356 val_loss: 0.06366379\n",
      "Step = 570 train_loss: 0.027191598 val_loss: 0.059921183\n",
      "Step = 571 train_loss: 0.026526349 val_loss: 0.058784194\n",
      "Step = 572 train_loss: 0.022685897 val_loss: 0.061575145\n",
      "Step = 573 train_loss: 0.018010996 val_loss: 0.06439053\n",
      "Step = 574 train_loss: 0.021810522 val_loss: 0.061501585\n",
      "Step = 575 train_loss: 0.015099423 val_loss: 0.057536397\n",
      "Step = 576 train_loss: 0.023159632 val_loss: 0.052508675\n",
      "Step = 577 train_loss: 0.027373832 val_loss: 0.04804159\n",
      "Step = 578 train_loss: 0.026222577 val_loss: 0.041482348\n",
      "Step = 579 train_loss: 0.024811087 val_loss: 0.046041287\n",
      "Step = 580 train_loss: 0.021026317 val_loss: 0.046189122\n",
      "Step = 581 train_loss: 0.02711572 val_loss: 0.04523636\n",
      "Step = 582 train_loss: 0.016883327 val_loss: 0.040925108\n",
      "Step = 583 train_loss: 0.022692291 val_loss: 0.039782528\n",
      "Step = 584 train_loss: 0.019073809 val_loss: 0.0402028\n",
      "Step = 585 train_loss: 0.01846874 val_loss: 0.034717526\n",
      "Step = 586 train_loss: 0.017083215 val_loss: 0.03417134\n",
      "Step = 587 train_loss: 0.027961599 val_loss: 0.03671156\n",
      "Step = 588 train_loss: 0.018390791 val_loss: 0.03502861\n",
      "Step = 589 train_loss: 0.025890052 val_loss: 0.032480925\n",
      "Step = 590 train_loss: 0.0271326 val_loss: 0.03239395\n",
      "Step = 591 train_loss: 0.014593898 val_loss: 0.03473098\n",
      "Step = 592 train_loss: 0.019662134 val_loss: 0.02968727\n",
      "Step = 593 train_loss: 0.015702711 val_loss: 0.028666122\n",
      "Step = 594 train_loss: 0.013038067 val_loss: 0.028087486\n",
      "Step = 595 train_loss: 0.023790244 val_loss: 0.021782368\n",
      "Step = 596 train_loss: 0.019074425 val_loss: 0.016598707\n",
      "Step = 597 train_loss: 0.024750473 val_loss: 0.025784196\n",
      "Step = 598 train_loss: 0.020808183 val_loss: 0.028207954\n",
      "Step = 599 train_loss: 0.01656532 val_loss: 0.029416168\n",
      "Step = 600 train_loss: 0.022513185 val_loss: 0.032156482\n",
      "Step = 601 train_loss: 0.018632451 val_loss: 0.031323444\n",
      "Step = 602 train_loss: 0.01865479 val_loss: 0.031124577\n",
      "Step = 603 train_loss: 0.022011535 val_loss: 0.032151204\n",
      "Step = 604 train_loss: 0.019376995 val_loss: 0.034878977\n",
      "Step = 605 train_loss: 0.015347049 val_loss: 0.03621862\n",
      "Step = 606 train_loss: 0.022621479 val_loss: 0.037646558\n",
      "Step = 607 train_loss: 0.029459845 val_loss: 0.035298213\n",
      "Step = 608 train_loss: 0.018356236 val_loss: 0.0339556\n",
      "Step = 609 train_loss: 0.012894239 val_loss: 0.033438444\n",
      "Step = 610 train_loss: 0.010770572 val_loss: 0.031638972\n",
      "Step = 611 train_loss: 0.019363659 val_loss: 0.033127803\n",
      "Step = 612 train_loss: 0.013405079 val_loss: 0.030433632\n",
      "Step = 613 train_loss: 0.014958358 val_loss: 0.03033096\n",
      "Step = 614 train_loss: 0.020441068 val_loss: 0.029816587\n",
      "Step = 615 train_loss: 0.019980935 val_loss: 0.027933747\n",
      "Step = 616 train_loss: 0.015762694 val_loss: 0.027752155\n",
      "Step = 617 train_loss: 0.012094134 val_loss: 0.027902355\n",
      "Step = 618 train_loss: 0.013168038 val_loss: 0.028963482\n",
      "Step = 619 train_loss: 0.0151522765 val_loss: 0.027502434\n",
      "Step = 620 train_loss: 0.017376635 val_loss: 0.027607523\n",
      "Step = 621 train_loss: 0.010519069 val_loss: 0.028135916\n",
      "Step = 622 train_loss: 0.008976367 val_loss: 0.030146854\n",
      "Step = 623 train_loss: 0.009608036 val_loss: 0.028045883\n",
      "Step = 624 train_loss: 0.008680225 val_loss: 0.02669661\n",
      "Step = 625 train_loss: 0.008836698 val_loss: 0.026603373\n",
      "Step = 626 train_loss: 0.008877627 val_loss: 0.028085066\n",
      "Step = 627 train_loss: 0.0091077965 val_loss: 0.028866768\n",
      "Step = 628 train_loss: 0.011121573 val_loss: 0.028766667\n",
      "Step = 629 train_loss: 0.011346981 val_loss: 0.027354905\n",
      "Step = 630 train_loss: 0.010139055 val_loss: 0.026688129\n",
      "Step = 631 train_loss: 0.022318922 val_loss: 0.024885466\n",
      "Step = 632 train_loss: 0.010215296 val_loss: 0.024019144\n",
      "Step = 633 train_loss: 0.0113795 val_loss: 0.023360498\n",
      "Step = 634 train_loss: 0.016259862 val_loss: 0.022212485\n",
      "Step = 635 train_loss: 0.0097282715 val_loss: 0.022653151\n",
      "Step = 636 train_loss: 0.010819982 val_loss: 0.021702813\n",
      "Step = 637 train_loss: 0.015152614 val_loss: 0.02197812\n",
      "Step = 638 train_loss: 0.011345052 val_loss: 0.021769527\n",
      "Step = 639 train_loss: 0.012731727 val_loss: 0.021136852\n",
      "Step = 640 train_loss: 0.009608282 val_loss: 0.021116095\n",
      "Step = 641 train_loss: 0.00985612 val_loss: 0.0132922875\n",
      "Step = 642 train_loss: 0.022573562 val_loss: 0.019582445\n",
      "Step = 643 train_loss: 0.010260446 val_loss: 0.022172054\n",
      "Step = 644 train_loss: 0.011684169 val_loss: 0.0214563\n",
      "Step = 645 train_loss: 0.016015442 val_loss: 0.024558356\n",
      "Step = 646 train_loss: 0.00642314 val_loss: 0.024415886\n",
      "Step = 647 train_loss: 0.010260531 val_loss: 0.025956541\n",
      "Step = 648 train_loss: 0.007842117 val_loss: 0.025684051\n",
      "Step = 649 train_loss: 0.0068494133 val_loss: 0.026553828\n",
      "Step = 650 train_loss: 0.008518548 val_loss: 0.025962362\n",
      "Step = 651 train_loss: 0.010028379 val_loss: 0.025573263\n",
      "Step = 652 train_loss: 0.0072831875 val_loss: 0.027399834\n",
      "Step = 653 train_loss: 0.010582806 val_loss: 0.02849878\n",
      "Step = 654 train_loss: 0.029618032 val_loss: 0.026979826\n",
      "Step = 655 train_loss: 0.023561232 val_loss: 0.02636898\n",
      "Step = 656 train_loss: 0.02398785 val_loss: 0.025944352\n",
      "Step = 657 train_loss: 0.026809104 val_loss: 0.024919474\n",
      "Step = 658 train_loss: 0.020381926 val_loss: 0.023844313\n",
      "Step = 659 train_loss: 0.019734856 val_loss: 0.023944575\n",
      "Step = 660 train_loss: 0.025773255 val_loss: 0.022773962\n",
      "Step = 661 train_loss: 0.023383914 val_loss: 0.022547802\n",
      "Step = 662 train_loss: 0.019319039 val_loss: 0.02262789\n",
      "Step = 663 train_loss: 0.025033917 val_loss: 0.023162164\n",
      "Step = 664 train_loss: 0.035209797 val_loss: 0.021247536\n",
      "Step = 665 train_loss: 0.01563932 val_loss: 0.020463537\n",
      "Step = 666 train_loss: 0.028534634 val_loss: 0.021844033\n",
      "Step = 667 train_loss: 0.023994198 val_loss: 0.022980578\n",
      "Step = 668 train_loss: 0.0197607 val_loss: 0.0221775\n",
      "Step = 669 train_loss: 0.013689875 val_loss: 0.021913582\n",
      "Step = 670 train_loss: 0.023407975 val_loss: 0.022788566\n",
      "Step = 671 train_loss: 0.030329952 val_loss: 0.021808079\n",
      "Step = 672 train_loss: 0.018545559 val_loss: 0.021583231\n",
      "Step = 673 train_loss: 0.020814331 val_loss: 0.021764923\n",
      "Step = 674 train_loss: 0.017905543 val_loss: 0.02149514\n",
      "Step = 675 train_loss: 0.023204286 val_loss: 0.02094597\n",
      "Step = 676 train_loss: 0.029698549 val_loss: 0.021849344\n",
      "Step = 677 train_loss: 0.026763817 val_loss: 0.021161513\n",
      "Step = 678 train_loss: 0.036005873 val_loss: 0.019744428\n",
      "Step = 679 train_loss: 0.0264679 val_loss: 0.019585619\n",
      "Step = 680 train_loss: 0.021186637 val_loss: 0.018520325\n",
      "Step = 681 train_loss: 0.026807833 val_loss: 0.019933492\n",
      "Step = 682 train_loss: 0.024757734 val_loss: 0.020090267\n",
      "Step = 683 train_loss: 0.023366166 val_loss: 0.017391497\n",
      "Step = 684 train_loss: 0.025002573 val_loss: 0.018941455\n",
      "Step = 685 train_loss: 0.026451072 val_loss: 0.019930705\n",
      "Step = 686 train_loss: 0.024164926 val_loss: 0.01791837\n",
      "Step = 687 train_loss: 0.02434983 val_loss: 0.018981239\n",
      "Step = 688 train_loss: 0.025447177 val_loss: 0.019435748\n",
      "Step = 689 train_loss: 0.019941611 val_loss: 0.017724738\n",
      "Step = 690 train_loss: 0.018715251 val_loss: 0.017362062\n",
      "Step = 691 train_loss: 0.030142665 val_loss: 0.018004036\n",
      "Step = 692 train_loss: 0.02981116 val_loss: 0.01684443\n",
      "Step = 693 train_loss: 0.021881491 val_loss: 0.016686048\n",
      "Step = 694 train_loss: 0.026299993 val_loss: 0.017284099\n",
      "Step = 695 train_loss: 0.0276646 val_loss: 0.01696942\n",
      "Step = 696 train_loss: 0.03644412 val_loss: 0.017097972\n",
      "Step = 697 train_loss: 0.029830653 val_loss: 0.017140962\n",
      "Step = 698 train_loss: 0.015757723 val_loss: 0.01692112\n",
      "Step = 699 train_loss: 0.01726478 val_loss: 0.016858913\n",
      "Step = 700 train_loss: 0.026044972 val_loss: 0.015760627\n",
      "Step = 701 train_loss: 0.026084332 val_loss: 0.015714847\n",
      "Step = 702 train_loss: 0.026414314 val_loss: 0.01635175\n",
      "Step = 703 train_loss: 0.026727213 val_loss: 0.016052574\n",
      "Step = 704 train_loss: 0.020947654 val_loss: 0.016231649\n",
      "Step = 705 train_loss: 0.022618553 val_loss: 0.015300784\n",
      "Step = 706 train_loss: 0.016593494 val_loss: 0.015133262\n",
      "Step = 707 train_loss: 0.02019476 val_loss: 0.0151628405\n",
      "Step = 708 train_loss: 0.023256205 val_loss: 0.015380921\n",
      "Step = 709 train_loss: 0.027265707 val_loss: 0.015415479\n",
      "Step = 710 train_loss: 0.023550563 val_loss: 0.014646416\n",
      "Step = 711 train_loss: 0.018691558 val_loss: 0.015188427\n",
      "Step = 712 train_loss: 0.02798296 val_loss: 0.014853459\n",
      "Step = 713 train_loss: 0.03083984 val_loss: 0.014869887\n",
      "Step = 714 train_loss: 0.026817854 val_loss: 0.014933609\n",
      "Step = 715 train_loss: 0.019305084 val_loss: 0.015031089\n",
      "Step = 716 train_loss: 0.027019205 val_loss: 0.0147211235\n",
      "Step = 717 train_loss: 0.017400106 val_loss: 0.014726286\n",
      "Step = 718 train_loss: 0.014697813 val_loss: 0.013989612\n",
      "Step = 719 train_loss: 0.022135423 val_loss: 0.014995015\n",
      "Step = 720 train_loss: 0.018041896 val_loss: 0.015253863\n",
      "Step = 721 train_loss: 0.022799058 val_loss: 0.014976284\n",
      "Step = 722 train_loss: 0.017428685 val_loss: 0.014528873\n",
      "Step = 723 train_loss: 0.021029603 val_loss: 0.014374316\n",
      "Step = 724 train_loss: 0.017851107 val_loss: 0.01451532\n",
      "Step = 725 train_loss: 0.022621963 val_loss: 0.015954603\n",
      "Step = 726 train_loss: 0.017835217 val_loss: 0.017953034\n",
      "Step = 727 train_loss: 0.026866615 val_loss: 0.029697176\n",
      "Step = 728 train_loss: 0.018559868 val_loss: 0.043354705\n",
      "Step = 729 train_loss: 0.018986221 val_loss: 0.059070226\n",
      "Step = 730 train_loss: 0.017525982 val_loss: 0.041267913\n",
      "Step = 731 train_loss: 0.019222869 val_loss: 0.04841895\n",
      "Step = 732 train_loss: 0.028016664 val_loss: 0.04790484\n",
      "Step = 733 train_loss: 0.012929888 val_loss: 0.100527324\n",
      "Step = 734 train_loss: 0.011380927 val_loss: 0.040899076\n",
      "Step = 735 train_loss: 0.016244857 val_loss: 0.04652456\n",
      "Step = 736 train_loss: 0.012005884 val_loss: 0.0756508\n",
      "Step = 737 train_loss: 0.023070274 val_loss: 0.04795013\n",
      "Step = 738 train_loss: 0.014011379 val_loss: 0.21905558\n",
      "Step = 739 train_loss: 0.024366139 val_loss: 0.028255882\n",
      "Step = 740 train_loss: 0.026385097 val_loss: 0.05615879\n",
      "Step = 741 train_loss: 0.018735964 val_loss: 0.050724845\n",
      "Step = 742 train_loss: 0.020343928 val_loss: 0.11130582\n",
      "Step = 743 train_loss: 0.01061325 val_loss: 0.08860195\n",
      "Step = 744 train_loss: 0.012459066 val_loss: 0.20823349\n",
      "Step = 745 train_loss: 0.018654453 val_loss: 0.14586394\n",
      "Step = 746 train_loss: 0.020080246 val_loss: 0.15680756\n",
      "Step = 747 train_loss: 0.009287035 val_loss: 0.184891\n",
      "Step = 748 train_loss: 0.0066383695 val_loss: 0.23177728\n",
      "Step = 749 train_loss: 0.0074831075 val_loss: 0.21461782\n",
      "Step = 750 train_loss: 0.009325024 val_loss: 0.25569767\n",
      "Step = 751 train_loss: 0.006572505 val_loss: 0.20978753\n",
      "Step = 752 train_loss: 0.006561393 val_loss: 0.21066819\n",
      "Step = 753 train_loss: 0.009269969 val_loss: 0.2029424\n",
      "Step = 754 train_loss: 0.006341293 val_loss: 0.09320697\n",
      "Step = 755 train_loss: 0.008441752 val_loss: 0.12744822\n",
      "Step = 756 train_loss: 0.008735069 val_loss: 0.22981727\n",
      "Step = 757 train_loss: 0.013043394 val_loss: 0.29377607\n",
      "Step = 758 train_loss: 0.014031913 val_loss: 0.30161506\n",
      "Step = 759 train_loss: 0.0148473745 val_loss: 0.30321315\n",
      "Step = 760 train_loss: 0.014788371 val_loss: 0.21568494\n",
      "Step = 761 train_loss: 0.022788169 val_loss: 0.29973173\n",
      "Step = 762 train_loss: 0.01464341 val_loss: 0.23558767\n",
      "Step = 763 train_loss: 0.012443767 val_loss: 0.28241152\n",
      "Step = 764 train_loss: 0.01979083 val_loss: 0.25573722\n",
      "Step = 765 train_loss: 0.019588737 val_loss: 0.2568267\n",
      "Step = 766 train_loss: 0.021957071 val_loss: 0.18272635\n",
      "Step = 767 train_loss: 0.026558084 val_loss: 0.13619804\n",
      "Step = 768 train_loss: 0.019010764 val_loss: 0.058610056\n",
      "Step = 769 train_loss: 0.018134477 val_loss: 0.012929287\n",
      "Step = 770 train_loss: 0.01215074 val_loss: 0.02673498\n",
      "Step = 771 train_loss: 0.01796455 val_loss: 0.029558958\n",
      "Step = 772 train_loss: 0.014247611 val_loss: 0.031098587\n",
      "Step = 773 train_loss: 0.0072110645 val_loss: 0.030933509\n",
      "Step = 774 train_loss: 0.0083630765 val_loss: 0.031412907\n",
      "Step = 775 train_loss: 0.008968018 val_loss: 0.033747893\n",
      "Step = 776 train_loss: 0.009135981 val_loss: 0.031236617\n",
      "Step = 777 train_loss: 0.007172213 val_loss: 0.031928103\n",
      "Step = 778 train_loss: 0.006539085 val_loss: 0.031531554\n",
      "Step = 779 train_loss: 0.0068644555 val_loss: 0.033006698\n",
      "Step = 780 train_loss: 0.006161533 val_loss: 0.034755554\n",
      "Step = 781 train_loss: 0.007337593 val_loss: 0.03300482\n",
      "Step = 782 train_loss: 0.01042288 val_loss: 0.03056218\n",
      "Step = 783 train_loss: 0.005077695 val_loss: 0.029785784\n",
      "Step = 784 train_loss: 0.007976324 val_loss: 0.02286821\n",
      "Step = 785 train_loss: 0.012659876 val_loss: 0.009321243\n",
      "Step = 786 train_loss: 0.010511542 val_loss: 0.012528736\n",
      "Step = 787 train_loss: 0.019764788 val_loss: 0.02470842\n",
      "Step = 788 train_loss: 0.0068755476 val_loss: 0.025886126\n",
      "Step = 789 train_loss: 0.007439151 val_loss: 0.02419726\n",
      "Step = 790 train_loss: 0.005091038 val_loss: 0.022845563\n",
      "Step = 791 train_loss: 0.022777624 val_loss: 0.02438219\n",
      "Step = 792 train_loss: 0.023095684 val_loss: 0.022879042\n",
      "Step = 793 train_loss: 0.019490065 val_loss: 0.022859285\n",
      "Step = 794 train_loss: 0.024043549 val_loss: 0.022825073\n",
      "Step = 795 train_loss: 0.02813414 val_loss: 0.02354091\n",
      "Step = 796 train_loss: 0.028729659 val_loss: 0.022812922\n",
      "Step = 797 train_loss: 0.02635628 val_loss: 0.022967853\n",
      "Step = 798 train_loss: 0.019431878 val_loss: 0.02317994\n",
      "Step = 799 train_loss: 0.024737487 val_loss: 0.023976369\n",
      "Best model at index: 785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fisher Man\\AppData\\Local\\Temp\\ipykernel_5240\\2213074592.py:106: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('Best_target_model/net_parameters.pkl')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "'''Data loader for Pytorch'''\n",
    "input_train = torch.FloatTensor(train_Qd)\n",
    "input_train = torch.unsqueeze(input_train, 1)\n",
    "train_labels = torch.FloatTensor(train_cycle_life)\n",
    "\n",
    "input_val = torch.FloatTensor(train_Qds)\n",
    "input_val = torch.unsqueeze(input_val, 1)\n",
    "val_labels = torch.FloatTensor(train_cycle_lifes)\n",
    "\n",
    "input_test_a = torch.FloatTensor(test_Qd_a)\n",
    "input_test_a = torch.unsqueeze(input_test_a, 1)\n",
    "test_labels_a = torch.FloatTensor(test_cycle_life_a)\n",
    "\n",
    "input_test_b = torch.FloatTensor(test_Qd_b)\n",
    "input_test_b = torch.unsqueeze(input_test_b, 1)\n",
    "test_labels_b = torch.FloatTensor(test_cycle_life_b)\n",
    "\n",
    "\n",
    "\n",
    "seed = 17\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "np.random.seed(seed)  # Numpy module.\n",
    "random.seed(seed)  # Python random module.\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(seed)    # reproducible    \n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "loss_func = torch.nn.MSELoss() \n",
    "\n",
    "# # 动态调整学习率\n",
    "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.8 ** (epoch // 40))\n",
    "\n",
    "# # 将学习率调度器修改为指数下降\n",
    "# initial_lr = 0.0001  # 初始学习率\n",
    "# decay_rate = 0.96  # 每个epoch衰减的比例\n",
    "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: decay_rate ** epoch)\n",
    "\n",
    "# 假设你已经定义了模型和优化器\n",
    "# 当验证损失不下降时，减少学习率\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=5)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "# 创建历史记录DataFrame\n",
    "history = pd.DataFrame(columns=['index', 'train_loss', 'val_loss'])\n",
    "val_losses = []\n",
    "max_models_to_keep = 10\n",
    "saved_models=[]\n",
    "import os\n",
    "\n",
    "for t in range(800):\n",
    "    net.train()\n",
    "    train_prediction = net(input_train)\n",
    "    train_loss = loss_func(train_prediction, train_labels)\n",
    "   \n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    # 保存模型\n",
    "    model_path = 'Target_model/net_parameters'+str(t)+'.pkl'\n",
    "    torch.save({\n",
    "        'epoch': t,\n",
    "        'model_state_dict': net.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()}, model_path)\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        val_prediction = net(input_val)\n",
    "        val_loss = loss_func(val_prediction, val_labels)\n",
    "    print('Step = %d' % t, 'train_loss:', train_loss.data.numpy(), 'val_loss:', val_loss.data.numpy())\n",
    "    val_losses.append(val_loss.item())\n",
    "    \n",
    "    # 添加当前模型及其验证损失\n",
    "    saved_models.append((val_loss.item(), model_path))\n",
    "\n",
    "    # 保持模型数量不超过max_models_to_keep\n",
    "    if len(saved_models) > max_models_to_keep:\n",
    "        # 找到验证损失最大的一组模型并删除\n",
    "        saved_models.sort(key=lambda x: x[0])  # 排序，根据损失\n",
    "        os.remove(saved_models.pop()[1])  # 删除损失最大的模型\n",
    "    # 加入训练历史记录\n",
    "    # 创建新的一行数据\n",
    "    new_entry = pd.DataFrame({'index': [t], 'train_loss': [train_loss.item()], 'val_loss': [val_loss.item()]})\n",
    "    \n",
    "    # 使用concat进行数据合并\n",
    "    history = pd.concat([history, new_entry], ignore_index=True)\n",
    "\n",
    "'''find the best model'''\n",
    "best_index = val_losses.index(np.min(val_losses))\n",
    "print(f'Best model at index: {best_index}')\n",
    "print(f'Best model val_loss: {val_losses[best_index]}')\n",
    "\n",
    "'''copy the best model from model file to the model_test file'''\n",
    "shutil.copyfile(f'Target_model/net_parameters{best_index}.pkl', 'Best_target_model/net_parameters.pkl')\n",
    "\n",
    "'''Reload the best model''' \n",
    "model = Net()\n",
    "checkpoint = torch.load('Best_target_model/net_parameters.pkl')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6QklEQVR4nO3dd3xT1fsH8E+SNukuLaWLQimbsmkZLUtkL1FEUJHxFX6IioK4vogDcOAWRUFxMFSGfAFFBaEouwhSWmRv2gItpUD3Tu7vj9vsmzadadLP+/XKi+Tm5ObcFsiT5zznHJkgCAKIiIiI6hG5rTtAREREVNsYABEREVG9wwCIiIiI6h0GQERERFTvMAAiIiKieocBEBEREdU7DICIiIio3nGydQfqIo1Ggxs3bsDT0xMymczW3SEiIiIrCIKA7OxsBAcHQy4vO8fDAEjCjRs30KRJE1t3g4iIiCohOTkZISEhZbZhACTB09MTgPgD9PLysnFviIiIyBpZWVlo0qSJ7nO8LAyAJGiHvby8vBgAERER2RlryldYBE1ERET1DgMgIiIiqncYABEREVG9wxqgKlCr1SguLrZ1N6gKlEpluVMliYjI8TAAqgRBEJCamoqMjAxbd4WqSC6XIywsDEql0tZdISKiWsQAqBK0wY+/vz/c3Ny4WKKd0i54mZKSgqZNm/L3SERUjzAAqiC1Wq0Lfho2bGjr7lAVNWrUCDdu3EBJSQmcnZ1t3R0iIqolLH6oIG3Nj5ubm417QtVBO/SlVqtt3BMiIqpNDIAqicMljoG/RyKi+okBEBEREdU7DICIiIio3mEARJXSrFkzLFmypFrOtWfPHshkMi4rQEREtYazwOqRe+65B126dKmWwOWff/6Bu7t71TtFRER1k0YDqAsBZ1db96RGMANEOoIgoKSkxKq2jRo14kw4IiJH9sMDwEdtgLw7tu5JjbB5ALRs2TKEhYXBxcUFERER2L9/v8W2Bw4cQO/evdGwYUO4urqibdu2+OSTT8zabdq0CeHh4VCpVAgPD8eWLVtq8hIgCALyikpschMEwao+Tp06FXv37sWnn34KmUwGmUyGVatWQSaTYceOHYiMjIRKpcL+/ftx6dIljBkzBgEBAfDw8ED37t2xa9cuo/OZDoHJZDJ88803eOCBB+Dm5oZWrVph69atlf6Zbtq0Ce3bt4dKpUKzZs3w0UcfGT2/bNkytGrVCi4uLggICMC4ceN0z/3vf/9Dx44d4erqioYNG2LQoEHIzc2tdF+IiOqdjCTg8h6gIBNIO2Pr3tQImw6BbdiwAXPmzMGyZcvQu3dvfPXVVxg+fDhOnz6Npk2bmrV3d3fHrFmz0KlTJ7i7u+PAgQN44okn4O7ujhkzZgAADh06hAkTJuDNN9/EAw88gC1btmD8+PE4cOAAevbsWSPXkV+sRvjrO2rk3OU5vWgo3JTl/xo//fRTnD9/Hh06dMCiRYsAAKdOnQIAvPTSS/jwww/RvHlzNGjQANeuXcOIESPw1ltvwcXFBatXr8bo0aNx7tw5yd+L1sKFC/H+++/jgw8+wNKlSzFx4kQkJibC19e3QtcUFxeH8ePHY8GCBZgwYQJiY2Px1FNPoWHDhpg6dSqOHj2KZ599Ft9//z2io6Nx584dXeCckpKCRx55BO+//z4eeOABZGdnY//+/VYHikREBOCiwZdeZxfb9aMGyQQbfjL07NkT3bp1w/Lly3XH2rVrh/vvvx+LFy+26hxjx46Fu7s7vv/+ewDAhAkTkJWVhe3bt+vaDBs2DD4+Pli3bp1V58zKyoK3tzcyMzPh5eVl9FxBQQGuXLmiy1oBQF5RSZ0PgADzGqA9e/ZgwIAB+PnnnzFmzJgyX9u+fXs8+eSTmDVrFgAxAzRnzhzMmTMHgJgBevXVV/Hmm28CAHJzc+Hp6Ylt27Zh2LBhZZ5b24+7d++iQYMGmDhxIm7duoWdO3fq2rz00kv4/fffcerUKWzevBn/+c9/cO3aNXh6ehqd69ixY4iIiMDVq1cRGhpa7s9E6vdJRFTv7V4M7H1XvP/IeqDNcNv2x0plfX6bslkGqKioCHFxcfjvf/9rdHzIkCGIjY216hzx8fGIjY3FW2+9pTt26NAhPPfcc0bthg4dWmbhb2FhIQoLC3WPs7KyrHp/LVdnBU4vGlqh11QXV2dFlc8RGRlp9Dg3NxcLFy7Eb7/9ptsmIj8/H0lJSWWep1OnTrr77u7u8PT0RFpaWoX7c+bMGbOArHfv3liyZAnUajUGDx6M0NBQNG/eHMOGDcOwYcN0Q2+dO3fGwIED0bFjRwwdOhRDhgzBuHHj4OPjU+F+EBHVWwUZ+vvrHgYe3wE07WWz7tQEm9UApaenQ61WIyAgwOh4QEAAUlNTy3xtSEgIVCoVIiMj8fTTT2P69Om651JTUyt8zsWLF8Pb21t3a9KkSYWuRSaTwU3pZJNbdaxkbDqb68UXX8SmTZvw9ttvY//+/UhISEDHjh1RVFRU5nlM99KSyWTQaDQV7o8gCGbXZZio9PT0xLFjx7Bu3ToEBQXh9ddfR+fOnZGRkQGFQoGYmBhs374d4eHhWLp0Kdq0aYMrV65UuB9ERPVWQabx48Nf2aYfNcjmRdBSH3Tlfajv378fR48exZdffoklS5aYDW1V9Jzz5s1DZmam7pacnFzBq7APSqXSqj2v9u/fj6lTp+KBBx5Ax44dERgYiKtXr9Z8B0uFh4fjwIEDRsdiY2PRunVrKBRixsvJyQmDBg3C+++/j3///RdXr17FX3/9BUD8/ffu3RsLFy5EfHw8lEpljRfCExE5lPwMW/egxtlsCMzPzw8KhcIsM5OWlmaWwTEVFhYGAOjYsSNu3ryJBQsW4JFHHgEABAYGVvicKpUKKpWqMpdhV5o1a4bDhw/j6tWr8PDwsJidadmyJTZv3ozRo0dDJpPhtddeq1Qmp7Kef/55dO/eHW+++SYmTJiAQ4cO4fPPP8eyZcsAAL/99hsuX76Mfv36wcfHB9u2bYNGo0GbNm1w+PBh/PnnnxgyZAj8/f1x+PBh3Lp1C+3atau1/hMR2T3TDBAcbyKJzTJASqUSERERiImJMToeExOD6Ohoq88jCIJR/U5UVJTZOXfu3FmhczqqF154AQqFAuHh4WjUqJHFmp5PPvkEPj4+iI6OxujRozF06FB069at1vrZrVs3/PTTT1i/fj06dOiA119/HYsWLcLUqVMBAA0aNMDmzZtx7733ol27dvjyyy+xbt06tG/fHl5eXti3bx9GjBiB1q1b49VXX8VHH32E4cPto4CPiKhOMAuAHI9NZ4Ft2LABkyZNwpdffomoqCisWLECX3/9NU6dOoXQ0FDMmzcP169fx5o1awAAX3zxBZo2bYq2bdsCENcFmjNnDp555hldIXRsbCz69euHt99+G2PGjMEvv/yCV199tULT4Cs6C4zsF3+fREQSPg4Hsq7rH4ffD4xfbbPuWMsuZoEB4pT127dvY9GiRUhJSUGHDh2wbds23fTllJQUoyyFRqPBvHnzcOXKFTg5OaFFixZ499138cQTT+jaREdHY/369Xj11Vfx2muvoUWLFtiwYUONrQFERETkcJgBqp+YAapeM2fOxA8//CD53GOPPYYvv/yylnukx98nEZEJjQZYZLJ0SPgYYPwa2/SnAuwmA0T1w6JFi/DCCy9IPlfeX1AiIqplQvmzhR0BAyCqcf7+/vD397d1N4iIyBqCxKxfBxwssvk6QERERFSHSAVADogBEBEREelJBkDMABEREZEjYwaIiIiI6h3WABEREVG9wwwQkbFmzZphyZIlVrWVyWT4+eefa7Q/RERUAxww2yOFARARERHpMQNERERE9Q4DILKaIABFuba5WZmq/Oqrr9C4cWNoNMZ/se+77z5MmTIFly5dwpgxYxAQEAAPDw90794du3btqrYf0YkTJ3DvvffC1dUVDRs2xIwZM5CTk6N7fs+ePejRowfc3d3RoEED9O7dG4mJiQCA48ePY8CAAfD09ISXlxciIiJw9OjRausbEREZqCdF0FwJujoU5wHvBNvmvV+5ASjdy2320EMP4dlnn8Xu3bsxcOBAAMDdu3exY8cO/Prrr8jJycGIESPw1ltvwcXFBatXr8bo0aNx7tw5NG3atEpdzMvLw7Bhw9CrVy/8888/SEtLw/Tp0zFr1iysWrUKJSUluP/++/F///d/WLduHYqKinDkyBHIZDIAwMSJE9G1a1csX74cCoUCCQkJcHZ2rlKfiIjIAqkA6NzvQE4a4OE4q/ozAKonfH19MWzYMKxdu1YXAG3cuBG+vr4YOHAgFAoFOnfurGv/1ltvYcuWLdi6dStmzZpVpff+8ccfkZ+fjzVr1sDdXQzWPv/8c4wePRrvvfcenJ2dkZmZiVGjRqFFixYAgHbt2ulen5SUhBdffBFt27YFALRq1apK/SEiojJYGgLbMhOYtLl2+1KDGABVB2c3MRNjq/e20sSJEzFjxgwsW7YMKpUKP/74Ix5++GEoFArk5uZi4cKF+O2333Djxg2UlJQgPz8fSUlJVe7imTNn0LlzZ13wAwC9e/eGRqPBuXPn0K9fP0ydOhVDhw7F4MGDMWjQIIwfPx5BQUEAgLlz52L69On4/vvvMWjQIDz00EO6QImIiKqZpQDoRnzt9qOGsQaoOshk4jCULW6lw0TWGD16NDQaDX7//XckJydj//79eOyxxwAAL774IjZt2oS3334b+/fvR0JCAjp27IiioqIq/3gEQdANZ5n/6MTjK1euxKFDhxAdHY0NGzagdevW+PvvvwEACxYswKlTpzBy5Ej89ddfCA8Px5YtW6rcLyIikmCxCNqx6oAYANUjrq6uGDt2LH788UesW7cOrVu3RkREBABg//79mDp1Kh544AF07NgRgYGBuHr1arW8b3h4OBISEpCbm6s7dvDgQcjlcrRu3Vp3rGvXrpg3bx5iY2PRoUMHrF27Vvdc69at8dxzz2Hnzp0YO3YsVq5cWS19IyIiE5YCII1jzQ5jAFTPTJw4Eb///ju+++47XfYHAFq2bInNmzcjISEBx48fx6OPPmo2Y6wq7+ni4oIpU6bg5MmT2L17N5555hlMmjQJAQEBuHLlCubNm4dDhw4hMTERO3fuxPnz59GuXTvk5+dj1qxZ2LNnDxITE3Hw4EH8888/RjVCRERUjSzN+HKw6fGsAapn7r33Xvj6+uLcuXN49NFHdcc/+eQTPP7444iOjoafnx9efvllZGVlVct7urm5YceOHZg9eza6d+8ONzc3PPjgg/j44491z589exarV6/G7du3ERQUhFmzZuGJJ55ASUkJbt++jcmTJ+PmzZvw8/PD2LFjsXDhwmrpGxERmbAU6DhYACQTBAec3F9FWVlZ8Pb2RmZmJry8vIyeKygowJUrVxAWFgYXFxcb9ZCqC3+fREQmbp0DvuhhftzJFXg1tfb7UwFlfX6b4hAYERER6dWTDBADIKqwH3/8ER4eHpK39u3b27p7RERUFfUkAGINEFXYfffdh549e0o+xxWaiYjsHAMgImmenp7w9PS0dTeIiKgmWAyA1LXbjxrGIbBKqq4p4mRbnANARGTCwTI9ljADVEFKpRJyuRw3btxAo0aNoFQqLa5yTHWbIAi4desWZDIZh+6IiLQYAJEUuVyOsLAwpKSk4MYNG+3/RdVGJpMhJCQECoXC1l0hIqob6klmnAFQJSiVSjRt2hQlJSVQqx1rTLS+cXZ2ZvBDRGSIGSAqi3bYhEMnRETkUOpJAMQiaCIiItJjAERERET1DgMgIiIiqncYABEREVG9wwCIiIiI6h0GQERERFTvMAAiIiKieqeeLITIAIiIiIj0mAEiIiKieocBEBEREdU7DICIiIio3mEARERERPUOAyAiIiKqd8oKgK4drb1+1DAGQERERPXdhV1AwlrxflkB0M5Xa6c/tcDJ1h0gIiIiG/vxQfHPJj3LXgfI2a12+lMLmAEiIiIiUc7NsjNA3iG115caxgCIiIiI9MosgnacVaJtHgAtW7YMYWFhcHFxQUREBPbv32+x7ebNmzF48GA0atQIXl5eiIqKwo4dO4zarFq1CjKZzOxWUFBQ05dCRERkf0yHvMoKgBxohphNA6ANGzZgzpw5mD9/PuLj49G3b18MHz4cSUlJku337duHwYMHY9u2bYiLi8OAAQMwevRoxMfHG7Xz8vJCSkqK0c3FxaU2LomIiMi+aNQGD2TlBECOkwGyaRH0xx9/jGnTpmH69OkAgCVLlmDHjh1Yvnw5Fi9ebNZ+yZIlRo/feecd/PLLL/j111/RtWtX3XGZTIbAwMAa7TsREZFDEAwCIFl5ARAzQFVWVFSEuLg4DBkyxOj4kCFDEBsba9U5NBoNsrOz4evra3Q8JycHoaGhCAkJwahRo8wyRKYKCwuRlZVldCMiIqoXjDJAqDcZIJsFQOnp6VCr1QgICDA6HhAQgNTUVKvO8dFHHyE3Nxfjx4/XHWvbti1WrVqFrVu3Yt26dXBxcUHv3r1x4cIFi+dZvHgxvL29dbcmTZpU7qKIiIjsjVCRAIgZoGojk8mMHguCYHZMyrp167BgwQJs2LAB/v7+uuO9evXCY489hs6dO6Nv37746aef0Lp1ayxdutTiuebNm4fMzEzdLTk5ufIXREREZE8qVAPkOAGQzWqA/Pz8oFAozLI9aWlpZlkhUxs2bMC0adOwceNGDBo0qMy2crkc3bt3LzMDpFKpoFKprO88ERGRozANasoa5nKgAMhmGSClUomIiAjExMQYHY+JiUF0dLTF161btw5Tp07F2rVrMXLkyHLfRxAEJCQkICgoqMp9JiIicjhGGSCh3qwDZNNZYHPnzsWkSZMQGRmJqKgorFixAklJSZg5cyYAcWjq+vXrWLNmDQAx+Jk8eTI+/fRT9OrVS5c9cnV1hbe3NwBg4cKF6NWrF1q1aoWsrCx89tlnSEhIwBdffGGbiyQiIqrLNCUG99UcAqsNEyZMwO3bt7Fo0SKkpKSgQ4cO2LZtG0JDQwEAKSkpRmsCffXVVygpKcHTTz+Np59+Wnd8ypQpWLVqFQAgIyMDM2bMQGpqKry9vdG1a1fs27cPPXr0qNVrIyIisguGRdCCpt4EQDJBcKA5bdUkKysL3t7eyMzMhJeXl627Q0REVHPuJgKfdhLvT/4FSD1hedf3tqOAh3+svb5VUEU+v20+C4yIiIhsyDADVO4QmOPkTBgAERER1Wcag4CnHg2BMQAiIiKqzyqUAWIARERERI5AU4EiaAeaBs8AiIiIqD4zmgWm5kKIREREVA/U03WAGAARERHVZ0ZF0AyAiIiIqD4wGgIrZysMToMnIiIih6DhLDAiIiKqb8yKoJkBIiIiIkdnTQbowW/FP5kBIiIiIodgTQZIodQ2qJUu1QYGQERERPXZ0ZX6+4JGephLJtM/7yAYABEREdVXmdeBM1v1jy0NgclKwwUGQERERGT3CrONH1vaCoMBEBERETkMuZPx43IzQKwBIiIiInsnVxg/trgZKmuAiIiIyGGYZHQsbYbKITAiIiJyGBqTgEajhuRUd+0sME6DJyIiIrtnuAaQ9rFkDZB2CIwBEBEREdk702BHY2kdIA6BERERkaPQmGaANJAeAmMARERERI7C6iEwToMnIiIiR2GaAdKoLdQ5cxo8EREROQrTjI5gaRYYh8CIiIjIUZgOgWm4DhARERE5kpJC4NZ542NmRdBC2TVAXAeIiIiI7MrK4cAX3YGzv+uPSRVBl7UQIjNAREREZFeux4l/xv+gP2a2DpClITAuhEhERESOwmwIjEXQRERE5OjMhsDK2w2eGSAiIiKyd6YBjeEQmGeQ/rgDZoCcbN0BIiIispGytsKIehoozgdaDmIARERERA6krHWAnFyA6GfE+zdPl7Z3nACIQ2BERET1lVQRtOQ6QDJtgxrvUm1hAERERFSvyPR3TYMdwyEwmUE7BxwCYwBERERUrxhkcUyHwE5uAkqKSh8wACIiIiJHpJEIaK7sE/+UGYQIugCo5rtUWxgAERER1SulmR11iT4DJFPony7JLz0mgxkHygBxFhgREVF9k3YG+LIP4O4vPm4xAMi8Btw6a9CIQ2BERETkSHYtADQlQPYN8bFMAQR3NW7DImgiIiJyLCbDW3IF4NLApIlhDRCnwRMREZG9M63vkckB1wamjYyfB5gBIiIiInsmEQC5eJscYwBEREREjsQ0AyQ1BMYMEBERETk0yQyQYYhQGgyZ7h5vx2weAC1btgxhYWFwcXFBREQE9u/fb7Ht5s2bMXjwYDRq1AheXl6IiorCjh07zNpt2rQJ4eHhUKlUCA8Px5YtW2ryEoiIiOyLWQ2QAnB2sdxGFwwJDhME2TQA2rBhA+bMmYP58+cjPj4effv2xfDhw5GUlCTZft++fRg8eDC2bduGuLg4DBgwAKNHj0Z8fLyuzaFDhzBhwgRMmjQJx48fx6RJkzB+/HgcPny4ti6LiIio7pLJIDkLzPSY1BAY4DABkEwQbHclPXv2RLdu3bB8+XLdsXbt2uH+++/H4sWLrTpH+/btMWHCBLz++usAgAkTJiArKwvbt2/XtRk2bBh8fHywbt06yXMUFhaisLBQ9zgrKwtNmjRBZmYmvLy8KnNpREREdcuC0iGuNiMBhRNw+hf9c10eAzo9BKwZoz/24LdAx3Hi/bw7wPth4v3Xbouvr4OysrLg7e1t1ee3zTJARUVFiIuLw5AhQ4yODxkyBLGxsVadQ6PRIDs7G76+vrpjhw4dMjvn0KFDyzzn4sWL4e3trbs1adKkAldCRERkb0yHwCSyQkZDYIbPOUYGyGYBUHp6OtRqNQICAoyOBwQEIDU11apzfPTRR8jNzcX48eN1x1JTUyt8znnz5iEzM1N3S05OrsCVEBER2RGZTHoWmNneX5aGwBxjJpjNc1gykx+4IAhmx6SsW7cOCxYswC+//AJ/f/8qnVOlUkGlUlWg10RERPZMoghaZpITkSyCBgOgqvLz84NCoTDLzKSlpZllcExt2LAB06ZNw8aNGzFo0CCj5wIDAyt1TiIionpBEKQzQGUVQRved5AiaJsNgSmVSkRERCAmJsboeExMDKKjoy2+bt26dZg6dSrWrl2LkSNHmj0fFRVlds6dO3eWeU4iIqJ6TSaX3h5D6j4zQFU3d+5cTJo0CZGRkYiKisKKFSuQlJSEmTNnAhBrc65fv441a9YAEIOfyZMn49NPP0WvXr10mR5XV1d4e4vV7bNnz0a/fv3w3nvvYcyYMfjll1+wa9cuHDhwwDYXSUREVJdIFjxLZIAcfAjMpusATZgwAUuWLMGiRYvQpUsX7Nu3D9u2bUNoaCgAICUlxWhNoK+++golJSV4+umnERQUpLvNnj1b1yY6Ohrr16/HypUr0alTJ6xatQobNmxAz549a/36iIiI6iSzITCJDBCLoGvWU089haeeekryuVWrVhk93rNnj1XnHDduHMaNG1fFnhERETkqqeEuToMnIiIiRya1FYbZLDBLNUAMgIiIiMgucR0gBkBERET1jVm2p7wiaMNp8AyAiIiIyB5JTXk3SwCZhgilDTgERkRERPZJYhZYmQshQh8QMQNEREREdsks1pGoAbKUEWIARERERPZJqgjawpCX7qF2CIwBEBEREdkjyW0vytgKw+gxa4CIiIjILkmtA1TGLDCAQ2BERETkYMrdDR4MgIiIiMjOme0F5lR+BojT4ImIiMi+SQVAZWyFYfiYGSAiIiKyS6bZHYUzyh8C4ywwIiIismumGSDn8ofA5ArxT4265rpVixgAERER1TeSwU15GaDSAEhgAERERER2SWIIzNK0dy1tBohDYERERGSXpGaBlbUbPKAPiDgERkRERPbJihogi0NgzAARERGRvZHJpGuAyi2CZgaIiIiI7JUgQLIGqNwhMGaAiIiIyJ6ZZXesGQLTLoTIDBARERHZG5kMkitBl5cB4jpAREREZNfMVoKW2AuM6wARERGRQ7NmLzA59wIjIiIieyZVA2T1OkAMgIiIiMguWTENnkNgRERE5FCs2Q2eRdBERETkUATB+LHkbvCmNUFcB4iIiIjsmmkAJDENXmqYDOAQGBEREdkp0wyQQmoWGDdDJSIiIkcmt2YdIO00eJPgyU4xACIiIqpvpGqALAU8ujYcAiMiIiK7JlEDVN5u8DLOAkNycjKuXbume3zkyBHMmTMHK1asqLaOERERUU2QSWSAFFa8jJuh4tFHH8Xu3bsBAKmpqRg8eDCOHDmCV155BYsWLarWDhIREVF1EmCWAZLJys8AyTkNHidPnkSPHj0AAD/99BM6dOiA2NhYrF27FqtWrarO/hEREVF1kypkLm8vMM4CA4qLi6FSqQAAu3btwn333QcAaNu2LVJSUqqvd0RERFTNZBayONauA1SPM0Dt27fHl19+if379yMmJgbDhg0DANy4cQMNGzas1g4SERFRdZPKAFm7GWo9zgC99957+Oqrr3DPPffgkUceQefOnQEAW7du1Q2NERERUV0kWFjLx9rNUB0jA+RUmRfdc889SE9PR1ZWFnx8fHTHZ8yYATc3t2rrHBEREdUEazJAXAfITH5+PgoLC3XBT2JiIpYsWYJz587B39+/WjtIRERE1UliGjxgxVYYXAcIY8aMwZo1awAAGRkZ6NmzJz766CPcf//9WL58ebV2kIiIiKpbZYbAuA4Qjh07hr59+wIA/ve//yEgIACJiYlYs2YNPvvss2rtIBEREVUzyQxQeUNg2gDIMWqAKhUA5eXlwdPTEwCwc+dOjB07FnK5HL169UJiYmK1dpCIiIiqm0EA5ORSesfarTDqcQDUsmVL/Pzzz0hOTsaOHTswZMgQAEBaWhq8vLyqtYNERERUzQwzQM6u4p/l7QbPImjg9ddfxwsvvIBmzZqhR48eiIqKAiBmg7p27Vqhcy1btgxhYWFwcXFBREQE9u/fb7FtSkoKHn30UbRp0wZyuRxz5swxa7Nq1SrIZDKzW0FBQYX6RURE5LgMM0ClAZDVGaB6HACNGzcOSUlJOHr0KHbs2KE7PnDgQHzyySdWn2fDhg2YM2cO5s+fj/j4ePTt2xfDhw9HUlKSZPvCwkI0atQI8+fP1609JMXLywspKSlGNxcXF4vtiYiI6hXDEiDn0s9Ha7fCcJAaoEqtAwQAgYGBCAwMxLVr1yCTydC4ceMKL4L48ccfY9q0aZg+fToAYMmSJdixYweWL1+OxYsXm7Vv1qwZPv30UwDAd999Z/G8MpkMgYGBFeoLERFR/WE4BFa6fp/ZEJgJDoEBGo0GixYtgre3N0JDQ9G0aVM0aNAAb775JjRWFkcVFRUhLi5OVz+kNWTIEMTGxlamWzo5OTkIDQ1FSEgIRo0ahfj4+DLbFxYWIisry+hGRETksKypAeJWGObmz5+Pzz//HO+++y7i4+Nx7NgxvPPOO1i6dClee+01q86Rnp4OtVqNgIAAo+MBAQFITU2tTLcAiBuyrlq1Clu3bsW6devg4uKC3r1748KFCxZfs3jxYnh7e+tuTZo0qfT7ExER1Wkyk81QtQGQeUPjhw62GWqlhsBWr16Nb775RrcLPAB07twZjRs3xlNPPYW3337b6nPJTCJMQRDMjlVEr1690KtXL93j3r17o1u3bli6dKnFNYrmzZuHuXPn6h5nZWUxCCIiIsckCJAugjbBGiBzd+7cQdu2bc2Ot23bFnfu3LHqHH5+flAoFGbZnrS0NLOsUFXI5XJ07969zAyQSqWCSqWqtvckIiKq06SGwExxFpi5zp074/PPPzc7/vnnn6NTp05WnUOpVCIiIgIxMTFGx2NiYhAdHV2ZbkkSBAEJCQkICgqqtnMSERHZLZkMkkXQ5g2NHzpYEXSlMkDvv/8+Ro4ciV27diEqKgoymQyxsbFITk7Gtm3brD7P3LlzMWnSJERGRiIqKgorVqxAUlISZs6cCUAcmrp+/bpu3zEASEhIACAWOt+6dQsJCQlQKpUIDw8HACxcuBC9evVCq1atkJWVhc8++wwJCQn44osvKnOpREREjscwA9R5gnQbB88AVSoA6t+/P86fP48vvvgCZ8+ehSAIGDt2LGbMmIEFCxbo9gkrz4QJE3D79m0sWrQIKSkp6NChA7Zt24bQ0FAA4sKHpmsCGS60GBcXh7Vr1yI0NBRXr14FIG7OOmPGDKSmpsLb2xtdu3bFvn37KjxFn4iIyHGVBkBdJwHN75FuYml3eAepAZIJgtSOaJVz/PhxdOvWDWq1fUeHWVlZ8Pb2RmZmJrf2ICIix7DAW/wzfIyYzTm1GRj2HtBrpnkbAJh/U79IIgAc+ATYtQDoMhG4f1mtdLmiKvL5XakaICIiIrJnpbmPsmZdO/gQGAMgIiKi+kY3+FPWsjOOXQTNAIiIiKjesSYDxHWAdMaOHVvm8xkZGVXpCxEREdUGa8p/HXwIrEIBkLe3d7nPT548uUodIiIioppmRQbIbAhMmwGqhwHQypUra6ofREREVFOMMj4y62qALGaAHGMIjDVARERE9YqgD4AqMgvMwTZDZQBERETk6MxqfqyZBWZC5lhDYAyAiIiIHJ6FIbAya4BMOFgRNAMgIiIiR1edGSBU2wYSNsUAiIiIqL6pVAbIsfYCYwBERETk8KqzBogZICIiIrIHpkFLZTJAutcyA0RERER2gRkgUwyAiIiI6htdBqgCYQCLoImIiMiuWJoFxiJoIiIiclwWaoAqNQTGAIiIiIjsgWEGSCZD5TJArAEiIiIieyUIlcsAgUNgREREZFeqowaIQ2BERERkT0yHwCozjMVZYERERGRfqmEhRM4CIyIiIvtWmVlg2gCIGSAiIiKyB9WxFQZngREREZF9qYatMDgLjIiIiOxKdWaAWARNRERE9okrQTMAIiIicnicBWaKARAREZGjs7QZaqUyQBwCIyIiInukywBVJAxgBoiIiIjsGrfCYABERETk6CzNAqvMEBhngREREZF9qI7NUDkERkRERPbELAOkDWIsBEBStUHcCoOIiIjsliCUPw1eppA45lizwJxs3QEiIiKqaQZBS/p5IO106QMLAZBcIgDiLDAiIiKyK4ZZG13wA8s10JJDYJwFRkRERHbF0rBVRWqAOAuMiIiIHEGFaoA4BEZERET2xGLhsqUaIA6BERERkd2zEADV41lgDICIiIgcXUUzQJJ7hHEIjIiIiByBpQyQ1DR4ZoCIiIjIvlTHLDBtWwZAREREZA8sZW0kh7osHOcssOq1bNkyhIWFwcXFBREREdi/f7/FtikpKXj00UfRpk0byOVyzJkzR7Ldpk2bEB4eDpVKhfDwcGzZsqWGek9ERGTHLBZBcxZYjdqwYQPmzJmD+fPnIz4+Hn379sXw4cORlJQk2b6wsBCNGjXC/Pnz0blzZ8k2hw4dwoQJEzBp0iQcP34ckyZNwvjx43H48OGavBQiIqI6rKLT4MvaCoNDYFX28ccfY9q0aZg+fTratWuHJUuWoEmTJli+fLlk+2bNmuHTTz/F5MmT4e3tLdlmyZIlGDx4MObNm4e2bdti3rx5GDhwIJYsWVKDV0JERFQH3b4E/PYccPeq9POVmgbPDFCVFBUVIS4uDkOGDDE6PmTIEMTGxlb6vIcOHTI759ChQ8s8Z2FhIbKysoxuREREdm/VKODod8AP4yw04BBYrUtPT4darUZAQIDR8YCAAKSmplb6vKmpqRU+5+LFi+Ht7a27NWnSpNLvT0REVGdk3xD/VBdKP1+hGiDOAqtWMpMfviAIZsdq+pzz5s1DZmam7pacnFyl9yciIrIPlVkHyDEyQE62emM/Pz8oFAqzzExaWppZBqciAgMDK3xOlUoFlUpV6fckIqJSBZmARg24+dq6J2QNzgKrfUqlEhEREYiJiTE6HhMTg+jo6EqfNyoqyuycO3furNI5iYjIChoN8G5T4P0woDjf1r0hq1RiKwzAIWaC2SwDBABz587FpEmTEBkZiaioKKxYsQJJSUmYOXMmAHFo6vr161izZo3uNQkJCQCAnJwc3Lp1CwkJCVAqlQgPDwcAzJ49G/369cN7772HMWPG4JdffsGuXbtw4MCBWr8+IqJ6pShbfz/nJuDTzGZdIStZqg4pawgMEAOgKpar2JpNA6AJEybg9u3bWLRoEVJSUtChQwds27YNoaGhAMSFD03XBOratavuflxcHNauXYvQ0FBcvXoVABAdHY3169fj1VdfxWuvvYYWLVpgw4YN6NmzZ61dFxFRvVRgMIPW0grDVLdYXB6orCJolA6D2ffv2KYBEAA89dRTeOqppySfW7VqldkxwYq027hx4zBunKUpf0REVCMKDQKgkiLb9YOspymWPl5eAOQAM8HsO3wjIqK6oyBTf7+kwHb9IOtpSqSPB0nstmA0BGb/hdA2zwAREZGDMBwCs7TuDNUtapMM0BP7gFNbgL7Pm7dlAERERCTBKAPEITC7oFEbPw7qLJ39AeBos8A4BEZERNWjkBkgu2NpCEyKg2WAGAAREVH1KMjQ32cGyD5YKoKWYlQYzQwQERGRiDVA9kdRgV0QzKbB2zcGQEREVD2K8/T3SxgA2YWWA61vyyEwIiIiCYYzihgA1X1jvpBe8dkiFkETERGZM5xRxCGwuq+iq3WbboVh5xgAERFR9TCcUcQi6LqvwgEQa4CIiIjMGc4oYgao7qtKAMRZYERERKWYAbIvldmwVvsaZoCIiIhKqQ0DIO4FVucxACIiIqoGhhkgDoHVfZUJgLQzwVgETUREVEpqCCwxFvhuGHD1oG36RJYxA0RERFQNTIug1SXAyuFA0iHg72W26xdJYwBERERUDQzXASopBPLv2q4vVL5KBUDamWAcAiMiIhIZ1QAVAyX5+scOkDFwOMwAERERVQPDrTDURUCxQQBUlFv7/aGyVSkAYgaIiIhIZJgB0pQYB0CGG6VS3cBZYERERNXAaC+wYuDMVv3jIgZAdY7Rys4VfI0DDIE52boDRETkIAxngV0/ClyM0T8u5hBYnVOhneBLsQaIiIjIhOEQmOkMsLtXgct7arM3VB7OAiMiIqoGhgGQlDVjaqcfZB3OAiMiIqoG6nICIKpbqlQEzQCIiIhIVF4GiOoWToMnIiKqBtYEQNfjar4fZB0OgREREVUDawKgr++t+X6QdapSBM0AiIiIqJS1Q2AOMHziECq1DpA2bLD/3yEDICIiqh6GW2GUpTCrZvtB1qlSBogBEBERkchSBsjNz/hxdmrN94XKJ6vEQoicBUZERGRAo4HFYZFh7xo/zrpR490hK3AWGBERURVpLAx/PbYJ6PSQ8bE7l4G/3ga+GQQUZNZ830haPZ8Fxr3AiIio6iwNfwV1NT8WuxS4e0W8n7AW6PVkzfWLLOMsMCIioiqSCoDkzoCbr3hf6ak/rg1+ACDvds32iyyrSgaIs8CIiIggvQ2GeyN9xmDWEeCxzeIxQ+nna75vJK2eD4ExAKpluYUluJKea+tuEBFVL6kMkFtD/X2vYKDlQMAnzLhN+oWa7RdZVpl1gDgLjCpj1+mbiHgrBi//719bd4WIqHppAyDDrIKLt3k7X5MAKCPJIWYU2SXOAqPa0r6xFwqKNThy9Q5SMvNt3R0iouqjnQWmUOmPqTzN2wV2Mn5clAPk3am5ftVXe98HPu9edhsOgVFtCfJ2RY9mYkHg/45es3FviIiqkUYt/qlw1h+TCoC6PKq/Ly+diJyRWHP9qq92v11+fVWlAqDSP5kBoop6pGcTAMDqQ4koKFbbuDdERNVEOwQmN1hdWCoAcvMFZh4EpsUAjSPEYwyAbENeiZWgtatHMwNEFTUqvCFaeAlIzynElvjrtu4OEVH10O4DJi8nAwQAgR2AJj3EwmgAyL5Zs30jaVUaArP/L/AMgGpTynE4fzMAyxr+BAD4et9laDT2n0YkItJngAzW17UUAGm5+4t/5jAAsonKBEDarJGGARBVRFEecOss2qT8gmEuJ3E5PRcHLqbbuldERFWn/UA0DIC8m5T9Gg9tAJRWM32islUqA6QdAmMARBURGgX0nAkAeM/5G3giD98dvFLOi4iI7IBuFpgTMPpToPOjQIcHy36NR4D4JzNA1cvaAmVmgKhWDXwN8AmDd3Ea5juvxZ5zt7D/wi1b94qIqGoMh8AipgIPLBeDobIwAKoZagsb05qqzEKInAZffZYtW4awsDC4uLggIiIC+/fvL7P93r17ERERARcXFzRv3hxffvml0fOrVq2CTCYzuxUUFNTkZVhP6Q6M+RwA8LDiL/SRn8BHO7kUPBHZOV0RdAX22OYQWM0osfLzrioZIAZAVbNhwwbMmTMH8+fPR3x8PPr27Yvhw4cjKSlJsv2VK1cwYsQI9O3bF/Hx8XjllVfw7LPPYtOmTUbtvLy8kJKSYnRzcXGpjUuyTrM+QI8ZAID3nL/GheQUXL6VY+NOERFVgVQNUHm0GaDcWw4xpFJnlBRa164qs8Ac4Pdl0wDo448/xrRp0zB9+nS0a9cOS5YsQZMmTbB8+XLJ9l9++SWaNm2KJUuWoF27dpg+fToef/xxfPjhh0btZDIZAgMDjW5lKSwsRFZWltGtxg18A2jQFI1l6XjG6Wf88Ld00EdEZBekZoGVx90PgEwsqOVq0NXH2gxQRX5XWiyCrrqioiLExcVhyJAhRseHDBmC2NhYydccOnTIrP3QoUNx9OhRFBfrxzxzcnIQGhqKkJAQjBo1CvHx8WX2ZfHixfD29tbdmjQpZ+ZCdVB5AMPfBwA8rtiGI0cPo6jE/lOKRGTnMpKA8zsq/jpNJYbAFM76DVNZB1R9rMkAdZoAOLtW/Nwsgq669PR0qNVqBAQEGB0PCAhAamqq5GtSU1Ml25eUlCA9XZxO3rZtW6xatQpbt27FunXr4OLigt69e+PCBcs7Ds+bNw+ZmZm6W3JychWvzkqth0FoORhKmRrPa1Yi7iq/ARHVe5nXgTVjKheEVIdlUcDa8cCFXRV7nTYDZLgVhjVYCF39rMkAtRleuXNzJejqIzOpQhcEwexYee0Nj/fq1QuPPfYYOnfujL59++Knn35C69atsXTpUovnVKlU8PLyMrrVCpkMsmHvogROGKA4jl82fodb2VaO3RKRYzrwMXB5jxiElBTV7nvfPCVuTgoAF3ZW7LW6GqAKbq/AQujqZ00AJK9goKp7HVeCrjI/Pz8oFAqzbE9aWppZlkcrMDBQsr2TkxMaNmwo+Rq5XI7u3buXmQGyKb+WSO/wOABgSv4ajFiyB+k5DIKI6q2sG/r7Bz6p3fdeHq2/X9EPuMrMAgP0GaD474HzFQy6SJo1AVBFM3VauiJoZoAqTalUIiIiAjExMUbHY2JiEB0dLfmaqKgos/Y7d+5EZGQknJ2lf5mCICAhIQFBQUHV0/EaEDhiHgoVHmgnT0ZU/j7EnGYqmKjeSjf4srbnHeD354FvhwIX/6zZ9zVdPO+fb4Bs6XIESboi6IoOgZVmgBIPAmsfAi79VbHXkzlLAZCnwedgZTZCBVgEXV3mzp2Lb775Bt999x3OnDmD5557DklJSZg5U1wted68eZg8ebKu/cyZM5GYmIi5c+fizJkz+O677/Dtt9/ihRde0LVZuHAhduzYgcuXLyMhIQHTpk1DQkKC7px1kpsvVP3nAACec9qIfWdvlN2eiBxTYixw2yRb/c83QPLfwK43gDO/WV7lNyMJUJdU/r2L88yPndho/esrMwsM0GeAtP6WngVMFWCpCNrNT3+/0kNgLIKuFhMmTMCSJUuwaNEidOnSBfv27cO2bdsQGhoKAEhJSTFaEygsLAzbtm3Dnj170KVLF7z55pv47LPP8OCD+uXWMzIyMGPGDLRr1w5DhgzB9evXsW/fPvTo0aPWr69Cej6JYlVDhMlvIvj6H7buDRHZwplfxT/9w82fSz0BbJgoZkpMHVsDLOkI/LnAeAitIgol1iKryNR0XQBU0RogkwDo9qWKvZ7MWcoAuRuUilRmCjzgUEXQlfwJVJ+nnnoKTz31lORzq1atMjvWv39/HDt2zOL5PvnkE3zySS2Pm1cHlQcKI6bDOfY93J+/BXFXn0FEM+m6JiJyUPl3xT87TQDCxwAbHgNunjRuow1wNBrgwEfAP98B2aXHYpcCh74A/rMdaNqrYu9dmK2/3/NJ4PBycYFCa1V6Fpi/8eOs62KWqzLbNJCo2FIA1Eh/v7I1QHIOgVENcO89A/mCEh3lV/HBiu+QmW/lfi5E5BjyM8Q/XRsAvmHAE/uA2f8at9n8f0D6RSDpEPDXW/rgR0vQAJtnAH+9DdxNtP69i0oDIM9gwL+teD/hR+DI10DamfJfX11DYCUFQN7tip2DjJXkSx83DIAqXQPElaCpBsjc/bBJ3RcAMF3xOzYeraX1iIiobijIEP90aSD+KVcAPqFA21HG7T6PADLL+P8hIxHY9z6w4xXr31ubAVJ5Au6lWRlBA2x7AVjWS8wupZ6w/PpKzwLzNz9W1rVR+YotBUDVUAPEzVCppoSOehEaQYZBinicOH7U1t0hotpkmAEy9PCPQLcpxse2PCH+2WYk8NwpoPt08/Nd2Qcc3wCsexS4tBu4Vsb/KdoaIJWHeVYGAHa+Kp7HksrsBQYArj5A+wfEIC+ku3hsxT1ANmfDVpphABTaW3/fJ0x/v6pDYA6QAbJ5DRAZ69srCvnnh8D18g50St2MrIIH4OVSyb+oRGQ/NGrgVulQkzYDZMjFwgKtDZsD3iHA8A+AwE7iN/TtLwPFuUBhFrBF3HgZ534X/3zpCuDma34e7QKIKk/Ay8KyIZlJ4uKMTkqJ/lcyAySTAQ+tEu8f+gK49o94/8RPQPQzFTsXibQz+jo/Coz5HDj7u/j79QnVt2ERNDNAdZFrT3FhxDGKgzh+tQJFiERkv2Je1983zQABgNJD+r42WyOXAxFTgG6TxNohS3LTpY8XZunP7RVs+fWWtqyobBG0IcMsV1ZK5c9T32kzQF7BYsYm/D6gy6MADArLKxsAsQiaalTLgchW+MBPloU7x7fZujdEVBsOfa6/L5UBUrrr748xaOvsZt62rADG0hRp3RBYaaZpzBfS7bItBCaVLYI2pPIABr8p3rd2BlpRLvC/acA/31b+fR2NNgNkutmprBoCIJnjDIExAKqLFM5IbDwSANAk6Rcbd4aIap1KYrjLMAAK7qq/79daoq0b4N1U+tyWCmSLcvWvBYCujwFzzwC9ngZGfgT4NhePWwqA1JVcB8iUNqN14iex7qi8LRf+Xgac/B/w+1y7356hoFiNTXHXqr4nZJE2AJIIjrUqvRVGaRDFDBDVlPzwCQCADrmxFVuMjIjsU0gP/Z9yif+aFQZ1Ny7ewNP/AOO+A8L6Sp/v0fXA6E+BR38yPi614jMAqIvM38crGBj2jlhgHdhRPGZpe4zKboVhysNgqnbs0vK3xji/Q3//ju0WUSxRWw6+/jiZit7v/oWjV8v+v3zJrgt4fuNxTPzm76p1RhvkmmaADFV5JWj7DjYBBkB1VmDrSJzRNIUSJdj7y3e27g4R1TR16bf+/i9JP2845KDyAhq1Bjo8KN0WAALaAxFTxcJoQ5YyQOUNYbmWFk5rF2us6Out5W4yLT5uJXBomXS/717VF00DQFIVA4dK+uvsTbR/Ywc2H7sm+fzMH+JwPSMf/7em7Jm9206I2bXzNyVW5a6IYgsZIMO/Q1XeC0wiADq3XSy4thMMgOqoxg1csVUtbgrrdHqz7rhgaR8gIqpb0i8Cm/5P/PAuyCq/vXb1XieV9PNCJT+8vIKA+w3217KUASqviFnbrz2LgQNLzK+psrPATJnWL539DdgxDzj8pXlb0w1i/91gea+0GvT4qqMoLNFg7k/Hy2yXU1j2Xm1Oimpa/dpSBkhj8P7VtRL03avicgvZqcC6h4H1j1Z+O5ZaxgCojpLLZWh2zyQAQJT8NIa+uRG//XsDEW/twg9/V2B1VztWotbgSnougz6yP4IA/PykWMeyYx7w23Plv0ZbnOxkYdhCam0ea3V5FGg1VLxvmkm5cxlIWKffQNPS0Ijh0NiuN4Df5hg/r80uKKoYALn5An0kfl5Jh82PaRdmbP+AOP3/6n5goQ+Q/I952zpAhrIDHCd5dQVA1mSAqqkI+otewOrRwK6F+jYXd1Xu3LWMAVAdNmFwH5xRtIFcJiCqYB9mrY3HndwivPrzSRy5cgfjvzyEi2lVTJXWosy8YtzJLdI9PnEtE6dv6L9FCoKAR1b8jUEf70VBsRpf7buMAR/uwU9cEZvszaktwLUj+sfntusLUy0pKScD1Hq4uC7OQ6sr1ydtNsA0AFreB/h5pjjUBFgOYEz7dfOU/v7tS/oP3apmgABg0ALghQvGxww38rx9SVw24PJu8XHbUUDvOaVPCsD3D1S9DzbgJFX7VRkWM0AG2ytVeSVoNZB7W7/txvG1+jaX91bu3LWMAVAdV9BW/Ic8WnHI6Pj4rw7hyNU7GPTxXiTdLuc/Vu25itW6bIpGIyCnsAT7zt+qlQyLWiNg9OcH0O3NGIz8bD++3HsJY744gBGf7cfx5AwAwN28Yhy6fBsX03JwLPEuPthxDgDw8qYylt+HGDidScnSFSFmFxRj6Z8XkJppYbov2ZW8ohJcu2vd33Gby04F0i8Avz8vPu7/MuDVWFyU8I+Xy36tdgjMUuGqXA4MeQtof3/l+qadRWY6BFaca/I+ljJAJgHQrbPiDvQHPwWWdhODPqB6AiBA3CKjy0T9Y8PJIDtfE9/37lXxcVBn47ZF2TYZCqsqZ4MhsKISy0XGao2ArIIy9oq0ZgisssGW9nWFOcCvz0q3uRFfuXPXMgZAdVyXoVOhgRwR8gsIkUmvi9Hvg924cDNb8jmtlMx89HlvN/6z6h+cupGJtq//gQ5v7MDk745g0W+nodFUz38WJWoNCkvUuJiWjeQ7+v9oU7MKkFT6+NSNLLy7/Sy0bznmi4OIS7yLK+n6/4gf/cY43Z1dUIxJ3x7GJzHnzd7v9xMpGP7pfjz303HEXkpHxwU78VHMeby0yXgTydWxV/H4qn8w5vMDeP6n49h4NBmXb4kZtOLS4KmoRINv9l/Gwl9P4d9rGfjjZAqS7+Th78u3kV3GfzgajYBVB6/gr7M3cfJ6pu4/rxK1BrGX0lFYok89SwWc1+7moahEgw92nMUfJy3MsqmEohINVsdeLffvhzXiEu/ifDWcp6JmrY1H/w/24Fxq1d9bEAQs/PUU3vvjbIVfl5pZUPaXhdNbgY/aAJ9HAvl3xA/lvs8DIz4AIAOOrREzQZboMkAuFeqb1XQZoHKCSYs1QBKrP2ckGS/gCFRfAASIaxGN+FC8bzj9/rzBz7FZX8CvFdCwBdB8gP74KX3tJADgRgKQKV2kXN3Ssgqw9M8LSMs2+RJmYYTryJU7uJ5hnJnLyCuSbgzgyR/i0P2tXbiRYaGg3eIQWDXM3NIOgZ38n1ifZahB6UrTdy6J2aE6jlth1HEyryAUNYmGKvkARssPYbn6Psl2r/58EuHBXlDIZBgXGQKNBmgX5IlXtpxEzOlUpOeI/5j2nLuFJj5uRt8uVh68ipUHr2LLU9Fo1tAdBSVqXEnPRbemPjh1IxPfHbiKB7o2xonrmfBydUbPMF+09PeAXCbD2sOJ2HUmDY/1aoqs/BK8v+Os7r0AoHWABy7fysXQDoFlXueDy2PRvZmPxecj3tqFohIN9l9Ix+DwAPi4K/HfTf/i8OU7KCoNXn49fgO/HtcX3+07fwt/nb2J0IbuyMgrxhtb9Sn749cysclkxoazQoZAbxck38nX/VykvDSsDUZ3CsbP8deRfDcPPm5KJN3Jw3aDwGVanzD0aemHH/5OxJ9n0+CmVGDWvS3xb3Imdp5ORWhDdwwOD4C3qzOS7+Rh/T/JcHVWIL9YDJS+mxqJYrWA9JxC9G/dCH9fvoNvD1zBIz2aIC7xLtoHe0EGGd7edgY9w3yxaEwH7DmXhrt5xejQ2Auz1orfwEIbuiHxdh7clQqMiwjBve0C0K+VHzYdu47vDlzBR+M74/u/ExF7MR1NfN0woXsTRLfwg4fKCT/HX0erAA8Eebvi+7+v4ovd4hRjN6UCA9sFYFxECC7czEZ4kBfWHkmCAKC5nztiL93GJ+O7oKGHEpn5xfj3Wgbe/+McLqfnopW/BzqGeGNcRAg6hzRAsVqDBm76D9bvDlxBQnIGnh3YEpO/PQJnJzkSSzOcb287gzfHtEdoQ3dkFxTjn6t34KFyRptAT6RmFkAjCGgb6InbuUXYfjIV97RuhCa+4gfAmZQszN9yAseSMnTv1TrAA839PLD3/C2MiwhBcAMxQBAEAYIg1uFtib+GLfE3MLCtP97YegpTo5vhjdHhkMkkPskMpmNrlJ74tdU7GCFzhnPbkUDU0+JCh9teEmtxTL99azT6WWA1HQCd2wYMKGOTVGszQJZYmiZfGTIZ0DjC+LzFBkFF50eAe+bh0q0c/Hr8BqaN3wjP1YOAlASxAN2vDRDYAbh5GljRH/AMAp6vWPBrSBAEvPbLSYT5eWBanzCL7f7v+zgcT87AgYvpeLSnhfWYSp1JycL4r8QMv1Kh/3txJ68I/l7mfxfUGgE7T4urcW89fgMz+7cwP6k1GaDKMi3Ad/UF7p0v7uPmHw581Q9IOw3EfgoMXlT196tBMoEVpmaysrLg7e2NzMxMeHlZ2H+nNsWtAn6djTT31uhxe0GVT+emVCCvyHwRK4VcBldnRbkzFarT9D5h+ObAlVp7P6p7JvZsisNX7uBKei7UVmQiW/l74IKVtW8TIpvA10OJr/ZeQlmnbtzAFbvm9kdqVgEe++YwUjLzMahdgO6DxtAT/Ztj3vB2AICsgmJk5RcjJGmrfnNS//Z4Lv9xbLkl7qe1+4V7EOYtB95vIQ43PbFPzA4ZKs4H3i79kjDvmrgfV3Xb/Q6w9z3x/ow9+sUUF3gbtxv5MdB9mvnrj35nXTH3qE+AyMdxNT0XR67cwdhujeGkqMJgQ/5d4IOW4of3f7aLP6sfxgJufsCLFwGZDK3nb0eRWoPHejXFW/29gJ8mASnHgeBuwO2L4rpJ2h3mH/0J2PGKODQ5fo30tiMWnD59Ej/++C3Wqwfg4uLRukC42X/1U793ze2PQR9L18ConOQ499Zwo2O7Tt/EdInp8f+bGYXIZuZ7tl1Jz8WAD/cAAP47vK15AKTRAItKv0y+cNF4XaXTW8WfDQAsyCzrUi2L/RzYOV+87+QKvHwVcDYI1I59D2ydJQZE042LoTUaAR/uPAe1RsB/h7eV/iJRRRX5/OYQmD1odx8gd4J/7nk80lz89jOoXQBeGxWOl4e1rfDp8orUaOSpQv/WjYyOq0vrgizp0qRBhd/LlJtSgT4t/QAAnionvDC0DX56Ikr3fKCXC356IgoX3x6Op+5pgacHtICbUv+No4Gb/tupv6cKnUv7pHKSw6f0uReHtim3H6EN3TAlKlTyue+n9cDYro2Njg23kMEK8LLyW7GB//RuhtGdy9iqwIDhtdcFjRuUsbBaJf14OAkX03KsCn4AWB38AMCGo8lYvkcMfsr6WV7PyEe71//AgA/34HpGPjQCJIMfAPjrTBpOXs/En2duYvrqoxj9/q/64AeA8Mg6XfADAC9uPC5+E2/eXzxgOnUbED+ktWoqA1RkUOtz67zldhaHwAz61W0KoDQJ0qb8Cgx7V8zKALjnwz14adO/2CAxicHwe3eJWoPE27lmbRb+egpTvjsCtaqBvr5n8xP6Yu0OY3WrEmuzwHGJGeKGn72eEtvcOCbucZZp0Ie148Wf95W9wPF10tcqRRDQYtt4vO38HSYpYpAr8SUSgMXgx5K8YunzFBSbD1cVFKuNJo6kSA2BGWx1UqJQYdzyWMz9KUE8UB1/twwzQAHtjYMfQL9iuMQCvmuPJGHZnkv4at9lXE43/53XNg6B2QM3X3Fs+2IM3mx5AeOHPYFWAZ7wUIm/vrjEO9h1Jg0AMLJjEJwVMqRkFiDQ2wVdmzTAn2fTsP+CfgPEbk0bYNnECDTyVGHOhgS4OSvg76XC0r8uSr59kLcL3hnbEfe0boT8YjVGLT2Ay7f0f3nfHNMei7efRV6RGnMGtcLM/i1QpNag04KdAIAFo8Ox4NfTAIB3HuiIyGY+2H4iFb2aN4SLswI9wnyxYUYvNG3ohiBv/QfsS6XB3YtD2+La3TwEeLlAEIAPd57DndwivHV/BwDAX2fT0NTXDT7uSsQl3sXoTkHYdiIFp25koX/rRgjxcUV2QQl83ZVoFeCBiFAftA300r3HxbQcjPniIIDSb+t+7mji4wZ3lRN6hPnCSS7D8I5B2H/hFv6z8h+E+bmjXZAXeoT5YkL3Jrh+Nx8b45IR3MAVn8RcQHqOOJThoXLCk/e0QHiQFzqFeGPqyn/QKcQb80e0g5NCjlkDWuK5DQm4npGPGf2a44+TqfDzUCIjvxhdm/igTaAHolv4YeiSfWjoocScga1x4nomnhvUGn9fuY3f/k3BudQsPDuwFZLv5KOhhxKHL9/RDe3d29YfC+9rj11nbuLHw0n4T+9m+HDHOdzNK0aPMF9M7xOGn44mo0gtYMWkCKic5FBrBBSpNfjvphPYevwG+rVuBGe5DGpBwCM9mmJoezEQ3H02DcevZeDBbiG4npGPlv4eWHMoEQnJGTibkoW07EJ0aOyFvCI1hrUPxItD2+DczWw8tPwQJkWFok8rP0z69ojFoGdSr1C8OqodTt/IwsnrmVj610U0cHNGeJAXArxccP5mNoZ1CESrAE+cT83G+Zs5aB/shS/3XsKFtBy0DvAwW0xu27N94eOuxP/iruHN38S/j25KBUZ3Cpb8kLbkQloORi09oHs8VH5ad/+A33ikXjL+Xnk08S6+2X8Z00N7i8NP1+OMT3jxTzGjAYj1FVXZTLQshkNTZU1Vt2YafEgk0KAJ8Ndb+mPBXYGwfmYvi714G75uSvRp5QdPF2f8cTIVL2w8jldHtsPDPZri2wNXsHj7WTzRrzliztzE5F6hmNo7TDcE3eKVbZg3YCqewGpxN/rMJPHE7ceavZdSW0TcYqBY/1JevdM/35QGc2VsGQEAGcnAlb1Q5VwHAExR7MArm/7FnMGt0byRh8WXyWUwyjwWltYY/qd3GG7nFMLfywX5RdJfOguK1biZVYDf/03BqM5B8HJxxoAP9yDFYHLH6kOJ8HVXYfagVvoXGszyO3q9AEcT7+Jo4l18PL4L0HIgED4Ghf6dUfGvbmLgmny3ALpBvYBw80ZulhfMNFwJ+3hyBlqU8bOrDRwCk1DnhsAAcZ2On2eK+/48fcRoU7uMvCIk38lHxxBvyZe+s+0MVuy7DAD4cXpPdG/mC6WT8X/SgiDg78t30LyRO/aev4WCYjWGdwjCzawCsd7E4P2uZ+Tj2/1XMDg8AIUlatzTRly59UZGPoK8XXRtT1zLRHZBMaJb+olFpFkFCPRyqZG0p6mMvCLkFqmtylgUlWgweukBuCgV2PJkNORVWIujoFiNEo2Av86moVNjbzTzcy//ReW4djcPLs4K+HmU/19WRl4RnlkXjyHhAZgU1czs+Qs3s5GZXyyZWjclCEKt/K6K1RrM23wCjRu44rnBEvtaQUydW/N7MezzoUu38cjXf0PlJMeheQPh6y5+gJeoNXjzt9O4nlGALyZ2hZNcjrWHE3HuZjaimvshNasAY7oE4/O/LuLIlTs4nWJ5EcOWsmvYpRJXbj4e+CDGXLW8MvPVJ32AlcMBz2Dg+TP6J1aNEtevAQBnd2B+DS0idyNBrIMBgNGfiTvHCwKwsIFxuwe/BTqOM3/9mV+BDY+J98d+LW5WukNbSyQDXr9jVNtkOCwEAAPaNMLK//TAQ1/G4p+r4ofjvwuGIPLNXboMjtaFt4ej1XzjgvGrAf/VBz8yhThUWBq4aN+rezMfbJwpLiCLjCRx7aDcNLEGqFlvcW0mAGgaJWaBcm+JRdY9/s/yz23/R8Cf5rUsX5eMwAeYjI/Hd9bV3JlycZZLZnLaB3vh1I0sfDslEkl38rDw19NmbbxcnJBVIAZHU6ObYXTnIDy4/JBZOwC4+u5I/YOMZGBJBxQKzviq3yF8XDpx5NI7I6CQy/DN/st4e9sZrJgUicHhFVtbakv8NcT970O85VyahRu6GIh6yrhRdqo4GUAmB168BBz9Fug2FfBohPFfirOXtde04L72FXp/a1Tk85sZIHvRdoRYhJh+Xpxi2Lib7qkGbkqjQlJTT/ZvgRPXMvFA18boXTr8ZEomkyGqhbjOxvjIJrrjjTzNP3QbN3DF66PNI/9gk2DDMCCTyWRG2Z2aJv5MrGurdJJjx3Pm31wrw8VZTA/fZ+UQlzVCfKy8EIjX/f20nhafbxVgfW1JbQQ/AOCskOPDhzqX2cbaoNSwz1EtGmL14z3QwNVZF/wAgJNCjoVjOhi9TipY1P7nXFCsxuilB+CqVKB9sDfWHSn9EIaAr50/0rXfXWg89NrS38NonS51QEcoACD7hjg8oP2mbPgd1HQ4oToFdwE6jBNn7xSV9kstMdPI0iwuwyJoJ5Vxga3Swyj4kZpVuvucOItVO8kAAK7cykXThm5m65lJ1SjC3U8XAGn8WkMukbUx+mLXoKl4M1RSACQeEmfnnftdDGwu7rIcAKWeMAt+4jStECG/gP9z2oYdhZGYtdbyzKpCC1PZT5UOY01bbXlrDG3wAwDX7uYbZX5MGX5BUBflQQEgH0qkZulfU1iihpvSCW/9LgbfH+08V+EAaFVsItobVs64SHzpdi2tPxI0wNoJ4npY148Bj6zDjUz97371oat4KDIE7YOlv7jXBtYA2QsXbyC8dAbYkRUVeqmPuxLrZvTC+O5Nym9M5ED6t26kqxMzciMeOPeHVedwcVbgjzn98MvTvfHmmPZ4fnBrtAnwxISQOwiTi3VC84qn4dMU4y8FQ0w+XA5fK0SRU2kAmptu8Iw+WMgXLH+RqRaq0iGHwtKAo0TiQ9WaafBOLsZTrE2KtjPzpZeMuJ6Rb/ShnHQnTzdkbChPaljIQ79H2PEMfaBYYFBD41xesXXk48CDXwP+bYGWg8Vjl/dIT4/PvQ182Uf/uPkA3A2IwtSil/FTiZhJW6t8G36wXEysjW3dlAqzrHtF3M0r0s2GlJJr8PPKyxGXi8iHCoUG2afCYo1RjWeIT8W/kOYXlUBtGDZIrVnlpBIzmYB+MdBz2yCsGoXcTHFqvBwavKFYhaU/2XbfMAZA9qTnTPHP4+uBqwfKbktE0kqKgBX3AOsmAKknrXqJQi6DTCaDk0KOZwa2wo7n+uHdCPGD5kKDPlinHgjB5L9T02zro98cxo2i0qAhXxwGyMwrRola/wF+w0JdaFGJxmJQUSHK0gCoqHRNpRLz4MOqafCmGSCVB9JzCvHHyRSUqDW4Y2ENm97vGu/sfi41Gxl55tcllQFKLtIPJ6cU6PuYZfBzUVQkaxnYURwKKykAfpllvnBi4kH9/Uc3ApN/xtH+q5ENN3yhHgO1IINSpsbXyo8wQB6PaPlJeCEXrWTXIIcGhoGtj5uynE0w9IK8zbOAt3MKcbWMouHcQrVuaZP8PPF3myeocCdX//stKFEbbaPkprR+AEi7yGxekRoawyuxtGinm/kQu+zqfuxxfhYHVc9gm3IepjrtxPtZ84yXNahlHAKzJyGR4myIhB+BnyYDIz8CGrYU09i3L4nfYm6dE1dodfEWZ0N4BoubCzZoKqa2826L0xO9go3qiHTUxTVXhFkXFRcAf70J5NwUfzbNBwBtR4qLqpHj2L1Y3CjzrsmSCxsmitmLB1ZIF3SWQVZaVBwYFg5ILH3TM8wX306JxJErd7D60FUUFGuQAQ8AN/H3yfPIz2+OGWuOYpPyLrT7tWfAA0m385BfrEabQH1WZdK3hxGflIHYefdaVQtmkTZTo80ASe2wbnErDMMMkCvgbBC4qDzxwLKDSL6Tj9dHhaOThXpEU0eums8UAoB5Equ/77sOaNd6zhFc8X9rjuKloW2M1h3LtzCjSpJMhr9azkP/6+OhuLxbrIV6Nh7wbY7luy9i0JEP0AoAWg4CWg8BoF+dOVEIxOfqBzDbaTO6yi9ipfIDFApOuCQ0RrhcDDISNC3wYNECqKGAr7vSaBsgAJg7uLWuPsdQmJ+7briria8rku/k4+rtPFwtIwP01b5LWHnwKp7o1xxZJxOwGEABlLiRoQ8ufjuegne369dAsjagfv+Ps1gdexW/PtMH+UVqaASDQN/SrDLXBsYz70p5y/LgjTxAJmaCdgU8jrE1OexbDgZA9mbEh0Dqv+LY9MapZbcta3kdt4bit0FBI6ayle7idNHbF8UxXI9AcRdpJxdx07u8dHGVT4VS3E/G2VX8T7QwG2jSU9xQsaQAcG8EuHiJuwOri8W09Z3L4vncfMXnCnPEoE1dJBZ1Kz2A2xfE9j7NxMBMEMRvp84u4p+Cxvjm7C4+59tCvBYnldhXJ5UYDN69Ip5f0IjncvUBGrURF+0K7iquKntxF/D3MuMpyJf+AmJeA7ybin2PmAo06yMuoKb9hyoI4pTiwixxR+zCLPHaZXL9t5ngLuJ0UefSn2t+BlCYKf6s5U7i667HAf+uF18XPkYMSjVqMQjLTAIatROvRxDEc9VSTY7DuXoQ2Puu9HParRTWPSyuKOzaQKwH8WlW/nlzxOEvT78QHH5lIG5lF0IQgE//vIAHS9e+GdguAAPbBaCgWI3VhxJxRxADkE0HT2DjPrHmTqMu0eXicwUXPPjBbrg6K/D3KwPh7eoMQRBw+IoYKOw8dbPchfXKpMsAaYfAqpAB0hhmgDx1tT1/nEpFcIOyP9TubeuPv86m4UjpdSmd5EaLs0oFRtkKH6D0MzsHrog5fRMxJksVWJqaLuVqei4e35aDBU79MNVJnLGKz7oCrYbgzKlWeFJZupJ801661xSVZutaB3jgk5vjIIcGzzj9DABQyUoQLtNnWLrIL+GkahpcZUXIv+OG/5O9jANiSIUtT0Wja1MfXEnPxZb460b9ala6mCgANGvoblQzZYl2xtxX+y5jqDwTUIpDYIYrRf9xyjhKtzYAWrZHXAD1k10XkGvNEBgAqIyLj28KDRAgy0C+oISrrAhXNQFYp74XTqEPWdWHmsIAyN4o3YDJW4EDn4gf1qX/CcOvDeAdIq7BEBAuBhkZSeIHvfbPkgLxP7zsFDHbkWdhqfL8u+Lt1hnj46bTd7UuSaxrYsowyDBUV3YNbj4ACOokFusl/a2fbnvdoEhR5SUuxlZSIAZW1emaxO7VMrn5+8gUpcGQXH8fMjEodVKJQaTKU+yrwlkfABZkiv9ZKZQABPGYoNHflzwGMeiSycX3kMn1GyFq0/va1wJi8FacJ35QaoM1jVoMkj0Dxdk4rr76IFpdIv48VZ5i/4DSa1OIBbVKDzGTqS4WN1wsKRQDTHWheK1KTzEolTuL76dRi3/m3REDeqWHGHymln6QhXQXFyD85xvzn3VGIpBQ+uF16HNxc02vYPHfUWiUOFSmdBeDao0a8G4sZpQAwCMQAV4uCChdtfebKZFmp2/pLwYedyH+6Qv9th6e0H+zz4H4gZJfrEbynTx4N/bGXYMhosISNQpL1Nh99hbuadNIV3RvNW0NUGbph26JVAbIUg2QYQDkIm6GqaUNrEqVla3o09IPU6Ob4a+zabpjLRp54EwZs+0AIEvRQHc/G9IfvNop5WlZ4vTvQe0CLNbe3CytRfq0ZCymBF+DLK10JtaFnfhMuVPfULtgJPQZoBAfN5y/mYOPSsZjqzoaC5xWo7fCYHPYUq4yMevjKuThM6cliChaCgFydG0qFgr7eRjXfA1tHwBPlf5jObgSE0dcIAa1+YIS2Qa1QcUmM+0SkjNQUKy2+u9QWlYBCoo10MitCIAMM0MNW+K+7PdwM0vsV5cmDZBQuv/ji6oarnkrBwMge+TmCwx5E8CblXt9cT6Qdkb80FF5iavTFuWKx10biMcKs8TpjNpZIoXZ4k3QiB9ixblA3l1xGqncSRwyUrqLxZ15t8Vsi3sj8TxeIWK7wmzxm6fKS/ygKs4T2xZkif+QPALE2gjth69CKWae3Pz0H4wyufjawizxwyn9vNjvkkLxfMV5YhDYsIWYbdF+eGcmi1sVqE2+8crkwH/+AJoazJwqzBZ3M45dKmavtBmeQpP/oGUKMaOl8hL7Lwil15UvfqAaUnmJHyB5t8UPi5JCcfiypEAcniwpFOsybl/Wb04pFWQJakBt4Vuuds2TohzjfZPqgtulH/jaQMdQbWwvFtYPeGSD+AVCuzy/k6v4+7q8Gzj4mX5nccB4jyPDXa6leJY/k6aRp/iBcLc0A9RIlqF7zkem/wHkQf/BMWrpAcwb3hb9DBYsXbHvsm7K9MiOQfhion42qFW0gUpSrPiFRiPxd8nSLDAnkwyQQY2L6Tf+K7cs16uM6RJsVufSwNUZj/ZsirWHkyy8Cjh+1xko/bzMEaQ/eHML1biekY93fj+D30+koH/rRlj9eA+L5wSAu/BC3rT9cC9ME7OFm6frnrvj0xm+LQbqHhepxWs23LLighCCt0smYptCXBJgYtE8HNR0RDtZIgbI4/GS808AAF/NXRxzfxZeskLg63aAwhkdGk5Dc1kGLgvB+PThLhjTpbHRsJini5PZbMLyaIOuApOVfqQ2V31n2xkcvJiOfq0b4Y3RZU9J12YhjTJAThYCIIPA6G6xk1F5lZPBjE5lVVYIrwYMgOojZ1ejafT1yu1LYtCjXf6+pFDMThhSeQLtRok3QAxs8u+KmQWFs/jtRuVRGmBZGJYqKQQgE4MZpae+rkIbJFmifS8XbzGIUajE4E/QiB9WgkYMgoweG9wUSv3QnKDWZ20UKjH4EzQGGR2Z+Z/a9to+CgaZIe1Ny+j1EF/n7GY+tdrZVQyAXbzFoFVQi1kbhbP4mvy74hClXFF6TYKYGSrKEQMmhXNpzYmL+LNXKPUBY3GBfqhToRTP7eorBvRFOeJ7y52B5vfoa1i0u6JrtbhXvGnU4s/8RoI4yeDmSTEALs4Tg/MmPcShzDO/wujD36Psfe4A/ZIQ2iGw6U7b8XnJ/ciFK3xl+g+3vzXtjF63ePtZtDaoBTKcCv37iRR8XtG1mgwDlaS/xUJgU1ZMgxcUSuP3ddGfVwbgcrr0B7ZSIUdkM1+zzIenixPeeaBjmQFQuqCvK8qxkAG6npFvVGi99/wtqDUCFBLLKBjO1M8rUsPdKxjo9BCE35+DrFAMSk90mof+BtepDSKUTnJM6hWK70uLik8LzTCzaA6CZLdxUCMusXBGCMUZdShWqEfh95a/oM21TfBRlw7tlWaWxyQdwlClM/oVLoGqNFPl4qwPCjxcnLB+Ri9EviVmygO9XIxm0Ulx1WaAYPwzNl1rCQDWHBL7f+lWrmQAJLVMoPEQmIWhToMA6GKGBvlyfaDdOtATRxPFdaD8K7GSfnViAET1S2WKm2UyMesmMbPBIu23ZdMdtMv7sNK+FyAOaTqMduU3sTW5QvyZe4fog18p2mzpV/3FoNJHeksVQ40buOLXWX3glxsArBMzAgkuTyDTrxtQOiP+9eIp2KTua/baf65IFwoDwOjPD2DTk9FQOZkPY2TmF2PB1lN4oGtjfRZJux0HIAaZEjNwBLkT1sReRccQb3Rrqt+guESQ6T4wVhxIwhMDDYrGO4wD9uqHtKSGwA7+9154KJ3g7WY+xCYVoJi6bRAA5QnWf3CmZhVILohqOH0+36B2SKP0gqI0AMpXGQe3hgHQwvvao08rP9zMKsDq2Kv445Z0pqkETjjW7mW0SfnNPAMNwEVWjL2q55CYvhTAw3Ax+F16ujjDx2CNtzA/d10A9Oy9LfGZxOr9rhC/gOSb/IxMh8CsIVVUHtTABdpR2+3nMjFcatkxgyGwfEGF7NI1jXqG+eLFIW3QIdgbR6/ewciOQRIvrj0MgIiIKkLpLt6e/lvMVlmqgzAhZoEigeHvA9vF1aO9048BANLkjXDYbxw6OstxJ7cI1+7qa3O0RahSTl7Pwosb/8XxaxkY0zkYM/q3wGPfHEZLfw8cT87AhbQcbIm/rlspODlLDUWriQi+8KOYjZOoATqclIU3toqZgegWDdG3VSO898dZuMiKcLb0M/Xj/al4YmQU8NgmwMkVQkgkgG0AxEzDrWzjD3qZTKx3MQzUDFdJtmYfOG39FAAoZeIHapsAT5y7WfYY6t+XbuPjmPOYHBWKJww2DjX8cDe8b9iTbIXx0J42AHJWyCGXy3Rbw0zqFYqwedss9qFZoB/w5EFg+8uSNZOusiK03fME8O/7GOLUBO5OwD5NJ3gqOxoFh96uzlg2sRtu5xRiUlQzpGQWYGOc8RpG2uFV0zqp/AoUiGtl5Ruvx9S4gSvGdQ4AShekfn7LeQyObG++2a3BGlH5BkNxnz3SFT7uSjzas2nVivmrCdcBIiKqDJWn0dCP1TqYb5fhH9wMO57rh62z+mDVf3ogxMcVvZpbl3HcevwGEm/n4bO/LuLTXeeRkJyB/8VdM9o09kxKFhZvO4O+7+/Gz2fEgKGkoHR2oomle/T1a7GXbuO9P8Sp0wWCEsMLF2N44WIUlg6v5DW9B9+nhuCWwWKG8Unm52zi42aWpfrz+Xt09y0FQE/dow9Y1DDPcv0yq7fk6ww9v/E4rmfkY7HBFHDAeK2hp9ceQ3xS6d5VGv2H/taT6bh0S/9z1M4CU5kUVksNQ97b1h+/P9sHHz3UWfxd+rUCJm0Gop8Rh4NHfAg8vA4IMBiGvHMJIWl7MMFpD75Qfobx2zoC3wzG804/QQ4N/L1UGNExSLdyubbwHgDcSzf7HeQmZoWGDR2NiFB9Bs9wuQDDYTbdtUnUCGUVGM8U83Z1RoC7/rUFUEqvUG0wNGY4FGfrmh9TzAAREdUmdz+g43jgxE/6YwZ1aC39PXDg5XsBAH+cTMXMH+LQuIErujZtgB2nUtG/tT+GhAfgxyNJOF46m0br6/3Sa18M/3S/7n6OIH44bT50Fn6hctxr0vbKHelFDAGxrsXQs+visetMGt4zCS5MSY1wGQ5LqUtrTTbM6IU/z6Zh9sBW2H8hHX1a+RllwL4pGY6HG17E6ZIBGNesccVnwRkwzPpcTMvBA8ti8dFDnXGfwSSD/RfSMfCjvboMWrG2CNqKVZ0LS9RoH+xtvtXDkLeAwW/qh8PbDBcXXYx5A7h5CsebPgaXi9vRRl6a2bl2BM84AT2Uieh62wP4phDoNgnwa4PezjexDDLcLz+AV3p5wzdyHOTLxH0fQ7oOxqa+/nji+6PYccp4uQB3pRMKio1/z3lFJVCaDNmbrl3k7eoMD2d9oKSBHIm389DE12RbEoMMkOFwZVVWw64JDICIiGrbmM/F2X/7PxQfN2wl2WxYh0CcWjgUMpn47TkzvxgNSxdCbBvkifs+PwhXZwWWTeyG/6wyX0ohtKGb2RYKuaVDI27Ix/mrSbjX5FOguDTTMrZbY2w+Jk6Xnz+iHd7ZfsZoNk9OYQl2nUnT3ZeiXezvlRFl14C1Kd2jrmfzhujZvKHu2k29VTIJvcb3wW8GGzQbbhpaEVK7sD+/8TiGuRXB0lKwuhogiUzGsPaBOJWSqVu3p1BiE1Qdw4yRTCauNfZ/4tBYs7xiPPndUHxatACNsvQrlffUxAPaGvHSLSaiAFzWJluOADjynni/caRu6xCpINFVqQBMJurlFqmN9k/UaARM/OawUZsGbs5QwfjnlnRHYskDgxogw9loDICIiOo7JxUw8DVxFlb+XaDzwxabuhusC9PQYBXoTiENsHZ6TzRv5IFAbxfMG94Wi7efRa/mvgjz84CzQoaF97XHvgvp+DjmPI4nZ2Du4NYIunoKSAZGKQ5LvR0im/sjNgV4blBrxF68jZzCEozpGozzN7ON6k2Gf7qvzEt8dWQ7PN47DA93bwJ/L+nZQpufisZvx1PwzEDpABAAxnZtjM0GiwW6KRVGQ0675vbHuZvZWB2biF1nbkqdQqdErdHVq+QXSQcoGnUxLO1bUWhQA2Rq+WPdoBGAFq9sM2pbUd5uzlg7azCA0r3KNBogbqW4f93NU8ANsW4MnsHixrpSDP4+uUgUyAd7uxrVmQFAnkkQ+3PCdbOhSVdnBWQmszyT70oEQIYZoNIASC4zngJfFzAAIiKylfb3V+nl0Qb7jT3RvwVGdgqCv6eL0Tft/q0boW9LP8QnZ6BziDeczrUFTHYpEDyDICtdO2rZpB6AizdkMhl+fro3itUa+Hu64MWhbdA+2Atp2YVYtudSmSsUPxQRgul9mwOAxeAHALo19TGaaSbl/XGd8HCPphj/lVh5qzLJaPh7ucDfywXbThivdPxQRIhZgbBhBi2vWDpr9K+mOXorThltTFus1sBZITeaBWZKJpNBIRPXZ/r9RApm9Gte5nVZTS4Huk/TP9YuGwEAhTnQbJwKQe4ExX1LxfWrXH2AdqN1zVUS9T4Lx7Q3GhYFjFfRFgQBH+0U1yN6cWgbfLDjHIDSbE+wcQCUIbHvm8ZJpSsw1s5GUzrJK7ZkQy2oW/koIiKqtBAfN8kPZ7lchohQHzH7ofIwe14Wol+9Wmawxk+gt4uuvsPfywVTe4fhpWFtMa1PmK796M7BZufr36aR2bHKclLI0b2ZDwa180dkqA+CLARUTXz1NUVjuzXGi0PbmLUxXFXbcJ8sQ88Xz8T6knvwQNEi3bHc0uyIdip5WUM5Sx7ugj+f7y/5c6kWrgYBo8oD8sf+B8Wj6wGPRkDkf8SgWq4PEoNNlgB4+4EOaN7IZC0sGGeAbucW4XpGPmQy4PHe+t9180buQJdHUSLIsUMt/p2R2sz23G2D3elLM0B1rQAaYAaIiKh+UXqaH2saVbrAIywvhGjgxaFtoBEEtA/2xriIEHwyvjNWxV7FW7+fQecQbwzvUL3ru8hkMnwzpXuZbSJD9bPmZvRrjkaeKvRq7oucwhLcyi7EzaxCZOaL2Yrley7h1+PSw0epaIj/lswwOpZTWIIGbsoyM0Bazgo5WjQyDzJtZXB4gNEmqEPCAyXXjTKcFafdQ8zfUwVXpQI75vTDuiNJeHpAS8BThU3DjuDlX8Ss0F2TDJBaIyCtQK5b+StREFdKV0q8p60xACIiqk+kpu63HSVuj+PsZr54p9QpnBVGKwc7KeSY3rc5pkQ3gyBYt7BhdTPcgb6Bq5jFWj8jCoIg4P5lsbiZVYjDV+6gSxMfLNllvgt7WaZ8dwTzR7bTbSiqqoPZDEtaNPLAjH7NkZVfjPkj28HTRbrEO9egKFybHQsq3YusTaAnFtyn/31PiGqFoIYNMPm7I2YZoMnfHYbz5RvoX/rX6JIgZsJMlw6oCxgAERHVJw1bAh0fErch6TZFXNTRJ1ScmVZFUsXBtcXFWYE1j/fA3bwiBBrsNSaTydCxsReOJ2fg/T/OYeXBqxYLlA1nvhm6dCsXj6/Sb4wc6G25rqkukpqF9/6DnXDuZjYSb+di15k0zNt8Aj/HX4eTQo7k0pldUitoazUoXdH7bGo25m0+geEdAtEjzBcHL97GA3L94pTXBHE4lAEQERHZllwBPPiNrXtRIww3jjU0vEMQfvhbnEOuXaV6SHgAXhnRDj7uSsReTEd8cgaeH9IaCpkMd/OKMG9EOwz8aK/k+aRqaOzN+O5NAAAv/+9fAOIQ2O5zt4zaBDewHOg1cNVnCtcdScKBi7ewYpJYF3RA0xElghwnhWa6BSzr2hR4gAEQERE5uOgWDbFgdDg+2nkezf090CXEG88ObKWbETa8YxCGl+5L9cFDncs9X7C3dduf2IN2QRI1YaUe7mF5uwrTPd2S7+Rj+wlxJuEtNEBE4ZdwcfcCiiwvHWBrDICIiMihyWQyTO0dhqkGM5oqSyGXQV7H1rOpinDTlapLNfF1LbOY28vFPHww3Jw1Ex5o06gBbuaKm/mWt2ebLTAAIiIiktCtaQMcK93brGeYLx7sFoJuoWWvW2RvOjT2gp+HCuk5xhvYjuvWpMzXyWQy/DCtJ7ILiuGucsLk746YtXlucGs88vXfAKT3GrM1BkBEREQSvp4ciQMX0zGsg/TUcUfgpnTCXy/0hwzA5Vu5SMsuxM2sAjxSxvCXVp9W+oU4Y57rh2/2X8GGo/pVNqNaNESbAM86mf0BAJkgCNLb8NZjWVlZ8Pb2RmZmJry8KrHbMxERUT2UfCcPk749jMd6hWJ63+a4dCsH01cfxZP3tMD4yLKzStWhIp/fDIAkMAAiIiKyPxX5/LZ5WfayZcsQFhYGFxcXREREYP/+/WW237t3LyIiIuDi4oLmzZvjyy+/NGuzadMmhIeHQ6VSITw8HFu2bKmp7hMREZEdsmkAtGHDBsyZMwfz589HfHw8+vbti+HDhyMpKUmy/ZUrVzBixAj07dsX8fHxeOWVV/Dss89i06ZNujaHDh3ChAkTMGnSJBw/fhyTJk3C+PHjcfiw9M7HREREVP/YdAisZ8+e6NatG5YvX6471q5dO9x///1YvHixWfuXX34ZW7duxZkzZ3THZs6ciePHj+PQIXGn4AkTJiArKwvbt2/XtRk2bBh8fHywbt06q/rFITAiIiL7YxdDYEVFRYiLi8OQIUOMjg8ZMgSxsbGSrzl06JBZ+6FDh+Lo0aMoLi4us42lcwJAYWEhsrKyjG5ERETkuGwWAKWnp0OtViMgIMDoeEBAAFJTUyVfk5qaKtm+pKQE6enpZbaxdE4AWLx4Mby9vXW3Jk1qvlKdiIiIbMfmRdAymfGKmoIgmB0rr73p8Yqec968ecjMzNTdkpOTLbYlIiIi+2ezhRD9/PygUCjMMjNpaWlmGRytwMBAyfZOTk5o2LBhmW0snRMAVCoVVCpVZS6DiIiI7JDNMkBKpRIRERGIiYkxOh4TE4Po6GjJ10RFRZm137lzJyIjI+Hs7FxmG0vnJCIiovrHplthzJ07F5MmTUJkZCSioqKwYsUKJCUlYebMmQDEoanr169jzZo1AMQZX59//jnmzp2L//u//8OhQ4fw7bffGs3umj17Nvr164f33nsPY8aMwS+//IJdu3bhwIEDNrlGIiIiqntsGgBNmDABt2/fxqJFi5CSkoIOHTpg27ZtCA0NBQCkpKQYrQkUFhaGbdu24bnnnsMXX3yB4OBgfPbZZ3jwwQd1baKjo7F+/Xq8+uqreO2119CiRQts2LABPXv2rPXrIyIiorqJW2FI4DpARERE9scu1gEiIiIishUGQERERFTvMAAiIiKiesemRdB1lbYsiltiEBER2Q/t57Y15c0MgCRkZ2cDALfEICIiskPZ2dnw9vYusw1ngUnQaDS4ceMGPD09y9xCozKysrLQpEkTJCcnO+QMM0e/PsDxr9HRrw9w/Gvk9dk/R7/Gmro+QRCQnZ2N4OBgyOVlV/kwAyRBLpcjJCSkRt/Dy8vLIf9Sazn69QGOf42Ofn2A418jr8/+Ofo11sT1lZf50WIRNBEREdU7DICIiIio3mEAVMtUKhXeeOMNh9193tGvD3D8a3T06wMc/xp5ffbP0a+xLlwfi6CJiIio3mEGiIiIiOodBkBERERU7zAAIiIionqHARARERHVOwyAatGyZcsQFhYGFxcXREREYP/+/bbuktX27duH0aNHIzg4GDKZDD///LPR84IgYMGCBQgODoarqyvuuecenDp1yqhNYWEhnnnmGfj5+cHd3R333Xcfrl27VotXIW3x4sXo3r07PD094e/vj/vvvx/nzp0zamPP1wcAy5cvR6dOnXSLjkVFRWH79u265+39+kwtXrwYMpkMc+bM0R2z92tcsGABZDKZ0S0wMFD3vL1fHwBcv34djz32GBo2bAg3Nzd06dIFcXFxuuft/RqbNWtm9juUyWR4+umnAdj/9ZWUlODVV19FWFgYXF1d0bx5cyxatAgajUbXpk5do0C1Yv369YKzs7Pw9ddfC6dPnxZmz54tuLu7C4mJibbumlW2bdsmzJ8/X9i0aZMAQNiyZYvR8++++67g6ekpbNq0SThx4oQwYcIEISgoSMjKytK1mTlzptC4cWMhJiZGOHbsmDBgwAChc+fOQklJSS1fjbGhQ4cKK1euFE6ePCkkJCQII0eOFJo2bSrk5OTo2tjz9QmCIGzdulX4/fffhXPnzgnnzp0TXnnlFcHZ2Vk4efKkIAj2f32Gjhw5IjRr1kzo1KmTMHv2bN1xe7/GN954Q2jfvr2QkpKiu6Wlpemet/fru3PnjhAaGipMnTpVOHz4sHDlyhVh165dwsWLF3Vt7P0a09LSjH5/MTExAgBh9+7dgiDY//W99dZbQsOGDYXffvtNuHLlirBx40bBw8NDWLJkia5NXbpGBkC1pEePHsLMmTONjrVt21b473//a6MeVZ5pAKTRaITAwEDh3Xff1R0rKCgQvL29hS+//FIQBEHIyMgQnJ2dhfXr1+vaXL9+XZDL5cIff/xRa323RlpamgBA2Lt3ryAIjnd9Wj4+PsI333zjUNeXnZ0ttGrVSoiJiRH69++vC4Ac4RrfeOMNoXPnzpLPOcL1vfzyy0KfPn0sPu8I12hq9uzZQosWLQSNRuMQ1zdy5Ejh8ccfNzo2duxY4bHHHhMEoe79DjkEVguKiooQFxeHIUOGGB0fMmQIYmNjbdSr6nPlyhWkpqYaXZ9KpUL//v111xcXF4fi4mKjNsHBwejQoUOd+xlkZmYCAHx9fQE43vWp1WqsX78eubm5iIqKcqjre/rppzFy5EgMGjTI6LijXOOFCxcQHByMsLAwPPzww7h8+TIAx7i+rVu3IjIyEg899BD8/f3RtWtXfP3117rnHeEaDRUVFeGHH37A448/DplM5hDX16dPH/z55584f/48AOD48eM4cOAARowYAaDu/Q65GWotSE9Ph1qtRkBAgNHxgIAApKam2qhX1Ud7DVLXl5iYqGujVCrh4+Nj1qYu/QwEQcDcuXPRp08fdOjQAYDjXN+JEycQFRWFgoICeHh4YMuWLQgPD9f9p2Lv17d+/XocO3YM//zzj9lzjvA77NmzJ9asWYPWrVvj5s2beOuttxAdHY1Tp045xPVdvnwZy5cvx9y5c/HKK6/gyJEjePbZZ6FSqTB58mSHuEZDP//8MzIyMjB16lQAjvF39OWXX0ZmZibatm0LhUIBtVqNt99+G4888giAuneNDIBqkUwmM3osCILZMXtWmeuraz+DWbNm4d9//8WBAwfMnrP362vTpg0SEhKQkZGBTZs2YcqUKdi7d6/ueXu+vuTkZMyePRs7d+6Ei4uLxXb2fI3Dhw/X3e/YsSOioqLQokULrF69Gr169QJg39en0WgQGRmJd955BwDQtWtXnDp1CsuXL8fkyZN17ez5Gg19++23GD58OIKDg42O2/P1bdiwAT/88APWrl2L9u3bIyEhAXPmzEFwcDCmTJmia1dXrpFDYLXAz88PCoXCLHpNS0szi4TtkXYmSlnXFxgYiKKiIty9e9diG1t75plnsHXrVuzevRshISG6445yfUqlEi1btkRkZCQWL16Mzp0749NPP3WI64uLi0NaWhoiIiLg5OQEJycn7N27F5999hmcnJx0fbTnazTl7u6Ojh074sKFCw7xOwwKCkJ4eLjRsXbt2iEpKQmA4/w7BIDExETs2rUL06dP1x1zhOt78cUX8d///hcPP/wwOnbsiEmTJuG5557D4sWLAdS9a2QAVAuUSiUiIiIQExNjdDwmJgbR0dE26lX1CQsLQ2BgoNH1FRUVYe/evbrri4iIgLOzs1GblJQUnDx50uY/A0EQMGvWLGzevBl//fUXwsLCjJ639+uzRBAEFBYWOsT1DRw4ECdOnEBCQoLuFhkZiYkTJyIhIQHNmze3+2s0VVhYiDNnziAoKMghfoe9e/c2W37i/PnzCA0NBeBY/w5XrlwJf39/jBw5UnfMEa4vLy8PcrlxWKFQKHTT4OvcNVZrSTVZpJ0G/+233wqnT58W5syZI7i7uwtXr161ddeskp2dLcTHxwvx8fECAOHjjz8W4uPjddP43333XcHb21vYvHmzcOLECeGRRx6RnNoYEhIi7Nq1Szh27Jhw77331onpm08++aTg7e0t7Nmzx2iKal5enq6NPV+fIAjCvHnzhH379glXrlwR/v33X+GVV14R5HK5sHPnTkEQ7P/6pBjOAhME+7/G559/XtizZ49w+fJl4e+//xZGjRoleHp66v4PsffrO3LkiODk5CS8/fbbwoULF4Qff/xRcHNzE3744QddG3u/RkEQBLVaLTRt2lR4+eWXzZ6z9+ubMmWK0LhxY900+M2bNwt+fn7CSy+9pGtTl66RAVAt+uKLL4TQ0FBBqVQK3bp1002ztge7d+8WAJjdpkyZIgiCOL3xjTfeEAIDAwWVSiX069dPOHHihNE58vPzhVmzZgm+vr6Cq6urMGrUKCEpKckGV2NM6roACCtXrtS1sefrEwRBePzxx3V/9xo1aiQMHDhQF/wIgv1fnxTTAMjer1G7Xoqzs7MQHBwsjB07Vjh16pTueXu/PkEQhF9//VXo0KGDoFKphLZt2worVqwwet4RrnHHjh0CAOHcuXNmz9n79WVlZQmzZ88WmjZtKri4uAjNmzcX5s+fLxQWFura1KVrlAmCIFRvTomIiIiobmMNEBEREdU7DICIiIio3mEARERERPUOAyAiIiKqdxgAERERUb3DAIiIiIjqHQZAREREVO8wACIiIqJ6hwEQEZEVZDIZfv75Z1t3g4iqCQMgIqrzpk6dCplMZnYbNmyYrbtGRHbKydYdICKyxrBhw7By5UqjYyqVyka9ISJ7xwwQEdkFlUqFwMBAo5uPjw8AcXhq+fLlGD58OFxdXREWFoaNGzcavf7EiRO499574erqioYNG2LGjBnIyckxavPdd9+hffv2UKlUCAoKwqxZs4yeT09PxwMPPAA3Nze0atUKW7durdmLJqIawwCIiBzCa6+9hgcffBDHjx/HY489hkceeQRnzpwBAOTl5WHYsGHw8fHBP//8g40bN2LXrl1GAc7y5cvx9NNPY8aMGThx4gS2bt2Kli1bGr3HwoULMX78ePz7778YMWIEJk6ciDt37tTqdRJRNan2/eWJiKrZlClTBIVCIbi7uxvdFi1aJAiCIAAQZs6cafSanj17Ck8++aQgCIKwYsUKwcfHR8jJydE9//vvvwtyuVxITU0VBEEQgoODhfnz51vsAwDh1Vdf1T3OyckRZDKZsH379mq7TiKqPawBIiK7MGDAACxfvtzomK+vr+5+VFSU0XNRUVFISEgAAJw5cwadO3eGu7u77vnevXtDo9Hg3LlzkMlkuHHjBgYOHFhmHzp16qS77+7uDk9PT6SlpVX2kojIhhgAEZFdcHd3NxuSKo9MJgMACIKguy/VxtXV1arzOTs7m71Wo9FUqE9EVDewBoiIHMLff/9t9rht27YAgPDwcCQkJCA3N1f3/MGDByGXy9G6dWt4enqiWbNm+PPPP2u1z0RkO8wAEZFdKCwsRGpqqtExJycn+Pn5AQA2btyIyMhI9OnTBz/++COOHDmCb7/9FgAwceJEvPHGG5gyZQoWLFiAW7du4ZlnnsGkSZMQEBAAAFiwYAFmzpwJf39/DB8+HNnZ2Th48CCeeeaZ2r1QIqoVDICIyC788ccfCAoKMjrWpk0bnD17FoA4Q2v9+vV46qmnEBgYiB9//BHh4eEAADc3N+zYsQOzZ89G9+7d4ebmhgcffBAff/yx7lxTpkxBQUEBPvnkE7zwwgvw8/PDuHHjau8CiahWyQRBEGzdCSKiqpDJZNiyZQvuv/9+W3eFiOwEa4CIiIio3mEARERERPUOa4CIyO5xJJ+IKooZICIiIqp3GAARERFRvcMAiIiIiOodBkBERERU7zAAIiIionqHARARERHVOwyAiIiIqN5hAERERET1zv8DAxlQhvgODPQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# history = np.DataFrame(columns=['index','train_loss', 'val_loss'])\n",
    "#画出训练过程中的loss变化曲线\n",
    "plt.plot(history['train_loss'], label='train_loss')\n",
    "plt.plot(history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''Prediction using the best model'''\n",
    "predict_labels_a=[]\n",
    "predict_labels_b=[]\n",
    "predict_labels_train=[]\n",
    "predict_labels_val = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predict_labels_a.append(model(input_test_a).data.numpy())\n",
    "    predict_labels_b.append(model(input_test_b).data.numpy())\n",
    "    \n",
    "    predict_labels_train.append(model(input_train).data.numpy())   \n",
    "    predict_labels_val.append(model(input_val).data.numpy())      \n",
    "\n",
    "\n",
    "actual_label_arr_train=np.round(np.asarray(train_labels*max_label).reshape(-1,1))  \n",
    "predict_label_arr_train=np.round(np.asarray(predict_labels_train).reshape(-1,1)*max_label)\n",
    "\n",
    "\n",
    "actual_label_arr_val=np.round(np.asarray(val_labels*max_label).reshape(-1,1))   \n",
    "predict_label_arr_val=np.round(np.asarray(predict_labels_val).reshape(-1,1)*max_label)\n",
    "\n",
    "\n",
    "actual_label_arr_a=np.round(np.asarray(test_cycle_life_a*max_label).reshape(-1,1))   \n",
    "predict_label_arr_a=np.round(np.asarray(predict_labels_a).reshape(-1,1)*max_label)\n",
    "\n",
    "\n",
    "actual_label_arr_b=np.round(np.asarray(test_cycle_life_b * max_label).reshape(-1,1))   \n",
    "predict_label_arr_b=np.round(np.asarray(predict_labels_b).reshape(-1,1)*max_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpe_train: 0.2556556\n",
      "mpe_val: 0.19783795\n",
      "mpe_a: 0.28725801268395584\n",
      "mpe_b: 0.18744038494426643\n",
      "rmse_train: 265.09766\n",
      "rmse_val: 217.82797\n",
      "rmse_a: 272.3585615443576\n",
      "rmse_b: 311.23013992863866\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGdCAYAAADjWSL8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABjuElEQVR4nO3dd3zV5d3/8dcZWZDksMySISpLQaayUVFRFAnEKoI3VetPiwQQQVtHW7W1Ym0NVTHRu+2tHSIqlSWI4sKE4YCEpQwVZEjCTE4CJ+Occ/3+OORAyA5JTsb7+XjkEXJynZPP+ebAeXNNizHGICIiItLIWANdgIiIiEhNKMSIiIhIo6QQIyIiIo2SQoyIiIg0SgoxIiIi0igpxIiIiEijpBAjIiIijZJCjIiIiDRK9kAXUFe8Xi8//fQTERERWCyWQJcjIiIiVWCMITc3l7i4OKzWivtammyI+emnn+jQoUOgyxAREZEa2LdvH+3bt6+wTZMNMREREYDvIkRGRga4GhEREakKp9NJhw4d/O/jFWmyIaZ4CCkyMlIhRkREpJGpylQQTewVERGRRkkhRkRERBolhRgRERFplBRiREREpFFSiBEREZFGSSFGREREGiWFGBEREWmUFGJERESkUVKIERERkUapWiFmzpw5XH755URERBAVFcW4cePYsWNHiTZ33XUXFoulxMegQYNKtCkoKGD69Om0a9eOli1bMnbsWPbv31+izfHjx5k8eTIOhwOHw8HkyZPJzs6u2bMUERGRJqdaIWb16tUkJiayfv16Vq1ahdvtZtSoUZw4caJEuxtuuIGDBw/6P1asWFHi+zNnzmTRokUsWLCAtLQ08vLyGDNmDB6Px99m0qRJZGRksHLlSlauXElGRgaTJ08+h6cqIiIiTYnFGGNqeufDhw8TFRXF6tWrGTFiBODricnOzmbx4sVl3icnJ4fzzjuPf//730yYMAE4feL0ihUruP766/n222+55JJLWL9+PQMHDgRg/fr1DB48mO3bt9OtW7dKa3M6nTgcDnJycnR2koiISCNRnffvc5oTk5OTA0CbNm1K3P7ZZ58RFRVF165duffeezl06JD/exs2bKCoqIhRo0b5b4uLi6Nnz56sXbsWgHXr1uFwOPwBBmDQoEE4HA5/m7MVFBTgdDpLfIiIiEjtyz5ZyC///TVrvjsS0DpqHGKMMcyaNYthw4bRs2dP/+2jR4/mjTfe4JNPPuH555/nq6++YuTIkRQUFACQmZlJcHAwrVu3LvF40dHRZGZm+ttERUWV+plRUVH+NmebM2eOf/6Mw+GgQ4cONX1qIiIiUo4NPx7nphfT+GBbFr9auJkijzdgtdhresdp06axefNm0tLSStxePEQE0LNnTwYMGECnTp1Yvnw5CQkJ5T6eMabEsdtlHcF9dpszPfroo8yaNcv/tdPpVJARERGpJV6v4W+pP/DnD3bg9houaNuCeZP6EWQL3ELnGoWY6dOns3TpUj7//HPat29fYdvY2Fg6derErl27AIiJiaGwsJDjx4+X6I05dOgQQ4YM8bfJysoq9ViHDx8mOjq6zJ8TEhJCSEhITZ6OiIiIVODYiUJmv53BpzsOA3Bz7zieGd+TiNCggNZVrfhkjGHatGm8++67fPLJJ3Tu3LnS+xw9epR9+/YRGxsLQP/+/QkKCmLVqlX+NgcPHmTr1q3+EDN48GBycnL48ssv/W2++OILcnJy/G1ERESk7n25+xg3vpDKpzsOE2K3MiehFy/e3ifgAQaquTpp6tSpzJ8/nyVLlpRYIeRwOAgLCyMvL48nn3ySW265hdjYWPbs2cNjjz3G3r17+fbbb4mIiADg/vvv57333uP111+nTZs2PPTQQxw9epQNGzZgs9kA39yan376iVdffRWA++67j06dOrFs2bIq1arVSSIiIjXn9RqSP/uOpFU78Rq48LyWvDypHz1i6/Y9tTrv39UKMeXNR3nttde46667cLlcjBs3jvT0dLKzs4mNjeXqq6/mD3/4Q4n5Kfn5+Tz88MPMnz8fl8vFNddcQ3Jycok2x44dY8aMGSxduhSAsWPHMm/ePFq1alWlWhViREREauZwbgGz3s4gdZdv9VFC3/P5w7ietAyp8VTaKquzENOYKMSIiIhU39rvj/DAggwO5xYQGmTl9/E9ubV/+3I7Mmpbdd6/6z5SiYiISIPn8Rpe+mQXL368C6+BLlHhJN/Rjy7REYEurVwKMSIiIs3cIWc+DyzIYN0PRwG4bUB7nhrbk7BgW4Arq5hCjIiISDOWuuswD76VwZG8QloE2/jj+J6M71vx9ikNhUKMiIhIM+T2ePnrR7t4+bPvMAa6x0Qwb1I/Lo4KD3RpVaYQIyIi0swczHHxwJsZfLnnGACTBnbkd2MuITSoYQ8fnU0hRkREpBn5dMchZr2VwfGTRYSH2JmT0Iube8cFuqwaUYgRERFpBoo8Xv7y4Q5eXf0DAD3Pj2TexH5c0K5lgCurOYUYERGRJu5Atovp8zeycW82AHcO7sRjN/UgxN64ho/OphAjIiLShK36JouH3tlEjquIiFA7z91yGaN7xQa6rFqhECMiItIEFbq9/Gnldv6RthuA3u0dzJvUjw5tWgS4stqjECMiItLE7Dt2kmnzN7Jpfw4A9wzrzK9v6E6w3RrgymqXQoyIiEgTsnLrQR5euJncfDeOsCD+cmtvrrskOtBl1QmFGBERkSagwO3hmeXf8s91PwLQr2MrXpzYl/atm87w0dkUYkRERBq5PUdOMO3NjWw94ATgl1deyEOjuhFka1rDR2dTiBEREWnElm36iUff3UJegZvWLYJIuq0PV3ePCnRZ9UIhRkREpBHKL/Lw+/e+Yf4XewG44oI2vDCxD7GOsABXVn8UYkRERBqZ7w/nkfjGRrZn5mKxQOJVFzPz2i7Ym/jw0dkUYkRERBqRRen7eXzRVk4WemgXHszcCX0Y3uW8QJcVEAoxIiIijYCr0MMTS7fy9tf7ARh8YVteuL0PUZGhAa4scBRiREREGrhdWblMfWMjuw7lYbHAA9d0YfrILtislkCXFlAKMSIiIg2UMYZ3Nuznd0u2kl/k5byIEF64vQ9DLmoX6NIaBIUYERGRBuhEgZvfLt7Ku+kHABjepR1Jt/XhvIiQAFfWcCjEiIiINDDfHnQybf5Gvj98AqsFZo/qxv1XXoS1mQ8fnU0hRkREpIEwxvDml/t4atk2CtxeYiJDeXFiX67o3CbQpTVICjEiIiINQG5+EY8t2sqyTT8BcFW380i6rQ9tWgYHuLKGSyFGREQkwLYeyGHa/I3sOXoSm9XCr67vxr3DL9TwUSUUYkRERALEGMO/1//I0+99S6HHy/mtwnhxYl/6d2od6NIaBYUYERGRAMhxFfHou5tZsSUTgGt7RPOXWy+jVQsNH1WVQoyIiEg927Qvm2lvbmTfMRdBNguPjO7BL4ZegMWi4aPqUIgRERGpJ8YY/m/NHp59/1uKPIb2rcN4eVI/endoFejSGiWFGBERkXqQfbKQhxduZtU3WQDccGkMf/rZZTjCggJcWeOlECMiIlLHNu49zvT56RzIdhFss/KbMT2YPKiTho/OkUKMiIhIHfF6DX9L/YE/f7ADt9fQqW0LXp7Uj57nOwJdWpOgECMiIlIHjp0o5KF3NvHJ9kMAjLksljkJvYgI1fBRbVGIERERqWVf7TnG9PnpZDrzCbZbefLmS5l4RQcNH9UyhRgREZFa4vUaUlZ/T9KqnXi8hgvPa8nLk/rRIzYy0KU1SQoxIiIiteBIXgEPvpVB6q4jAIzvez5Pj+tJyxC91dYVXVkREZFztO77ozywIJ1DuQWEBln5fXxPbu3fXsNHdUwhRkREpIY8XsNLn+zixY934TXQJSqcl+/oR9foiECX1iwoxIiIiNTAodx8Zi7IYO33RwG4tX97noq/lBbBemutL7rSIiIi1ZS26wgz30rnSF4hLYJtPD2uJwn92ge6rGZHIUZERKSK3B4vf/1oFy9/9h3GQPeYCOZN6sfFUeGBLq1ZUogRERGpgsycfGYsSOfL3ccAmDSwI78bcwmhQbYAV9Z8KcSIiIhU4rMdh5j19iaOnSgkPMTOMwm9GNs7LtBlNXsKMSIiIuUo8nh5/sOdvLL6ewAujYtk3qR+dG7XMsCVCSjEiIiIlOlAtosZb6az4cfjAPx8cCceu7GHho8aEIUYERGRs3z0TRaz39lEjquIiFA7z91yGaN7xQa6LDmLQoyIiMgphW4vz63czt/TdgPQu72Dlyb2o2PbFgGuTMqiECMiIgLsO3aSaW+ms2lfNgC/GNqZR0Z3J9huDWxhUi6FGBERafZWbj3Iwws3k5vvJjLUzl9u7c2oS2MCXZZUQiFGRESarQK3h2eWf8s/1/0IQN+OrXhpYl/at9bwUWOgECMiIs3SniMnmPbmRrYecALwyxEX8tD13QiyafiosVCIERGRZue9zT/xyH+3kFfgpnWLIJ6/rTcju0cHuiypJoUYERFpNvKLPPzhvW9444u9AFx+QWtenNiXWEdYgCuTmlCIERGRZuH7w3kkvrGR7Zm5WCww9aqLePDartg1fNRoKcSIiEiTtzj9AI8t2sLJQg9tWwYzd0IfRnQ9L9BlyTlSiBERkSbLVejhyaXbeOvrfQAMurANL97el6jI0ABXJrVBIUZERJqkXVm5JM7fyM6sPCwWmDGyCzOu6YLNagl0aVJLFGJERKTJeefrffxuyTZcRR7OiwjhhQl9GHJxu0CXJbWsWrOZ5syZw+WXX05ERARRUVGMGzeOHTt2lGhjjOHJJ58kLi6OsLAwrrrqKrZt21aiTUFBAdOnT6ddu3a0bNmSsWPHsn///hJtjh8/zuTJk3E4HDgcDiZPnkx2dnbNnqWIiDQLJwrczHo7g4cXbsZV5GHYxe1YMWO4AkwTVa0Qs3r1ahITE1m/fj2rVq3C7XYzatQoTpw44W/z3HPPkZSUxLx58/jqq6+IiYnhuuuuIzc3199m5syZLFq0iAULFpCWlkZeXh5jxozB4/H420yaNImMjAxWrlzJypUrycjIYPLkybXwlEVEpCnanulk7Lw03t14AKsFHhrVlX/94grOiwgJdGlSV8w5OHTokAHM6tWrjTHGeL1eExMTY5599ll/m/z8fONwOMwrr7xijDEmOzvbBAUFmQULFvjbHDhwwFitVrNy5UpjjDHffPONAcz69ev9bdatW2cAs3379irVlpOTYwCTk5NzLk9RREQaOK/Xa+Z/8aPp+vgK0+nX75kr/rjKrP/+SKDLkhqqzvv3OS2Oz8nJAaBNmzYA7N69m8zMTEaNGuVvExISwpVXXsnatWsB2LBhA0VFRSXaxMXF0bNnT3+bdevW4XA4GDhwoL/NoEGDcDgc/jZnKygowOl0lvgQEZGmLa/AzQMLMnj03S0UuL1c1e08VswYzsAL2wa6NKkHNQ4xxhhmzZrFsGHD6NmzJwCZmZkAREeX3Lo5Ojra/73MzEyCg4Np3bp1hW2ioqJK/cyoqCh/m7PNmTPHP3/G4XDQoUOHmj41ERFpBLYeyGHMi6ks3fQTNquFR0Z35//uvJy24Ro+ai5qHGKmTZvG5s2befPNN0t9z2IpuXzNGFPqtrOd3aas9hU9zqOPPkpOTo7/Y9++fVV5GiIi0sgYY/j3uj0kpKxlz9GTxDlCefuXg5hy5UVYtXy6WanREuvp06ezdOlSPv/8c9q3b++/PSYmBvD1pMTGxvpvP3TokL93JiYmhsLCQo4fP16iN+bQoUMMGTLE3yYrK6vUzz18+HCpXp5iISEhhIQofYuINGXO/CIe+e9mVmzx9cpf2yOKv9zam1YtggNcmQRCtXpijDFMmzaNd999l08++YTOnTuX+H7nzp2JiYlh1apV/tsKCwtZvXq1P6D079+foKCgEm0OHjzI1q1b/W0GDx5MTk4OX375pb/NF198QU5Ojr+NiIg0L5v3Z3PTi6ms2JJJkM3Cb27qwd9+PkABphmrVk9MYmIi8+fPZ8mSJURERPjnpzgcDsLCwrBYLMycOZNnnnmGLl260KVLF5555hlatGjBpEmT/G3vueceZs+eTdu2bWnTpg0PPfQQvXr14tprrwWgR48e3HDDDdx77728+uqrANx3332MGTOGbt261ebzFxGRBs4Yw2tr9jDn/W8p8hjatw5j3qR+9OnQKtClSYBVK8SkpKQAcNVVV5W4/bXXXuOuu+4C4Fe/+hUul4upU6dy/PhxBg4cyIcffkhERIS//dy5c7Hb7dx22224XC6uueYaXn/9dWw2m7/NG2+8wYwZM/yrmMaOHcu8efNq8hxFRKSRyjlZxMMLN/HhN74pBjdcGsOffnYZjrCgAFcmDYHFGGMCXURdcDqdOBwOcnJyiIyMDHQ5IiJSTRv3Hmf6/HQOZLsItll5/KYe/Hxwp0oXikjjVp33b52dJCIiDYrXa/h72g88t3IHbq+hU9sWzJvYj17tHYEuTRoYhRgREWkwjp8oZPY7m/hk+yEAxlwWy5yEXkSEavhISlOIERGRBuGrPceY8WY6B3PyCbZbeeLmS5h0RUcNH0m5FGJERCSgvF5DyurvSVq1E4/XcGG7lsyb1I9L4jSfUSqmECMiIgFzJK+AWW9v4vOdhwEY3/d8nh7Xk5YhenuSyulVIiIiAbH+h6PMeDOdQ7kFhAZZ+f3Yntw6oL2Gj6TKFGJERKReebyGeZ98xwsf78Rr4OKocJLv6EfX6IjK7yxyBoUYERGpN4dy85m5IIO13x8F4Nb+7Xkq/lJaBOvtSKpPrxoREakXabuOMPOtDI7kFRAWZOOP43uS0K995XcUKYdCjIiI1Cm3x8sLH+9i3qffYQx0j4lg3qR+XBwVHujSpJFTiBERkTqTmZPPjAXpfLn7GAATr+jAEzdfSmiQrZJ7ilROIUZEROrEZzsOMevtTRw7UUjLYBvPJPQivs/5gS5LmhCFGBERqVVFHi9Jq3aS8tn3AFwSG8nLd/Sjc7uWAa5MmhqFGBERqTU/ZbuY/mY6G348DsDPB3fisRt7aPhI6oRCjIiI1IqPv81i9jubyD5ZRESInT/97DJu7BUb6LKkCVOIERGRc1Lo9vLcyu38PW03AJe1dzBvYj86tm0R4MqkqVOIERGRGtt37CTT3kxn075sAH4xtDO/Ht2NELuGj6TuKcSIiEiNrNyaya8WbsKZ7yYy1M5fbu3NqEtjAl2WNCMKMSIiUi0Fbg9zVmzn9bV7AOjbsRUvTexL+9YaPpL6pRAjIiJV9uPRE0ybn86WAzkA3DfiQh6+vhtBNmuAK5PmSCFGRESqZPnmgzzy383kFrhp3SKI52/rzcju0YEuS5oxhRgREalQfpGHp5d/w3/W7wXg8gta8+LEvsQ6wgJcmTR3CjEiIlKuHw7nkTg/nW8POgGYetVFzLquK3YNH0kDoBAjIiJlWpJxgMfe3cKJQg9tWwaTNKEPV3Y9L9BlifgpxIiISAmuQg9PLdvGgq/2ATDowja8cHtfoiNDA1yZSEkKMSIi4vfdoVwS30hnR1YuFgtMH9mFB67pgs1qCXRpIqUoxIiICAALN+znt4u34iry0C48hBdv78OQi9sFuiyRcinEiIg0cycL3fxm8Vbe3XgAgGEXt2PuhD6cFxES4MpEKqYQIyLSjG3PdJL4xka+P3wCqwUevLYrU6++WMNH0igoxIiINEPGGN76ah9PLN1GgdtLdGQIL9zel0EXtg10aSJVphAjItLM5BW4eXzRFpZk/ATAlV3PI+m23rQN1/CRNC4KMSIizci2n3KYNj+d3UdOYLNaeGhUN3454kKsGj6SRkghRkSkGTDG8J8v9vKH976h0O0lzhHKS5P60r9Tm0CXJlJjCjEiIk2cM7+IR/+7heVbDgJwbY8o/vyz3rRuGRzgykTOjUKMiEgTtnl/NtPmp7P32EnsVguPjO7OPcM6Y7Fo+EgaP4UYEZEmyBjD62v38MyKbynyGM5vFca8SX3p27F1oEsTqTUKMSIiTUzOySIeXriJD7/JAuD6S6N57pbeOFoEBbgykdqlECMi0oSk7z3OtPnpHMh2EWyz8tiN3blzyAUaPpImSSFGRKQJMMbw99Td/GnldtxeQ8c2LXh5Uj96tXcEujSROqMQIyLSyB0/UchD72zi4+2HALjpsljmJPQiMlTDR9K0KcSIiDRiX+85xvQ30zmYk0+w3crvxlzCHQM7avhImgWFGBGRRsjrNbzy+fc8/+FOPF7Dhe1aMm9SPy6Jiwx0aSL1RiFGRKSROZpXwKy3N7F652EAxvWJ4+nxvQgP0T/p0rzoFS8i0ois/+EoDyxIJ8tZQGiQlafGXsptAzpo+EiaJYUYEZFGwOM1vPzpd/z1o514DVwcFc7Lk/rRLSYi0KWJBIxCjIhIA3coN58H38pgzXdHAfhZ//b8Pv5SWgTrn3Bp3vQ3QESkAVvz3REeWJDBkbwCwoJsPD2uJ7f0bx/oskQaBIUYEZEGyOM1vPDRTl769DuMgW7REbx8R18ujtLwkUgxhRgRkQYmy5nPjDfT+WL3MQAmXtGBJ26+lNAgW4ArE2lYFGJERBqQ1TsP8+BbGRw7UUjLYBvPJPQivs/5gS5LpEFSiBERaQDcHi/Pr9pJymffA3BJbCTzJvXlwvPCA1yZSMOlECMiEmA/ZbuY8WY6X/94HIDJgzrx+E09NHwkUgmFGBGRAPpkexaz3t5E9skiIkLsPHvLZdx0WWygyxJpFBRiREQCoMjj5bmV2/lb6m4Aep3vYN6kvnRq2zLAlYk0HgoxIiL1bN+xk0x/M52MfdkA3D30Ah4Z3Z0Qu4aPRKpDIUZEpB59sC2Th9/ZhDPfTWSonT/f2pvrL40JdFkijZJCjIhIPShwe5izYjuvr90DQJ8OrXhpYl86tGkR2MJEGjGFGBGROvbj0RNMm5/OlgM5ANw7vDMPX9+dYLs1wJWJNG4KMSIidWj55oM88t/N5Ba4adUiiOdv7c01PaIDXZZIk1Dt/wZ8/vnn3HzzzcTFxWGxWFi8eHGJ7991111YLJYSH4MGDSrRpqCggOnTp9OuXTtatmzJ2LFj2b9/f4k2x48fZ/LkyTgcDhwOB5MnTyY7O7vaT1BEJBDyizz8ZvEWEudvJLfAzYBOrVkxY7gCjEgtqnaIOXHiBL1792bevHnltrnhhhs4ePCg/2PFihUlvj9z5kwWLVrEggULSEtLIy8vjzFjxuDxePxtJk2aREZGBitXrmTlypVkZGQwefLk6pYrIlLvdh85QULyWv6zfi8AU6+6iDfvG0Rcq7AAVybStFR7OGn06NGMHj26wjYhISHExJQ92z4nJ4d//OMf/Pvf/+baa68F4D//+Q8dOnTgo48+4vrrr+fbb79l5cqVrF+/noEDBwLwt7/9jcGDB7Njxw66detW3bJFROrFkowDPPbuFk4UemjbMpikCX24sut5gS5LpEmqk1lln332GVFRUXTt2pV7772XQ4cO+b+3YcMGioqKGDVqlP+2uLg4evbsydq1awFYt24dDofDH2AABg0ahMPh8Lc5W0FBAU6ns8SHiEh9yS/y8Mh/N/PAggxOFHoY2LkNKx4YrgAjUodqfWLv6NGjufXWW+nUqRO7d+/mt7/9LSNHjmTDhg2EhISQmZlJcHAwrVu3LnG/6OhoMjMzAcjMzCQqKqrUY0dFRfnbnG3OnDk89dRTtf10REQq9d2hXBLfSGdHVi4WC0wf2YUZIy/GbtPqI5G6VOshZsKECf4/9+zZkwEDBtCpUyeWL19OQkJCufczxmCxWPxfn/nn8tqc6dFHH2XWrFn+r51OJx06dKjJUxARqbL/btjPbxZvxVXkoV14CC/c3oehF7cLdFkizUKdL7GOjY2lU6dO7Nq1C4CYmBgKCws5fvx4id6YQ4cOMWTIEH+brKysUo91+PBhoqPLntkfEhJCSEhIHTwDEZHSTha6+d2SbSzc4FtZOfTitsyd0IeoiNAAVybSfNR5X+fRo0fZt28fsbG+U1n79+9PUFAQq1at8rc5ePAgW7du9YeYwYMHk5OTw5dffulv88UXX5CTk+NvIyISKDsycxk7bw0LN+zHaoFZ13XlX78YqAAjUs+q3ROTl5fHd9995/969+7dZGRk0KZNG9q0acOTTz7JLbfcQmxsLHv27OGxxx6jXbt2jB8/HgCHw8E999zD7Nmzadu2LW3atOGhhx6iV69e/tVKPXr04IYbbuDee+/l1VdfBeC+++5jzJgxWpkkIgFjjOHtr/fxuyXbKHB7iY4M4YXb+zLowraBLk2kWap2iPn666+5+uqr/V8Xz0O58847SUlJYcuWLfzrX/8iOzub2NhYrr76at566y0iIiL895k7dy52u53bbrsNl8vFNddcw+uvv47NdvoE1zfeeIMZM2b4VzGNHTu2wr1pRETqUl6Bm98s2sLijJ8AGNH1PObe1pu24RrGFgkUizHGBLqIuuB0OnE4HOTk5BAZGRnockSkEfvmJyfT5m/khyMnsFktzB7VlSkjLsJqLXuhgYjUXHXev3V2kohIOYwxvPHFXn7/3jcUur3EOkJ5aWJfBlzQJtCliQgKMSIiZXLmF/Hou1tYvvkgANd0j+Ivt/amdcvgAFcmIsUUYkREzrJlfw7T3tzIj0dPYrdaeGR0d+4Z1rncfapEJDAUYkRETjHG8M+1e3hmxXYKPV7ObxXGvEl96duxdeV3FpF6pxAjIgLknCziV//dxAfbfBttjrokmj//rDeOFkEBrkxEyqMQIyLNXvre40x/M539x10E2Sw8dmMP7hpygYaPRBo4hRgRabaMMfwjbTfPvr8dt9fQsU0L5k3qy2XtWwW6NBGpAoUYEWmWjp8o5KF3NvHx9kMA3NQrljm39CIyVMNHIo2FQoyINDsbfjzG9Pnp/JSTT7Ddym/HXML/DOyo4SORRkYhRkSaDa/X8OrnP/CXD3fg8Ro6t2vJvEl9uTTOEejSRKQGFGJEpFk4mlfArLc3sXrnYQDi+8Txx/G9CA/RP4MijZX+9opIk/fFD0eZsSCdLGcBIXYrv4+/lNsGdNDwkUgjpxAjIk2Wx2tI/vQ75n60E6+Bi85rSfId/ekWExHo0kSkFijEiEiTdDi3gAffyiDtuyMA3NKvPX8YdyktgvXPnkhTob/NItLkrP3uCDMWZHAkr4CwIBt/GNeTn/VvH+iyRKSWKcSISJPh8Rpe+HgXL32yC2OgW3QE8yb1pUu0ho9EmiKFGBFpErKc+TywIJ31PxwD4PbLO/DEzZcSFmwLcGUiUlcUYkSk0Vu98zCz3srg6IlCWgbbeCahF/F9zg90WSJSxxRiRKTRcnu8JK3aSfJn3wPQIzaSlyf15cLzwgNcmYjUB4UYEWmUDua4mPFmOl/tOQ7A/wzqyG9uuoTQIA0fiTQXCjEi0uh8sj2L2W9v4vjJIiJC7My5pRdjLosLdFkiUs8UYkSk0SjyePnzBzv4389/AKDX+Q7mTepLp7YtA1yZiASCQoyINAr7j59k+pvppO/NBuCuIRfw6I3dCbFr+EikuVKIEZEG78NtmTz0ziac+W4iQ+0897Pe3NAzJtBliUiAKcSISINV6PYy5/1veW3NHgB6d2jFvIl96dCmRWALE5EGQSFGRBqkvUdPMu3NjWzenwPAvcM78/D13Qm2WwNcmYg0FAoxItLgrNhykF8v3ExugZtWLYL4y896c+0l0YEuS0QaGIUYEWkw8os8/HH5t/x7/Y8A9O/Umpcm9iWuVViAKxORhkghRkQahN1HTpD4xka+OegE4P6rLmLWdV0Jsmn4SETKphAjIgG3JOMAj727hROFHtq0DCbptt5c1S0q0GWJSAOnECMiAZNf5OGpZdt488t9AFzRuQ0v3t6XGEdogCsTkcZAIUZEAuK7Q3lMm7+R7Zm5WCww/eqLmXFNF+waPhKRKlKIEZF6998N+/nN4q24ijy0Cw/hrxP6MKxLu0CXJSKNjEKMiNSbk4VufrdkGws37AdgyEVt+evtfYiK0PCRiFSfQoyI1IudWbkkvrGRXYfysFpg5rVdSbz6YmxWS6BLE5FGSiFGROqUMYZ3vt7P75ZuJb/IS1RECC/c3pfBF7UNdGki0sgpxIhInckrcPObRVtYnPETAMO7tGPuhD60Cw8JcGUi0hQoxIhInfjmJyfT5m/khyMnsFktzB7VlSkjLsKq4SMRqSUKMSJSq4wxzP9yL08t+4ZCt5dYRygvTuzL5Re0CXRpItLEKMSISK3JzS/ikXe3sHzzQQBGdo/i+Vt707plcIArE5GmSCFGRGrF1gM5JM7fyI9HT2K3Wvj1Dd25Z1hnDR+JSJ1RiBGRc2KM4V/rfuSPy7+l0OPl/FZhvDSpL/06tg50aSLSxCnEiEiN5biK+PXCzazclgnAqEui+fPPeuNoERTgykSkOVCIEZEaydiXzbT5G9l/3EWQzcJjN/bgriEXYLFo+EhE6odCjIhUizGGf6Tt5k8rt1PkMXRs04J5k/pyWftWgS6t2XAVuXAWOIkMiSQsKCzQ5Uh1uVzgdEJkJITp93cudFysiFRZ9slC7v3X1zy9/FuKPIYbe8Xw3oxhCjD1JG1vGglvJRA+J5yY52MInxNOwlsJrNm7JtClSVWkpUFCAoSHQ0yM73NCAqzR76+mLMYYE+gi6oLT6cThcJCTk0NkZGSgyxFp9Db8eIzp89P5KSefYLuV3465hP8Z2FHDR/Uk5asUElckYrPacHvd/tvtVjser4fkm5KZMmBKACuUCqWkQGIi2GzgPv37w24HjweSk2GKfn9QvfdvhRgRqZDXa/jf1B/48wc78HgNndu1ZN6kvlwa5wh0ac1G2t40Rrw2AkP5/1xbsJB6dypDOw6tx8qaL5fLhdPpJDIykrDKhoTS0mDECKjo7dZigdRUGKrfX3XevzWcJCLlOppXwC/++RXPvr8dj9cwtnccy6YPU4CpZ0nrkrBZbRW2sVltzF0/t/wGLhdkZfk+S42lpaWRkJBAeHg4MTExhIeHk5CQwJqKhoSSknw9MBWx2WBuBb8/KZN6YkSkTF/8cJQZC9LJchYQYrfy1NhLmXB5Bw0f1TNXkYvwOeF4jbfStlaLlbxH80pO9k1L872JLlkCXi9YrRAfD7Nn183/+pvwpNWUlBQSExOx2Wy4zxgSstvteDwekpOTmXL2kJDL5Zv74q3894fVCnl5Te66VZd6YkSkQq4iF1l5WbiKSv+v3Os1zPtkFxP/tp4sZwEXndeSJdOGcvsVmv8SCM4CZ5UCDIDXeHEWOE/fkJLiG8ZYtuz0m6jX6/t6+HB45ZXaK7SJT1pNS0sjMTERY0yJAAPgdrsxxjB16tTSPTJOZ9UCDPjaOZ2VtxM/hRiRZqSy1S2Hcwu487Uv+cuHO/EaSOh3PkunDaN7jHozAyUyJBKrpWr/VFstViJDTv2u0tJ8E0mNKTmRFHxfGwNTp9ZOyKjPsBQgSUlJ2EoMCYUCUac++9hsNuaePSQUGenrYakKq9XXXqpMIUakmUj5KoURr41g2c5l/v/Ze42XZTuXMfy14Tyy4jVufDGV1F1HCAuy8eefXUbSbX1oGaLtpAIpLCiM+G7x2K0V/x7sVjvju48/PZRUX/Mw6jMsBYjL5WLJkiWnemCGAguBPCDr1OeFwBDcbjeLFi3Cdea8o7Aw3/CdvZK/R3Y7jB/f7IeSqkshRqQZSNubRuKKRAymxPJcALfHS2TRRN78vB2HcwvoGh3O0mlDuXVAhwBVK2ebNXgWHq+nwjYer4cHBz3o+8Ll8s2BOTtUnM3thkWLzm2ybzOYtOp0OvF6vcAU4HNgLFD8nG2nvk4FfonX68V59pDQrFm+ZdQV8XjgwQdrt/BmQCFGpBkob3WLzbQhuvBpWrknYcFKu7Y7WZI4jC7REQGoUsozrOMwkm9KxoKlVI+M3WrHgoXkm5JPL6+ur3kY9RmWAigyMhKLZTjwMr63zbPPBgs6dXsyFsuw0pNRhw3z7QNjsZTukbHbfbcnJ2t5dQ0oxIg0ca4iF0t2LCnVAxPq6Uts/ouEei/Di4sjQX8h3fUQWAoDVGnD4nK5yMrKKjk0EEBTBkwh9e5U4rvF++fIWC1W4rvFk3p3asmN7uprHkYzmbQaFhZGTMxzQCW9KXiIjX2u7H1jpkzx7QMTH3/6d1O8Uiw1VRvd1ZAGu0WauFKrW4yVVu47iHTfigUrhZYfOBz8LG7rT2B87ZvzeTxpaWkkJSWxZMkSvF4vVquV+Ph4Zs+ezdAA/095aMehDO04tPKzk4rnYSxbVnEvid3ua1fTeRjFYamqy4cb6aRV3xY7A4HKVucFkZk5CJernEs6dKjvowkvQ69v6okRaeLOXN1iM22JLpyDwz0BC1ZybSvIDHnIF2A4a3VLM5SSksKIESNYtmzZqTkQ4PV6WbZsGcOHD+eVBrLKJiwojOjw6IrDZn3Mw2gmk1Z9HU5V217A67VU3uEUFgbR0Y32ejQkCjEi9SkAu6YWr25p6R14avjoUryc5HDQsxwLTsacGj4qtbqlmSm9D8jpJbQV7gPSUNXXPIxmMGlVq6QbrmqHmM8//5ybb76ZuLg4LBYLixcvLvF9YwxPPvkkcXFxhIWFcdVVV7Ft27YSbQoKCpg+fTrt2rWjZcuWjB07lv3795doc/z4cSZPnozD4cDhcDB58mSys7Or/QRFGoQAbgRW5PESa+6nXcFvseGgwPIdB0NmcNKeVqJdidUtzdDpfUDKX0Jb5j4gDVl9zMNoBpNWm0mHU6NU7RBz4sQJevfuzbx588r8/nPPPUdSUhLz5s3jq6++IiYmhuuuu47c3Fx/m5kzZ7Jo0SIWLFhAWloaeXl5jBkzBs8ZaX7SpElkZGSwcuVKVq5cSUZGBpMnT67BUxQJsABuBLb/+Elue3UdyzN8vS25tmUcCXsEtzXT36bM1S3NzOl9QP4fFS2hdbvvKb0PSEM3dCgsXOjbzj4z0/d54cLaDRXNYNJqM+hwapzMOQDMokWL/F97vV4TExNjnn32Wf9t+fn5xuFwmFdeecUYY0x2drYJCgoyCxYs8Lc5cOCAsVqtZuXKlcYYY7755hsDmPXr1/vbrFu3zgBm+/btVaotJyfHACYnJ+dcnqLIuUlNNcZiMca35VfZHxaLMWlptf6jP9h60Fz25Aem06/fMz2fWGne3/KTSfsxzdzy1i3G+pTV8CTG+pTV3PLWLSbtx9r/+Y1JZmamgaEGPBX+qnzfH2IyMzMDXXLDdfKkMZmZvs9NTEqK76+r3V7ydWG3+25PSQl0hU1Ddd6/a3V10u7du8nMzGTUqFH+20JCQrjyyitZu3Ytv/zlL9mwYQNFRUUl2sTFxdGzZ0/Wrl3L9ddfz7p163A4HAwcONDfZtCgQTgcDtauXUu3bt1K/eyCggIKCgr8X5fabEgkEIo3AqtohUjxRmC19D/jQreXZ9/fzv+t2Q1A7w6tmDexLx3atABiq7a6pZnx7esxC98S2oo6qD3ALB0qW5GwsCY7njJlCvTq5fvrumhRyfM0H3ywUY+YNVq1GmIyM31d1NHR0SVuj46O5scff/S3CQ4OpnXr1qXaFN8/MzOTqKioUo8fFRXlb3O2OXPm8NRTT53zcxCpNcUbgVW2/PTMjcDO8R//fcdOMm3+RjbtzwHg/w3rzK9u6E6wveQbc1hQWKnw4nK5cDqdREZGlr3PRZMWBoyj8hH2IGB8FdpJU6VV0g1LnfxNPPukW2NMpaffnt2mrPYVPc6jjz5KTk6O/2Pfvn01qFykFtXzRmDvbznIjS+msml/Do6wIP7+8wH8ZswlpQLM2dLS0khISCA8PJyYmBjCw8NJSEhoPKtwaoHv0lf1n0NrY92zTWqRVkk3DLUaYmJiYgBK9ZYcOnTI3zsTExNDYWEhx48fr7BNVlZWqcc/fPhwqV6eYiEhIURGRpb4EAmoelqXmV/k4XdLtnL/GxvJzXfTv1NrVjwwnGsvKfvvypkay74odU1LaEUap1oNMZ07dyYmJoZVq1b5byssLGT16tUMGTIEgP79+xMUFFSizcGDB9m6dau/zeDBg8nJyeHLL7/0t/niiy/IycnxtxFp8OphXebuIye4JWUt/1rnG66dcuVFLLhvEOe3qvyxSu+Lclqj3BflHGgJrUjjVO0Qk5eXR0ZGBhkZGYBvMm9GRgZ79+7FYrEwc+ZMnnnmGRYtWsTWrVu56667aNGiBZMmTQLA4XBwzz33MHv2bD7++GPS09P5n//5H3r16sW1114LQI8ePbjhhhu49957Wb9+PevXr+fee+9lzJgxZU7qFWmwqrIu0+2Gw4ervWfM0k0/cfNLaWz7yUmblsG8fvflPDK6O0G2qv21Pr0vSvka3b4o50BLaEUaoeouffr0008NUOrjzjvvNMb4llk/8cQTJiYmxoSEhJgRI0aYLVu2lHgMl8tlpk2bZtq0aWPCwsLMmDFjzN69e0u0OXr0qLnjjjtMRESEiYiIMHfccYc5fvx4levUEmtpMMpbl1nDNZquQrd55L+bTadfv2c6/fo9c+sra83BbFe1Sjp58qSxWq1n/T0ONRB16vPp261WqznZBJfLlqUxLKE9WXjSZOZmmpOFzeN3Is1Pdd6/LcYYE5D0VMecTicOh4OcnBzNj5HAW7MGHn8cVq+uuJ3F4tscrJy1mt8dymPa/I1sz8zFYoFpV1/MA9d0wV7F3pdiWVlZ/jlsvh1qH8S3OseGbxnxYiAJWAv45rmVNx+tqVmzpvQS2vHjA7+ENm1vGknrkliyYwle4/WfYD178Oxmu0mhNE3Vef9WiBGpLwkJsHRpxWMWxacKL1xY6lvvbtzPbxZv5WShh3bhwfx1Ql+GdWlXo1JcLhfh4eF4vfcBL+MLLkFntCjCF2imYrX+jby8vGa37LohLaFN+SqFxBWJ2Kw23N7T85fsVjser4fkm5KZMiCwu+Jq7yGpLQoxKMRIA3PsGLRr5xudqIzV6tsa/tQ758lCN08s2cY7G3zniw25qC1/ndCHqMjQcyppxIjHSE19moqnxnm58srf8tlnfzynnyU1l7Y3jRGvjcBQ/mvHgoXUu1PrvEemrKCiHiKpbdV5/67Vze5EGqM63eQtLc23a++SJVULMHB6z5iwMHZm5ZL4xkZ2HcrDaoEHrunKtJEXY7NWvO9SVVgsVd2hVjNZAylpXVKpHpiz2aw25q6fW2ehobygcmGrC0la76vPa04t0Tdelu1cxuLtixtED5E0beqJkWYrLS2NpKQklixZgtfrxWq1Eh8fz+zZsxlaG5MfUlIgMbHyYwfOZrVicnN555uj/G7JVvKLvERFhPDC7X0ZfFHbc68L31BJeHjV9uI7q2NI6pGryEX4nHB/QKiI1WIl79G8Wh/KKW8oy2ax4TEVL+eqrx4iaVqq8/6tvbOlWarzTd7S0nwBxpjqBRi7nRMJtzJr2U5+tXAz+UVehndpx4oHhpcKMC6Xi6ysrBqdqOx0QrDXRUf20JE9hFL+Y9TCZsJ1ylXkIisvC1dRIzpZuoqcBc4qBRjw9YA4C2r3F5W2N43EFYkYTKmeoMoCDJzuIRKpKwox0uzUyyZvxQc/VtO3bTpw82V3sij9ADarhYev78Y/776CduEhJeo/p2MC0tJo97MrOUkLfqQzP9KZk7TgU65kCKUfo6HuUJu2N42EtxIInxNOzPMxhM8JJ+GtBNbsbTqb80WGRGK1VO2faavFSmRI7f6iioeyasrtdbNo+6ImGTClYVCIkWanzjd5Kz74sRo9MIXAf3rfQPzdL/DDCS8xkaEsuG8QiVdfjPWM+S/n0oPkKnKR9fKfcF09HFva55w5q8YCXMnnpDKMX3L6MRrqDrUpX6Uw4rURLNu5rNRcjOGvDeeVr5vGcQlhQWHEd4vHbq14+qLdamd89/G1OpTkKnKxZMeSCufiVEVd9BCJFNOcGGlWTi8trsIcA6u1ZkuLs7LAvwdL5bKDw7jrhulk9BgBwNXdzuP52/rQpmVwiXZpaWmMGDGCiv7KWiwWUlNTS8zp8U/K3L4EL16sXojfDrPXwdAyzkn1AsNJYy1DK9u2Bqj/pbUNabVOfQjU883KyyLm+aq/jstTV3N1pOnSnBiRcjidzioFGPD1cDjLmQzicvmySpnTUSIjfZvWVcGm6IvpdecrZPQYgfG4efi6i/nHnZeXCjBQsx6klLUv+HosdizDy6keCyss6wbDfwHPDQFXGf/Jn8VcLBZITi4/wNT3cE7x3Jc/r/lzpUMcTWkuxrCOw0i+KRkLllI9MnarHQsWkm9KrvXAVp2hrPLURQ+RyJnUEyPNyrn2xJy5Yrp4N9f4eJg9+4w3+5QUmDq1wsc2wGv9xvLHq+/BY7fhznHR0/kxK99IqZW6T374IV+9/hQjLkrFVJKnLF4Yd1bPjBcLX3x8gsEjy37zqc/N185e3ltVTa0HYM3eNcxdP5dF2xf5lzmP7z6eBwc9WGc9TglvJbBs57IaDyk1pR4xqT/a7A6FmGalmlurJiQksGzZsjMm9YYCkYATyAfAbrcTHx/PwjN2zi1vxbTd7tuENzkZpvRMgxEjKtwTJiekJY+MnsH73Xz/sJ/cGc3R93syL2kn999/WZn3KXlMQMWmAMkWC7dMMCzrAu4qzMu0e8Bjhb++DxO2QWQBhO3PhDOOGigeNtp6aCvX/fu6ehneKC8sVVXm7Eyiw5vWcQn1OXxXlaEsKL3cuiHtJCyNj4aTpHlIS/Nt5R8e7puDEh7u+7qSVTqzZs3C4/HgOzNoIZAHZJ36vBAYgsfj4cEzjisuc8W03QUts3Djwhhf58vRxytelbQppgtj7nqB97sNJchTxG8++hvJi55hSMFXfPzxGQHmrPGqyMhIrNaz/7qGAlGnPvsMxXeIQL7NsKRr1QIM+NoZCzwwGmIehvDHIOHj+1izd02pYaNr/31tpY9XG8M5FS3vrYq6WK3TEIQFhREdHl0vPUxVGcp6aPBDjOs+zj/0VLwRXurdqQowUufUEyONU5W6Rcr/B3TixM9ZsGAY5Z0ZNHFiGvPnj/DfmpAAy5ad+lEd02BQEnRfAlavb5LJ9njCvphG3o/XYaX0kIcB/m/AWJ696m6KbEF0yM5k3pI/0TtzF0XYseFhmiWZuat6EvJy2eNVCc8/f6oHaSDlHdj4Lmu52WLhaAtDzMM1vLbFl9Jq94eHM/9cVRYsnHjsRI3fbM9lKMNutRPfLZ6Ft5U+g0qqrypDWTo7SWqLhpNQiGnS0iofsqloWU11715id9sBKXBTInhtYDvjzdVjB6uHlOWGKV+XfKzs0HAeunEmH3UZBMDoHWt49v0XcRScKNGuuByL3V5mMPtu1iy6PH8SmEdZ4SuUQvKIwIbBZff1pngD3Nf6p2v/xK+G/qra96vOTrVl0VyMuqGgIvVBw0nStFVlIzmbDcrZ56W6d3c6TwWYjmm+AGMxJQMM+L62GKbeBGs6nL55Q1x3brrrRT7qMohgdxF/+DCZ5MVzSgWYYhYotb+MCzdZLQxxLzzPECbh+2sbdNY9g4gkD9upKBTmhjE7wVb5pqp16tcf/bpGq5Wqs1PtmepytY7U71CWSFWoJ0Yal3M89Kcmd4dT9/lZAnRbVjrAnHkfj4VxOw3vvGXhf69I4M9X/hyP1cYFx35i3pJn6Xnoh8p/8ClpHSFpECzp7utRsXphwPY4vlz3Nuwr/QYdios8wlnX0UvSIFjcHUwD+G/KlZ2u5LO7PqvWfWrSE1Mfq3VEpO7pFGtpuvzdIlVwxmnQ53L36GgYM87F0uI5MBXdx2ZY2jWSO2+dReqFAwC4+ZvVPPPBPCIKq771esoAmHoT2Lynh4S8VtjY7SfoMRyWJ8PXJef85Nvhziu688Z132D3nhVgDHDuB1/XyOofV+MqclXrf+/FO9VWNifGbrUzpssYXhnzioY4RJqhBvD/NJFqiIz0dZFURRmH/ixY8L/45pNU7+73THVWGmAAQjyXEl34IqkXDiCkqIA5K1/ixWV/rlaASb7cF2CwgOesYS+3Dd9w1k1TocOpYZqOaXBbAjwWzhujvgFLGauSAhRgimXlZVX7PrMGz8Ljrfh35fF6eGjIQxriEGmmFGKkcQkL863WsVfSiVjGoT9paWk8+OAUfCt5iqp19+tGRGKp6K+LsRBZdBvRhc9gpx2dW1p4/ds3uW3TB+TbIbMlnKhCv2fKAEi8sfJ2eG0weK5vovHdI3zDXFUIWWUsnGqwArVTrYg0Hgox0vjMmuVbRl0RjwfO2OcFzty2fy6+pclVv3tYUBjjusdjs5ROIlbTiqjCp2jt/jkWbHhC1pE43sPDbQ8SMgFaPAaxD0PkY5BwW8mJv2dK7QiJp3pgKu05sbmh+yJfj0xZE43LY4VK9i2rEzXdcG7KgCmk3p1KfLd47UMiIqVoYq80Tq+84ttdror7xJTetv+XQDLl7RPzwgtuZswoeX5R8lfJJK5ILHFbiKcX7Qofxk4bvORzLCiFE/aPfd/0r5k+o7xTO+MmL8e/FLsIO3bc3HIbLO1WegipQh5bzZYgeay+CTc1dPYOrRWpycTesmh5r0jzoCXW0vRNmeLbyCU+/vQcmeKN4VJTS210V/rgx1eB4cASTs+R8Zz6ejgTJhz33XRq59yUtS8wbcW00wfiGSuOoolEFz6NnTYUWn4kM+TB0wEGyuxRKd4Zt3gptgcrS4hnWPBHLO5hqV6AMdQswBjOKcAAjOs+jpdvfLlKbf848o/n9LOKaXmviJxNq5Ok8Ro69PRudJWcnVS8bX9xkPGdlrQBJ1PJ514gmOKzk6xWK622boX774clS0hr7yXxbl/4MMZgM61pV/gQod7eAOTZPuRY0KsYS0GVSzfAlaMvJeh/vyKfMAjK8g0LVecBajJZ9xxXKVmw8NHkjxh54UjAN7Rz//L7sWApcb5O8dcpN6VozoqI1Bn1xEidcblcZO3Zg2vPHv8ZQHUiLMy3DrqCwx/DwsKIj4/nSpuNhbQhDwtZFJDHURZyFUOYAfTDbrfzcq9eBF93HWbZMvD69lwp7rgI9fQhNv9FQr298eLiSNBfOBr8YrUCDOBbeRS7jfyf3en7uiCyetvr1jSIVHA/Cxb6xvQFqHAibXGAAd+clbS700jokVBizkpCjwTS7k7TnBURqVOaEyO1Li0tjRWPPcaA1FTi8U2h9QLHR4yg7TPPlHkUQK2opEfmu9mzuTApCQ92gjg9j6b47KKpzGMrH/A5S/3p3r99v8VKK/ckIt23YcFKoWU3h4OfxW09cG41G+C9ZNhwP0xIwH7JMtymapN0z+79qPTnVBBgbBYbN3e9mUW3L6rSOTll0ZwVEakNOjsJhZhASUlJYcvUqeWc7uMbv7SkpFR4OGO1paX5zhIo49BEf2BKS8MMH4Glgjd9LxY+ZzhD+dxfd1ZLOP+htrQrfJhQb08Acm3vczzobxhL4bnXboDcOOwvHmDoxDQ+v2hE1YNJdX5GFXpurBYreY/m+QOIQomIBIIm9kpApKWlMf9UgCn7dB/fe6m5/35YU/3zdMqUkuI7zfHU0A/g+7xsGQwf7lvFBJCUhMdSybJqbFx5RoABSI8bcGr4qCdeTnI46E8cC365dgIM+C5IxE+4g47xx1/69kWpifKGf347/LdVHnryGi/OAqf/a02kFZGGTiFGak1SUhKzqHw/XK/FUu7hjNWSlgaJib7jqM86NBG323f71KnwySeYJUuwVzJME4Tb/35fZLUx56q7mZLwJDYcFFq+42DIA5y0p5573WezwKSn3mPoUN8ck48nf1z5fU6xWqx8PPnjUvuojOkyhiW3L2HmoJmnV1RV4bEiQ9RrKSKNh1YnSa1wuVx8sHgx71DZNnJgMwbvf//LF598wuCRIytpXYHi46jPDjAlfpgNkpKwVPXAJOBAxHlMj/8VG8/vAcCoHUv5+2X/h7FWcUO56jIw/+SdDP/6JFMGTCHYHlz5ffDNYxnXfRwjLxzJyAtH4ipyseqHVfxj4z9YunMpi3csxmqxEt0ymkMnDlW4r4vdaie+W7x6XUSkUVGIkVrhdDoJN6bSAFPMCiy65ho2paQwpSbzY1yu03NgKuJ2w/vvYywWLFWY/vXhxVfw8I0PkhMWQUR+Hn9+/wVu2LmOfvtPH8hY6lyic3Wq+2fq8qn0iupF0rqkKm0m5zEeHhx0elvh1zNeJ3FFIjarzX/6s9d4Kw0w4DuD6MzHEhFpDDScJLUiMjKSXlR9R3sD/An45v77WVOT+THVPI7acsMNuMs4MqBYodXOb6+5l/tu+R05YRH0/mknK15/gBt2rgN8u+um/h/E7zjjiCJDrW7hb7Pa+Mvav7Bkx5Iq7YZrwUK/2H4ApO1NI3FFIgZT6tTnMx/Ldta8IJ1BJCKNmUKM1IqwsDCejo2t8nt68Wa2LwCt4uOrN9E3LQ3uu696BV5/PbZygsG7PaLpM+M5/j0gHgCnbTGWgl/xQ2TJk5ev2Advvw13P4Pv+KVz3DjubG6vm6U7l/p7USpjMP6JuEnrkrBZK+4isllsRIdH6wwiEWkyNJwktePjjxl48GC139MtQI+jRzHDh2M567yjMqWk+Cbz2qoxpmOxQGoqlpRkzP1TcWPz7xMzc/Rg3r3sAayE4yGXo8Fzcdm+ZEk3WNIDXl4OU78+fSDBXGCtG3BTJ/8F8Bpvlfd/KZ6I6ypysWTHkkrDj8d4yMzL5PBDhynyFmnptIg0euqJkXOXkoK59toad0pYwTdfZerUintkKlqNVBFjYNEiuPNONr+cyu6WPcm32bl3/C9ZfNnjWAkn3/otB0Nm4LJ96buPDbD4TpVu3aEbEcCtwNrixyzAt4NfLbNarNzc9eZSS6bPZrfaGd99PGFBYTgLnFXuvfEaL0XeIi2dFpEmQSFGqsXlcpGVlYWr+BiBtDTM1Km1M6pis1W89Lp4NVJNeL28/qKTaYkGe9AhfvY/f2FV15sByLEvJCv4ETzWw2Xcz0724Evp1icFu/2MYOEOhe3Bla8nL2bwHb5UgeJg8vDQh/F4qz4RNzIkUsuoRaRZUoiRKklLSyMhIYHw8HBiYmIIDw8nISGBo48/jsdSSxND3G5fj0lZ5ywVr0aqTg/MGYzVyv2PRHJl90XcfNdf2RpzMR5yyAp+kuyg18FSTmiwuaH7YjK2/hy3eyAwFFgI5MH6j8Fanede8RBRcTAZ1tG36Z0FS4VnGBVPxA0LCiO+W3y1em9ERJoChRipVEpKCiNGjGDp0qX+U6C9Xi+rli6l1eefY6/Nkyu8Xt/Ko7NVZzXS2ex23m/1MyJGbec/8SM5EdKCPge2cjB0Bvm2ryu/v9WLrWUu7dsvAj4HxgI22DsMlif7eljKObzRarFiwULKmBReGJXiCyaWyoPJlAFTSL07tdQmduVNxJ01eFa1em9ERJoCnZ0kFUpOTiYxMbHM70UBWWV+5xxYrZCXV/oAR5cLwsNrFGS+a9OeG+L/F3eUF4vxMm3d29y3fj6tHvVW7eBorxWeyQN3OT0YHdbA4LnQfdEZ6699S6ATeiSUODixJocrVvUMo1e+foWpy6dis9pKLLO2W+14vB6Sb0rWKiQRafCq8/6t1UlSrpSUlHIDDIAT35SQWtv7zW6H668v+3thYb5DHZctq/qQkt3Oom7D+fX1D+AO8tL2xHH++t7zDN+TAUD8dljWrZLN6zx22BHvCzB2F4Q4oSCyZKDZNxT2DcUW6uKGeCf/+r+gclf/DO04lKEdh1brcMWwoLAqDQFNGTCFXlG9SoWk+G7xlZ5ALSLSGKknRsqUlpbG8OHDK2wzFFgFhFI726UUb7tirFYsZ59C7SvKd9hjFV6yruBQnrjnGd6O7ArAoB838+KyPxN14vjph+sII+6uZL6tscDyeXDhR9B9ia+nxWuF7fGwbrYvwJyhvI6k+qYTqEWksdIp1nLOkpKSsFWwEmgKvtkhtRFgije+LX4ci9eLe/FizLBhp0+hBhg2DJKTffu+2M/qRLTbfbe/8AK7tu1m7DPv83ZkVyzGy8y0N3jjrd+UCDAAw/ZC8nKwGLCfPZ3EY/MFmC0T4KZp0G3Z6aEiq9f39S+Gw4BXStytvCk99U0nUItIc6CeGCnF5XIRHh7un8RbUihDCeVzsuslARvAkpZWokem4JNPMElJhLz/vu9gR6sVxo/HzJzJO6Gd+N2SreQXeTnPfZIX3n2GIbszKvwZazrA3MGwqLuvk8XitWC2J8API30BxlLBXxFjgf9L9ffINJSeGBGRxko9MXJOnE5nGQHm9NLiB7kaTy1Np6osQbuBI48/Di4XXyxdyu3x8bS47jrCli8n3BjuHj2adatWceKNBcw+EM6vFm4mv8jL8Atb8/6rv6w0wAAM3QdvvW3lX8+MY8Cfl2KeOQFvL/QNIXkrmfHjtfkm9eLrDBo/XgFGRKS+qCdGSindEzMFeBnwEIqbPMKx1cJ2tVU9eqh4uMmKbyLxYiAJ3+65drsda5sO9LwviaNFQVgtMHtUN+7vEY41NrbKtXRiN3u54PQNdhc8Fl5itVG5Tq1esnjCSE0tOY1HRESqRz0xck7CwsKIj48/tUPt/UAyvpdKEJE4ayXAQNXn0lg4/UK14dulJRW4Dwi99Bqi/+cvHC0KonWohQX3DSbx6ouxOhy+sZ0q8GDlNy9Ec/IkZGbC0aOwZaezagEGfO1CnSQnK8CIiNQnLbGWMs2aNYtFi2Lw9cBAKC4icdKPDed8ePO53j8IyA0OI+j6abS95EoA8n/YQEd2cEXnG32NwsJwjRuD8+PlRJ7wEFbOqmy3xU72iHjunRFWfDff5wjfVv5VOpPIWPl4eSQjR5zDkxIRkWpTiJFyDAOGMpQ1PEgS41iCDW8Vzlb2KW5XVlg519VMW6MuZFr8I+xpE4fV4+Xo5x6cX37Ae9b1uFx/Z8PhDSStS2LJZe/hvcyL1evbE2b2Ot/8lzPZ8dDuj6V3sS3eyn/ZzmUlNo47m91iJ75HPCNHaCKMiEh903CSlCkpCaZaXuFzRjCWZf4hJAtVCyHFbcwZn891EMoA/+p7EwmTn2dPmzjOzznEW/N/TeGXI4FUvN57eXHdi4x4bQTLdi7De+oneq2+Te2G/wJeGXDqwYqXZFcwBlSlrfyNtvIXEQkUhRgpxeWCI4vTeMkkYsUQRM0OXbQAHix4OT0xt6ZyQlqSGP8Ivxt1P4X2IK7dtZ7lr8/g8p++JRKX79E7TuKR1EcxmFK9J+5T275MvQnWdLL4dv9NTYUp5W/DX92DGEVEpH5pOElKcTrhAZOEBxvWGgaYYvYqD0Cd5sGKFa+/N2dTTBemxf+afa1iCPIU8chnr/GLr5eeCklWnJyavT54LhZjw1jKr9lmtTF3zs0MnbiwSrVoK38RkYZLIUZKiQxy+efA1JayJvO67OAMgcgC/BNvPVhox2H+zv/jZpbx7wE38uxVd1NkC6JDdibzlvyJ3pm7ACjCzhLiyefUuUbdlmIsFdfsNh4W7VqKq8hV5d1sa3LekYiI1D2FGCklrMjJuc9gKcnC6SCT1hGSBsGSUzvkFk+8fWCdjcP7xpFNG54PncnK0ZeyqusgAEbvWMOz77+Io+CE/zFteJjLqfkoIVVfEu01XpwFzmoHkaoexCgiIvVDIUZKi4z0HcJY5rEDNWcBUgZA4k1gO3WOIpyeeLu4h4fOyzsT/NNx9o5185NjEMHuIh795P+4K32ZvyenCDs2PEwlmbWcGs4piDydiCphtViJDNEGiCIijZ0m9kppYWFY4uPxWms3437e0RdgjMU30fZMbhsYLBy5/gdi7liL3eGi6HgLHP9pTUR6MN5TL1UPVpYQz3BSeZUzJuW6w2B7PBZvxTXbrXbGdx+vHhURkSZAPTFStlmzsC5eXGsPV4SdhwdFYbxZYCu9bNlqImlbOJMW3ivACie3x3J0ZS9+/VwQEx68kmCvb7M9J5G+OTBlWT8Lc0nFNXu8WhItItJUqCdGyjZsGCQnYywWimoh6xba3XzZPbPMABPiuZTY/Bdp4b0CQyFH7S8zJKg7n38cxIwZvtXQbnsYh4guP8AAfdsOI0VLokVEmg2FGCnflCkcX5LKEuLx1PClUoQdLxbuD/lT6fkqxkJk0a1EFz6DnXYUWfZxMGQWeUHv8+pruf496GbNAk/Fe84B8NJLviXRqXenEt8tHqvFV3PxkujUu1OZMqD8fWFERKRx0SnWUiGXC8LDIdjrIoosfuBCbFXc+8WDlUWMZy4Pstber8Sp0FbjoF3hbMK8/QDIs33CsaBkjCUfq8VK3qN5JeatvPIKTJ0KNhu4z9gGxm73BZzk5NL71mlJtIhI46NTrKXWhIWdHs7ZywUsZlylw0tF2FjGTYSTx60s9K0gOjXxFo+dEE8vYvNfJMzbDy/5HAn6K0eDkjCW/HIn3k6Z4ttgNz7+9OHUVmvFG++GBYURHR6tACMi0kTVeoh58sknsVgsJT5iYmL83zfG8OSTTxIXF0dYWBhXXXUV27ZtK/EYBQUFTJ8+nXbt2tGyZUvGjh3L/v37a7vUJsXlcpGVlYXL5Srrm5CV5ftcA2cO58xlFjYqHtux4eVZHi09f+WLB3F4byW68GnstKXQ8iOZIbM4Yf/IvxNeRRNvhw6FhQshLw8yM32fFy4s9+gjERFp4uqkJ+bSSy/l4MGD/o8tW7b4v/fcc8+RlJTEvHnz+Oqrr4iJieG6664jNzfX32bmzJksWrSIBQsWkJaWRl5eHmPGjMFTlYkRzUxaWhoJCQmEh4cTExNDeHg4CQkJrFmzBtLSICHBNx4UE+P7nJAAa9ZU62ecmuMLwBqGMZVkvJSe8Fs8/6XE/i2nWFvmEzUoiFbuO7BgI8/6EZkhsyiy7gWqN/E2LAyio32fRUSkGTO17IknnjC9e/cu83ter9fExMSYZ5991n9bfn6+cTgc5pVXXjHGGJOdnW2CgoLMggUL/G0OHDhgrFarWblyZZXryMnJMYDJycmp2RM5VydPGpOZ6ftcR5KTk43FYjF2u91AqIEoA6HGbreb+8F4wRi73Rg4/WG3G2OxGJOSUu2f9/HHpx9mCGnmHW4xbqzGgHFjNe9wixlCWokfB8aEdjps2k/70HT69Xumw4Pvm5bDPzHcdovhd1bDkxjrU1Zzy1u3mLQf0+rgKomISGNSnffvOumJ2bVrF3FxcXTu3Jnbb7+dH374AYDdu3eTmZnJqFGj/G1DQkK48sorWbt2LQAbNmygqKioRJu4uDh69uzpb1OWgoICnE5niY+AqKXej8p/TBqJiYkYMwS3ewGQB2QBeQx0P8E8To3QuM86DNHt9mWLqVOrXdPIkTB+vG8y7VqGcisLCSePaDJLzn8pZvHSavgOoiZ8ga1lIYWHIjj4z2GcSL0a3l6I7bk8bvo2k7xH81h420ItfRYRkWqp9RAzcOBA/vWvf/HBBx/wt7/9jczMTIYMGcLRo0fJzMwEIDo6usR9oqOj/d/LzMwkODiY1q1bl9umLHPmzMHhcPg/OnToUMvPrApSUmDECFi2DIq37Pd6fV8PH+5bYlNLkpKSsFimAp8DY4HiLXBtPMgGPJXt7WKzwdy51f65Zy93zqfs/Vts4flE3/4FjiHfYbFAbnpHMv89FPexcH8bb0EYj07XxFsREamZWg8xo0eP5pZbbqFXr15ce+21LF++HIB//vOf/jYWS8nzjI0xpW47W2VtHn30UXJycvwf+/btO4dnUQNpaZCY6OvlqMXej7K4XC4WLz6C1/sivl9hkP97obgYx1KCcJd7f39NixZVe7Jv8fwYi8XXI3Mmu913+8w/HaLnQ6mEdjyGt8DOsff6cuzDXphTZw0Ut0tO1qRcERGpuTpfYt2yZUt69erFrl27/KuUzu5ROXTokL93JiYmhsLCQo4fP15um7KEhIQQGRlZ4qNeJSX5ejcqUsPej7M5nU6MeQDKWCUUiRNbVU+g9nqhBsNu5S13vjney9RXv2XRsa/IdhVyaVwkc28YxqjucVVeFi0iIlJVdR5iCgoK+Pbbb4mNjaVz587ExMSwatUq//cLCwtZvXo1Q4YMAaB///4EBQWVaHPw4EG2bt3qb9PguFywZEnpHpiz1bD342xBQZHAOM7sgSnmJLLqu+tarVDDsHf2cuedB1xYrlnPe9/75j/dObgT/71/CLdc31LLokVEpE7U+gGQDz30EDfffDMdO3bk0KFDPP300zidTu68804sFgszZ87kmWeeoUuXLnTp0oVnnnmGFi1aMGnSJAAcDgf33HMPs2fPpm3btrRp04aHHnrIPzzVIDmdp+fAVKa49+Mc1gcXFZV/33zCWEw8Y1lW8ZCS3e7rEjnHdcphYbBmdxaz39lEjquIiFA7z91yGaN7xZZqpyXRIiJSm2o9xOzfv5+JEydy5MgRzjvvPAYNGsT69evp1KkTAL/61a9wuVxMnTqV48ePM3DgQD788EMiIiL8jzF37lzsdju33XYbLpeLa665htdffx1bZcM1gRIZ6evVqEqQOYfej5I/zuD1lj1HaC6zGM/iih/E44EHz+0050K3l+dWbufvabsB6N3ewUsT+9GxbYtzelwREZGq0NlJtSUhwbcKqaIhpeLej4ULa+XHLVnixeste+jol7xCMlPxWmzYTRUPG6qGfcdOMu3NdDbtywbgF0M788jo7gTbdZKFiIjUnM5OCoSqHLVcC70fZ/64irb5eZUpjCCV7BHVOGyoilZuPciNL6ayaV82jrAg/vbzAfzu5ksUYEREpF7V+nBSs1W89riyo5ZraUZrVX7c/yQPpd2Uob6JxE6nbxzqHCamFLg9PLP8W/657kcA+nZsxUsT+9K+tYaPRESk/um/zrWpJkct18ePq4XDhvYcOcEtKWv9AeaXV17I278crAAjIiIBozkxdaWWej8awo97b/NPPPLfLeQVuGndIoik2/pwdfeo2v0hIiIiVO/9W8NJdaWe1xTXxY/LL/Lwh/e+4Y0vfCdNX35Ba16c2JdYh9ZKi4hI4CnESJm+P5xH4hsb2Z6Zi8UCiVddzMxru2C3aQRSREQaBoUYKWVx+gEeW7SFk4Ue2rYM5q+392F4l/MCXZaIiEgJCjHi5yr08OTSbbz1te/wzMEXtuWF2/sQFRka4MpERERKU4gRAHZl5ZI4fyM7s/KwWGDGyC7MuKYLNmvFp4uLiIgEikKM8M7X+/jdkm24ijycFxHCCxP6MOTidoEuS0REpEIKMc3YiQI3v12ylXc3HgBgeJd2JN3Wh/MiQgJcmYiISOUUYpqp7ZlOEt/YyPeHT2C1wKzrujL1qouxavhIREQaCYWYZsYYw4Kv9vHk0m0UuL1ER4bw4u19GXhh20CXJiIiUi0KMc1IXoGbx97dwtJNPwFwVbfzeP7W3rQN1/CRiIg0PgoxzcTWAzlMm7+RPUdPYrNaePj6btw3/EINH4mISKOlENPEGWP4z/of+cN731Lo8RLnCOWlSX3p36lNoEsTERE5JwoxTZgzv4hH/ruZFVsyAbi2RzR/ufUyWrUIDnBlIiIi504hponavD+bxPkb2XfMRZDNwq9v6M49wzpjsWj4SEREmgaFmCbGGMNra/Yw5/1vKfIY2rcOY96kfvTp0CrQpYmIiNQqhZgmJOdkEQ8v3MSH32QBcMOlMfzpZ5fhCAsKcGUiIiK1TyGmidi49zjT56dzINtFsM3K4zf14OeDO2n4SEREmiyFmEbO6zX8Pe0Hnlu5A7fX0KltC16e1I+e5zsCXZqIiEidUohpxI6fKGT2O5v4ZPshAMZcFsuchF5EhGr4SEREmj6FmEbqqz3HmPFmOgdz8gm2W3ni5kuYdEVHDR+JiEizoRDTyHi9hpTV35O0aicer+HCdi2ZN6kfl8RFBro0ERGReqUQ04gcySvgwbcySN11BIDxfc/n6XE9aRmiX6OIiDQ/evdrJNZ9f5QHFqRzKLeA0CArvx/bk1sHtNfwkYiINFsKMQ2cx2uY98l3vPDxTrwGukSF8/Id/egaHRHo0kRERAJKIaYBO5Sbz8wFGaz9/igAt/Zvz1Pxl9IiWL82ERERvRs2UGm7jjDzrQyO5BXQItjG0+N6ktCvfaDLEhERaTAUYhoYt8fLCx/vYt6n32EMdI+JYN6kflwcFR7o0kRERBoUhZgGJDMnnxkL0vly9zEAJl7RkSduvoTQIFuAKxMREWl4FGIaiM92HGLW25s4dqKQlsE25txyGWN7xwW6LBERkQZLISbAijxeklbtJOWz7wG4JDaSl+/oR+d2LQNcmYiISMOmEBNAP2W7mP5mOht+PA7Azwd34rEbe2j4SEREpAoUYgLko2+yeGjhJrJPFhERYudPP7uMG3vFBrosERGRRkMhpp4Vur08t3I7f0/bDcBl7R3Mm9iPjm1bBLgyERGRxkUhph7tO3aSaW+ms2lfNgC/GNqZR0Z3J9huDWxhIiIijZBCTD1ZuTWTXy3chDPfTWSonb/c2ptRl8YEuiwREZFGSyGmjhW4PcxZsZ3X1+4BoG/HVrw0sS/tW2v4SERE5FwoxNShH4+eYNr8dLYcyAHglyMu5KHruxFk0/CRiIjIuVKIqSPLNx/kkf9uJrfATesWQTx/W29Gdo8OdFkiIiJNhkJMLcsv8vD08m/4z/q9AFx+QWtenNiXWEdYgCsTERFpWhRiatEPh/NInJ/OtwedAEy96iJmXdcVu4aPREREap1CTC1ZknGAx97dwolCD21bBpM0oQ9Xdj0v0GWJiIg0WQox58hV6OHJpdt46+t9AAy6sA0v3N6X6MjQAFcmIiLStCnEnIPvDuWS+EY6O7JysVhgxsguzLimCzarJdCliYiINHkKMTW0cMN+frt4K64iD+dFhPDChD4MubhdoMsSERFpNhRiqulkoZvfLN7KuxsPADDs4nbMndCH8yJCAlyZiIhI86IQU03zv9jLuxsPYLXArOu6cv9VF2v4SEREJAAUYqrpriEXkLEvm8mDOjHwwraBLkdERKTZUoipJrvNyrxJ/QJdhoiISLOnXdhERESkUVKIERERkUZJIUZEREQaJYUYERERaZQUYkRERKRRUogRERGRRkkhRkRERBqlBh9ikpOT6dy5M6GhofTv35/U1NRAlyQiIiINQIMOMW+99RYzZ87k8ccfJz09neHDhzN69Gj27t0b6NJEREQkwCzGGBPoIsozcOBA+vXrR0pKiv+2Hj16MG7cOObMmVPhfZ1OJw6Hg5ycHCIjI+u6VBEREakF1Xn/brA9MYWFhWzYsIFRo0aVuH3UqFGsXbu2VPuCggKcTmeJDxEREWm6GmyIOXLkCB6Ph+jo6BK3R0dHk5mZWar9nDlzcDgc/o8OHTrUV6kiIiISAA02xBSzWCwlvjbGlLoN4NFHHyUnJ8f/sW/fvvoqUURERAKgwZ5i3a5dO2w2W6lel0OHDpXqnQEICQkhJCTE/3XxVB8NK4mIiDQexe/bVZmy22BDTHBwMP3792fVqlWMHz/ef/uqVauIj4+v9P65ubkAGlYSERFphHJzc3E4HBW2abAhBmDWrFlMnjyZAQMGMHjwYP73f/+XvXv3MmXKlErvGxcXx759+4iIiMBiseB0OunQoQP79u3TaqV6pOseGLrugaHrHhi67oFRV9fdGENubi5xcXGVtm3QIWbChAkcPXqU3//+9xw8eJCePXuyYsUKOnXqVOl9rVYr7du3L3V7ZGSkXuQBoOseGLrugaHrHhi67oFRF9e9sh6YYg06xABMnTqVqVOnBroMERERaWAa/OokERERkbI0mxATEhLCE088UWIFk9Q9XffA0HUPDF33wNB1D4yGcN0b9LEDIiIiIuVpNj0xIiIi0rQoxIiIiEijpBAjIiIijZJCjIiIiDRKzSLEJCcn07lzZ0JDQ+nfvz+pqamBLqlRe/LJJ7FYLCU+YmJi/N83xvDkk08SFxdHWFgYV111Fdu2bSvxGAUFBUyfPp127drRsmVLxo4dy/79++v7qTRon3/+OTfffDNxcXFYLBYWL15c4vu1dZ2PHz/O5MmT/SfAT548mezs7Dp+dg1XZdf9rrvuKvX6HzRoUIk2uu7VM2fOHC6//HIiIiKIiopi3Lhx7Nixo0Qbvd5rX1Wue0N/vTf5EPPWW28xc+ZMHn/8cdLT0xk+fDijR49m7969gS6tUbv00ks5ePCg/2PLli3+7z333HMkJSUxb948vvrqK2JiYrjuuuv851kBzJw5k0WLFrFgwQLS0tLIy8tjzJgxeDyeQDydBunEiRP07t2befPmlfn92rrOkyZNIiMjg5UrV7Jy5UoyMjKYPHlynT+/hqqy6w5www03lHj9r1ixosT3dd2rZ/Xq1SQmJrJ+/XpWrVqF2+1m1KhRnDhxwt9Gr/faV5XrDg389W6auCuuuMJMmTKlxG3du3c3jzzySIAqavyeeOIJ07t37zK/5/V6TUxMjHn22Wf9t+Xn5xuHw2FeeeUVY4wx2dnZJigoyCxYsMDf5sCBA8ZqtZqVK1fWae2NFWAWLVrk/7q2rvM333xjALN+/Xp/m3Xr1hnAbN++vY6fVcN39nU3xpg777zTxMfHl3sfXfdzd+jQIQOY1atXG2P0eq8vZ193Yxr+671J98QUFhayYcMGRo0aVeL2UaNGsXbt2gBV1TTs2rWLuLg4OnfuzO23384PP/wAwO7du8nMzCxxzUNCQrjyyiv913zDhg0UFRWVaBMXF0fPnj31e6mi2rrO69atw+FwMHDgQH+bQYMG4XA49LuowGeffUZUVBRdu3bl3nvv5dChQ/7v6bqfu5ycHADatGkD6PVeX86+7sUa8uu9SYeYI0eO4PF4iI6OLnF7dHQ0mZmZAaqq8Rs4cCD/+te/+OCDD/jb3/5GZmYmQ4YM4ejRo/7rWtE1z8zMJDg4mNatW5fbRipWW9c5MzOTqKioUo8fFRWl30U5Ro8ezRtvvMEnn3zC888/z1dffcXIkSMpKCgAdN3PlTGGWbNmMWzYMHr27Ano9V4fyrru0PBf7w3+AMjaYLFYSnxtjCl1m1Td6NGj/X/u1asXgwcP5qKLLuKf//ynf8JXTa65fi/VVxvXuaz2+l2Ub8KECf4/9+zZkwEDBtCpUyeWL19OQkJCuffTda+aadOmsXnzZtLS0kp9T6/3ulPedW/or/cm3RPTrl07bDZbqaR36NChUoleaq5ly5b06tWLXbt2+VcpVXTNY2JiKCws5Pjx4+W2kYrV1nWOiYkhKyur1OMfPnxYv4sqio2NpVOnTuzatQvQdT8X06dPZ+nSpXz66ae0b9/ef7te73WrvOtelob2em/SISY4OJj+/fuzatWqErevWrWKIUOGBKiqpqegoIBvv/2W2NhYOnfuTExMTIlrXlhYyOrVq/3XvH///gQFBZVoc/DgQbZu3arfSxXV1nUePHgwOTk5fPnll/42X3zxBTk5OfpdVNHRo0fZt28fsbGxgK57TRhjmDZtGu+++y6ffPIJnTt3LvF9vd7rRmXXvSwN7vV+TtOCG4EFCxaYoKAg849//MN88803ZubMmaZly5Zmz549gS6t0Zo9e7b57LPPzA8//GDWr19vxowZYyIiIvzX9NlnnzUOh8O8++67ZsuWLWbixIkmNjbWOJ1O/2NMmTLFtG/f3nz00Udm48aNZuTIkaZ3797G7XYH6mk1OLm5uSY9Pd2kp6cbwCQlJZn09HTz448/GmNq7zrfcMMN5rLLLjPr1q0z69atM7169TJjxoyp9+fbUFR03XNzc83s2bPN2rVrze7du82nn35qBg8ebM4//3xd93Nw//33G4fDYT777DNz8OBB/8fJkyf9bfR6r32VXffG8Hpv8iHGGGNefvll06lTJxMcHGz69etXYvmYVN+ECRNMbGysCQoKMnFxcSYhIcFs27bN/32v12ueeOIJExMTY0JCQsyIESPMli1bSjyGy+Uy06ZNM23atDFhYWFmzJgxZu/evfX9VBq0Tz/91AClPu68805jTO1d56NHj5o77rjDREREmIiICHPHHXeY48eP19OzbHgquu4nT540o0aNMuedd54JCgoyHTt2NHfeeWepa6rrXj1lXW/AvPbaa/42er3Xvsque2N4vVtOPRERERGRRqVJz4kRERGRpkshRkRERBolhRgRERFplBRiREREpFFSiBEREZFGSSFGREREGiWFGBEREWmUFGJERESkUVKIERERkUZJIUZEREQaJYUYERERaZQUYkRERKRR+v8DAMkCGAMtuAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "'''Plot the predicted cycle lives'''\n",
    "plt.scatter(actual_label_arr_train, predict_label_arr_train,s=50,c='k')\n",
    "plt.scatter(actual_label_arr_val, predict_label_arr_val,s=50,c='b')\n",
    "plt.scatter(actual_label_arr_a, predict_label_arr_a,s=50,c='r')\n",
    "plt.scatter(actual_label_arr_b, predict_label_arr_b,s=50,c='g')\n",
    "plt.plot([100,2500],[100,2500])\n",
    "\n",
    "\n",
    "'''Evaluation metrics'''\n",
    "mpe_a=np.mean(np.abs(predict_label_arr_a-actual_label_arr_a)/actual_label_arr_a)\n",
    "mpe_b=np.mean(np.abs(predict_label_arr_b-actual_label_arr_b)/actual_label_arr_b)\n",
    "mpe_train = np.mean(np.abs(predict_label_arr_train-actual_label_arr_train)/actual_label_arr_train)\n",
    "mpe_val = np.mean(np.abs(predict_label_arr_val-actual_label_arr_val)/actual_label_arr_val)\n",
    "\n",
    "\n",
    "rmse_a=np.sqrt(np.mean((predict_label_arr_a-actual_label_arr_a)**2))\n",
    "rmse_b=np.sqrt(np.mean((predict_label_arr_b-actual_label_arr_b)**2))\n",
    "rmse_train=np.sqrt(np.mean((predict_label_arr_train-actual_label_arr_train)**2))\n",
    "rmse_val=np.sqrt(np.mean((predict_label_arr_val-actual_label_arr_val)**2))\n",
    "\n",
    "\n",
    "print ('mpe_train:',mpe_train)\n",
    "print ('mpe_val:',mpe_val)\n",
    "print ('mpe_a:',mpe_a)\n",
    "print ('mpe_b:',mpe_b)\n",
    "\n",
    "print ('rmse_train:', rmse_train)\n",
    "print ('rmse_val:', rmse_val)\n",
    "print ('rmse_a:', rmse_a)\n",
    "print ('rmse_b:', rmse_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_train: 0.515458881855011\n",
      "r2_val: 0.5441678166389465\n",
      "r2_a: 0.5139330232947799\n",
      "r2_b: -0.19161131123912956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_a = r2_score(actual_label_arr_a, predict_label_arr_a)\n",
    "r2_b = r2_score(actual_label_arr_b, predict_label_arr_b)\n",
    "r2_train = r2_score(actual_label_arr_train, predict_label_arr_train)\n",
    "r2_val = r2_score(actual_label_arr_val, predict_label_arr_val)\n",
    "\n",
    "print('r2_train:', r2_train)\n",
    "print('r2_val:', r2_val)\n",
    "print('r2_a:', r2_a)\n",
    "print('r2_b:', r2_b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
