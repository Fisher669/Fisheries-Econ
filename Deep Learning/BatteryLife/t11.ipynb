{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型效果\n",
    "对于googlenet baseline 的修改，详细见md文件\n",
    "\n",
    "\n",
    "## 对比（非lstm架构）\n",
    "r2_train: 0.9947811961174011\n",
    "r2_val: 0.9749422669410706\n",
    "r2_a: 0.9464100454957816\n",
    "r2_b: 0.6836000724611211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "'''Load data'''\n",
    "temp_Qd = np.load('Data_processed/Qd_100.npy',allow_pickle=True).item()\n",
    "temp_life = np.load('Data_processed/cycle_life.npy',allow_pickle=True).item()\n",
    "all_capacity = np.load('Data_processed/all_capacity.npy',allow_pickle=True).item()\n",
    "temp_Qd_all = []\n",
    "temp_life_all = []\n",
    "all_capacity_all = []\n",
    "\n",
    "for key in temp_Qd.keys():\n",
    "    temp_life_all.append(temp_life[key])\n",
    "    all_capacity_all.append(all_capacity[key])\n",
    "    temp_Qd_list = []\n",
    "    for item in temp_Qd[key]:\n",
    "        temp_Qd_list.append(item)\n",
    "    temp_Qd_arr = np.asarray(temp_Qd_list)\n",
    "    temp_Qd_all.append(temp_Qd_arr)\n",
    "all_Qd_arr = np.asarray(temp_Qd_all)\n",
    "cycle_life_arr = np.asarray(temp_life_all)    \n",
    "\n",
    "\n",
    "'''Divide the dataset as the original paper stated'''\n",
    "test_ind = np.hstack((np.arange(0,(41+43),2),83))\n",
    "train_ind = np.arange(1,(41+43-1),2)\n",
    "secondary_test_ind = np.arange(124-40,124)\n",
    "\n",
    "all_keys = list(temp_Qd.keys())\n",
    "train_keys = [all_keys[inx] for inx in train_ind]\n",
    "test_keys = [all_keys[inx] for inx in test_ind]\n",
    "secondary_test_keys = [all_keys[inx] for inx in secondary_test_ind]\n",
    "\n",
    "cycle_life_arr=np.asarray(cycle_life_arr).reshape(-1,1)\n",
    "max_label=np.max(cycle_life_arr)\n",
    "cycle_life_arr=cycle_life_arr/max_label\n",
    "\n",
    "\n",
    "train_Qds = np.asarray(all_Qd_arr)[train_ind]\n",
    "train_cycle_lifes = np.asarray(cycle_life_arr)[train_ind]\n",
    "\n",
    "test_Qd_a = np.asarray(all_Qd_arr)[test_ind]\n",
    "test_cycle_life_a = np.asarray(cycle_life_arr)[test_ind]\n",
    "\n",
    "test_Qd_b = np.asarray(all_Qd_arr)[secondary_test_ind]\n",
    "test_cycle_life_b = np.asarray(cycle_life_arr)[secondary_test_ind]\n",
    "\n",
    "train_Qd, _, train_cycle_life, _ = train_test_split(train_Qds, train_cycle_lifes, test_size=0.36, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class eca_layer(nn.Module):\n",
    "    \"\"\"Constructs a ECA module.\n",
    "    Args:\n",
    "        channel: Number of channels of the input feature map\n",
    "        k_size: Adaptive selection of kernel size\n",
    "    \"\"\"\n",
    "    def __init__(self, channel, k_size=3):\n",
    "        super(eca_layer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: input features with shape [b, c, h, w]\n",
    "        b, c, h, w = x.size()\n",
    "\n",
    "        # feature descriptor on the global spatial information\n",
    "        y = self.avg_pool(x)\n",
    "\n",
    "        # Two different branches of ECA module\n",
    "        y = self.conv(y.squeeze(-1).transpose(-1, -2)).transpose(-1, -2).unsqueeze(-1)\n",
    "\n",
    "        # Multi-scale information fusion\n",
    "        y = self.sigmoid(y)\n",
    "\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # 公用的前3层卷积层\n",
    "        self.shared_cnn = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 8, kernel_size=(50, 50), stride=(5, 40)),\n",
    "            torch.nn.BatchNorm2d(8),\n",
    "            torch.nn.LeakyReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            \n",
    "            torch.nn.Conv2d(8, 16, kernel_size=(2, 3), stride=1),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.LeakyReLU(inplace=True),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            \n",
    "            torch.nn.Conv2d(16, 32, kernel_size=(2, 3), stride=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # 插入Google net Inception模块\n",
    "        self.inceptions = torch.nn.ModuleList([\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(32, 32, kernel_size=(1, 1), stride=1),\n",
    "                torch.nn.BatchNorm2d(32),\n",
    "                torch.nn.LeakyReLU(inplace=True)\n",
    "            ),\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(32, 32, kernel_size=(1, 1), stride=1),\n",
    "                torch.nn.BatchNorm2d(32),\n",
    "                torch.nn.LeakyReLU(inplace=True),\n",
    "                torch.nn.Conv2d(32, 32, kernel_size=(3, 3), stride=1, padding=1),\n",
    "                torch.nn.BatchNorm2d(32),\n",
    "                torch.nn.LeakyReLU(inplace=True)\n",
    "            ),\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(32, 32, kernel_size=(1, 1), stride=1),\n",
    "                torch.nn.BatchNorm2d(32),\n",
    "                torch.nn.LeakyReLU(inplace=True),\n",
    "                torch.nn.Conv2d(32, 32, kernel_size=(5, 5), stride=1, padding=2),  # Adjusted padding to 2\n",
    "                torch.nn.BatchNorm2d(32),\n",
    "                torch.nn.LeakyReLU(inplace=True)\n",
    "            ),\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "                torch.nn.Conv2d(32, 32, kernel_size=(1, 1), stride=1),\n",
    "                torch.nn.BatchNorm2d(32),\n",
    "            )\n",
    "        ])\n",
    "        self.lstm = torch.nn.LSTM(input_size=32, hidden_size=128, num_layers=3, batch_first=True)\n",
    "        # Input size for fc1 will be calculated dynamically\n",
    "        # self.fc1 = None  \n",
    "        self.drop_layer = torch.nn.Dropout(p=0.2) \n",
    "        self.fc2 = torch.nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        try:\n",
    "            # 公用卷积层\n",
    "            shared_out = self.shared_cnn(x)\n",
    "            \n",
    "            # Inception outputs\n",
    "            inception_outputs = [inception(shared_out) for inception in self.inceptions]\n",
    "            combined = torch.cat(inception_outputs, dim=1)  # Concatenate along channel dimension (dim=1)\n",
    "            combined= eca_layer(32)(combined)  # Apply ECA module to the combined output\n",
    "            # Reshape for LSTM: (batch_size, sequence_length, input_size)\n",
    "            combined = combined.permute(0, 2, 3, 1)  # (batch_size, height, width, channels)\n",
    "            combined = combined.contiguous().view(combined.size(0), -1, 32)  # Flatten height & width into sequence length\n",
    "\n",
    "            # Pass through LSTM\n",
    "            lstm_out, (hn, cn) = self.lstm(combined)\n",
    "\n",
    "            # Use LSTM output at the final time step\n",
    "            lstm_out_last = lstm_out[:, -1, :]  # (batch_size, hidden_size)\n",
    "\n",
    "            # # Calculate input size for fully connected layer dynamically\n",
    "            # if self.fc1 is None:\n",
    "            #     self.fc1 = torch.nn.Linear(lstm_out_last.size(1), 1000)\n",
    "\n",
    "            # Fully connected layers\n",
    "            x = torch.relu(lstm_out_last)\n",
    "            x = self.drop_layer(x)\n",
    "            x = self.fc2(x)\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred during forward pass: {e}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (shared_cnn): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(50, 50), stride=(5, 40))\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Conv2d(8, 16, kernel_size=(2, 3), stride=(1, 1))\n",
      "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (8): Dropout(p=0.2, inplace=False)\n",
      "    (9): Conv2d(16, 32, kernel_size=(2, 3), stride=(1, 1))\n",
      "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (inceptions): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (lstm): LSTM(32, 128, num_layers=3, batch_first=True)\n",
      "  (drop_layer): Dropout(p=0.2, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Step = 0 train_loss: 0.07119028 val_loss: 0.06961862\n",
      "Step = 1 train_loss: 0.071699694 val_loss: 0.06958934\n",
      "Step = 2 train_loss: 0.0715742 val_loss: 0.069561996\n",
      "Step = 3 train_loss: 0.07139274 val_loss: 0.06953265\n",
      "Step = 4 train_loss: 0.071394496 val_loss: 0.06949968\n",
      "Step = 5 train_loss: 0.0714955 val_loss: 0.06947349\n",
      "Step = 6 train_loss: 0.07165286 val_loss: 0.069440596\n",
      "Step = 7 train_loss: 0.07091796 val_loss: 0.06940102\n",
      "Step = 8 train_loss: 0.07129301 val_loss: 0.06937826\n",
      "Step = 9 train_loss: 0.07186642 val_loss: 0.06934682\n",
      "Step = 10 train_loss: 0.071270406 val_loss: 0.06931821\n",
      "Step = 11 train_loss: 0.070720784 val_loss: 0.069293015\n",
      "Step = 12 train_loss: 0.07076208 val_loss: 0.06925154\n",
      "Step = 13 train_loss: 0.07166162 val_loss: 0.06921748\n",
      "Step = 14 train_loss: 0.07140156 val_loss: 0.06916222\n",
      "Step = 15 train_loss: 0.07140816 val_loss: 0.06912193\n",
      "Step = 16 train_loss: 0.07131763 val_loss: 0.069122225\n",
      "Step = 17 train_loss: 0.07137513 val_loss: 0.069064975\n",
      "Step = 18 train_loss: 0.07106104 val_loss: 0.0690544\n",
      "Step = 19 train_loss: 0.07057684 val_loss: 0.06899228\n",
      "Step = 20 train_loss: 0.070904434 val_loss: 0.06892267\n",
      "Step = 21 train_loss: 0.070820935 val_loss: 0.06890135\n",
      "Step = 22 train_loss: 0.07066916 val_loss: 0.0688782\n",
      "Step = 23 train_loss: 0.07090107 val_loss: 0.06878667\n",
      "Step = 24 train_loss: 0.07101578 val_loss: 0.06878454\n",
      "Step = 25 train_loss: 0.07084678 val_loss: 0.06874219\n",
      "Step = 26 train_loss: 0.07084958 val_loss: 0.068675265\n",
      "Step = 27 train_loss: 0.07089789 val_loss: 0.06870261\n",
      "Step = 28 train_loss: 0.0703868 val_loss: 0.06863614\n",
      "Step = 29 train_loss: 0.07034903 val_loss: 0.06856559\n",
      "Step = 30 train_loss: 0.07079767 val_loss: 0.06858418\n",
      "Step = 31 train_loss: 0.07044894 val_loss: 0.068434864\n",
      "Step = 32 train_loss: 0.07007155 val_loss: 0.068457276\n",
      "Step = 33 train_loss: 0.07054014 val_loss: 0.06836301\n",
      "Step = 34 train_loss: 0.070499845 val_loss: 0.06836477\n",
      "Step = 35 train_loss: 0.07021762 val_loss: 0.06829069\n",
      "Step = 36 train_loss: 0.07026506 val_loss: 0.06822749\n",
      "Step = 37 train_loss: 0.070228405 val_loss: 0.0682342\n",
      "Step = 38 train_loss: 0.06990273 val_loss: 0.06814048\n",
      "Step = 39 train_loss: 0.07050553 val_loss: 0.06808824\n",
      "Step = 40 train_loss: 0.06961821 val_loss: 0.068061076\n",
      "Step = 41 train_loss: 0.06983692 val_loss: 0.06804569\n",
      "Step = 42 train_loss: 0.0696602 val_loss: 0.06792442\n",
      "Step = 43 train_loss: 0.07040465 val_loss: 0.06795732\n",
      "Step = 44 train_loss: 0.070021644 val_loss: 0.0678293\n",
      "Step = 45 train_loss: 0.06969899 val_loss: 0.06783224\n",
      "Step = 46 train_loss: 0.06987995 val_loss: 0.0677746\n",
      "Step = 47 train_loss: 0.07027404 val_loss: 0.06770206\n",
      "Step = 48 train_loss: 0.06963241 val_loss: 0.067715235\n",
      "Step = 49 train_loss: 0.06974845 val_loss: 0.06760701\n",
      "Step = 50 train_loss: 0.07022791 val_loss: 0.06760381\n",
      "Step = 51 train_loss: 0.0696749 val_loss: 0.06756405\n",
      "Step = 52 train_loss: 0.06931588 val_loss: 0.06753982\n",
      "Step = 53 train_loss: 0.07041775 val_loss: 0.06748964\n",
      "Step = 54 train_loss: 0.069332674 val_loss: 0.06742663\n",
      "Step = 55 train_loss: 0.06960556 val_loss: 0.06737796\n",
      "Step = 56 train_loss: 0.06959307 val_loss: 0.06732847\n",
      "Step = 57 train_loss: 0.069624014 val_loss: 0.06728898\n",
      "Step = 58 train_loss: 0.069680706 val_loss: 0.06723695\n",
      "Step = 59 train_loss: 0.06983291 val_loss: 0.06722543\n",
      "Step = 60 train_loss: 0.06893317 val_loss: 0.06719338\n",
      "Step = 61 train_loss: 0.06973357 val_loss: 0.06710481\n",
      "Step = 62 train_loss: 0.069085665 val_loss: 0.067084074\n",
      "Step = 63 train_loss: 0.06936516 val_loss: 0.06705679\n",
      "Step = 64 train_loss: 0.06946798 val_loss: 0.06698496\n",
      "Step = 65 train_loss: 0.06864008 val_loss: 0.06693564\n",
      "Step = 66 train_loss: 0.06913671 val_loss: 0.06690981\n",
      "Step = 67 train_loss: 0.06919825 val_loss: 0.06687418\n",
      "Step = 68 train_loss: 0.068657234 val_loss: 0.06683877\n",
      "Step = 69 train_loss: 0.06937483 val_loss: 0.066780314\n",
      "Step = 70 train_loss: 0.068681195 val_loss: 0.06672513\n",
      "Step = 71 train_loss: 0.068902045 val_loss: 0.06667664\n",
      "Step = 72 train_loss: 0.06886407 val_loss: 0.06660844\n",
      "Step = 73 train_loss: 0.06874706 val_loss: 0.06655176\n",
      "Step = 74 train_loss: 0.068832666 val_loss: 0.06654552\n",
      "Step = 75 train_loss: 0.06911458 val_loss: 0.06654158\n",
      "Step = 76 train_loss: 0.068693 val_loss: 0.06642881\n",
      "Step = 77 train_loss: 0.06820196 val_loss: 0.066431314\n",
      "Step = 78 train_loss: 0.06817231 val_loss: 0.066403456\n",
      "Step = 79 train_loss: 0.068200745 val_loss: 0.06639074\n",
      "Step = 80 train_loss: 0.06842201 val_loss: 0.06633593\n",
      "Step = 81 train_loss: 0.06843687 val_loss: 0.06620836\n",
      "Step = 82 train_loss: 0.068243936 val_loss: 0.06624273\n",
      "Step = 83 train_loss: 0.06841033 val_loss: 0.066146635\n",
      "Step = 84 train_loss: 0.067761675 val_loss: 0.06625471\n",
      "Step = 85 train_loss: 0.068825305 val_loss: 0.066138685\n",
      "Step = 86 train_loss: 0.068643 val_loss: 0.065989606\n",
      "Step = 87 train_loss: 0.06832704 val_loss: 0.065967105\n",
      "Step = 88 train_loss: 0.06796996 val_loss: 0.06598699\n",
      "Step = 89 train_loss: 0.06808787 val_loss: 0.06591769\n",
      "Step = 90 train_loss: 0.06755403 val_loss: 0.06586007\n",
      "Step = 91 train_loss: 0.06847327 val_loss: 0.06592447\n",
      "Step = 92 train_loss: 0.067686014 val_loss: 0.065797105\n",
      "Step = 93 train_loss: 0.06802629 val_loss: 0.06578386\n",
      "Step = 94 train_loss: 0.06837604 val_loss: 0.06575438\n",
      "Step = 95 train_loss: 0.06747058 val_loss: 0.06574533\n",
      "Step = 96 train_loss: 0.06754103 val_loss: 0.06559135\n",
      "Step = 97 train_loss: 0.06810233 val_loss: 0.06564601\n",
      "Step = 98 train_loss: 0.06727356 val_loss: 0.06555058\n",
      "Step = 99 train_loss: 0.06740204 val_loss: 0.06550455\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "'''Data loader for Pytorch'''\n",
    "input_train = torch.FloatTensor(train_Qd)\n",
    "input_train = torch.unsqueeze(input_train, 1)\n",
    "train_labels = torch.FloatTensor(train_cycle_life)\n",
    "\n",
    "input_val = torch.FloatTensor(train_Qds)\n",
    "input_val = torch.unsqueeze(input_val, 1)\n",
    "val_labels = torch.FloatTensor(train_cycle_lifes)\n",
    "\n",
    "input_test_a = torch.FloatTensor(test_Qd_a)\n",
    "input_test_a = torch.unsqueeze(input_test_a, 1)\n",
    "test_labels_a = torch.FloatTensor(test_cycle_life_a)\n",
    "\n",
    "input_test_b = torch.FloatTensor(test_Qd_b)\n",
    "input_test_b = torch.unsqueeze(input_test_b, 1)\n",
    "test_labels_b = torch.FloatTensor(test_cycle_life_b)\n",
    "\n",
    "\n",
    "\n",
    "seed = 17\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "np.random.seed(seed)  # Numpy module.\n",
    "random.seed(seed)  # Python random module.\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(seed)    # reproducible    \n",
    "\n",
    "\n",
    "net = Net()     # define the network\n",
    "print(net)      # net architecture\n",
    "# summary(net,(1,100,1000))\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "loss_func = torch.nn.MSELoss() \n",
    "\n",
    "val_losses=[]\n",
    "\n",
    "# 用于保存模型的最大数量\n",
    "max_models_to_keep = 10\n",
    "saved_models = []\n",
    "\n",
    "for t in range(100):\n",
    "    net.train()\n",
    "    train_prediction = net(input_train)\n",
    "    train_loss = loss_func(train_prediction, train_labels)\n",
    "   \n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 保存模型\n",
    "    model_path = 'Target_model/net_parameters'+str(t)+'.pkl'\n",
    "    torch.save({\n",
    "        'epoch': t,\n",
    "        'model_state_dict': net.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()}, model_path)\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        val_prediction = net(input_val)\n",
    "        val_loss = loss_func(val_prediction, val_labels)\n",
    "    print('Step = %d' % t, 'train_loss:', train_loss.data.numpy(), 'val_loss:', val_loss.data.numpy())\n",
    "    val_losses.append(val_loss.item())\n",
    "\n",
    "    # 添加当前模型及其验证损失\n",
    "    saved_models.append((val_loss.item(), model_path))\n",
    "\n",
    "    # 保持模型数量不超过max_models_to_keep\n",
    "    if len(saved_models) > max_models_to_keep:\n",
    "        # 找到验证损失最大的一组模型并删除\n",
    "        saved_models.sort(key=lambda x: x[0])  # 排序，根据损失\n",
    "        os.remove(saved_models.pop()[1])  # 删除损失最大的模型\n",
    "\n",
    "# 'saved_models' 中现在只包含验证损失最小的前十个模型\n",
    "'''选择损失最小的模型'''\n",
    "best_index = val_losses.index(np.min(val_losses))\n",
    "print(best_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fisher Man\\AppData\\Local\\Temp\\ipykernel_29608\\399239800.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  a = model.load_state_dict(torch.load('Best_target_model/net_parameters.pkl')['model_state_dict'])\n",
      "C:\\Users\\Fisher Man\\AppData\\Local\\Temp\\ipykernel_29608\\399239800.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  optimizer.load_state_dict(torch.load('Best_target_model/net_parameters.pkl')['optimizer_state_dict'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''复制验证损失最小的模型到最佳模型文件夹'''\n",
    "if 1:\n",
    "    shutil.copyfile('Target_model/net_parameters'+str(best_index)+'.pkl', 'Best_target_model/net_parameters.pkl')\n",
    "\n",
    "\n",
    "'''重新加载最佳模型''' \n",
    "model = Net()\n",
    "a = model.load_state_dict(torch.load('Best_target_model/net_parameters.pkl')['model_state_dict'])\n",
    "optimizer.load_state_dict(torch.load('Best_target_model/net_parameters.pkl')['optimizer_state_dict'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpe_train: 0.999792\n",
      "mpe_val: 0.9918439\n",
      "mpe_a: 1.0668446740645487\n",
      "mpe_b: 0.2779595717397302\n",
      "rmse_train: 581.93823\n",
      "rmse_val: 571.55054\n",
      "rmse_a: 585.6197273967801\n",
      "rmse_b: 311.3103756703268\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "'''Prediction using the best model'''\n",
    "predict_labels_a=[]\n",
    "predict_labels_b=[]\n",
    "predict_labels_train=[]\n",
    "predict_labels_val = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predict_labels_a.append(model(input_test_a).data.numpy())\n",
    "    predict_labels_b.append(model(input_test_b).data.numpy())\n",
    "    \n",
    "    predict_labels_train.append(model(input_train).data.numpy())   \n",
    "    predict_labels_val.append(model(input_val).data.numpy())      \n",
    "\n",
    "\n",
    "actual_label_arr_train=np.round(np.asarray(train_labels*max_label).reshape(-1,1))  \n",
    "predict_label_arr_train=np.round(np.asarray(predict_labels_train).reshape(-1,1)*max_label)\n",
    "\n",
    "\n",
    "actual_label_arr_val=np.round(np.asarray(val_labels*max_label).reshape(-1,1))   \n",
    "predict_label_arr_val=np.round(np.asarray(predict_labels_val).reshape(-1,1)*max_label)\n",
    "\n",
    "\n",
    "actual_label_arr_a=np.round(np.asarray(test_cycle_life_a*max_label).reshape(-1,1))   \n",
    "predict_label_arr_a=np.round(np.asarray(predict_labels_a).reshape(-1,1)*max_label)\n",
    "\n",
    "\n",
    "actual_label_arr_b=np.round(np.asarray(test_cycle_life_b * max_label).reshape(-1,1))   \n",
    "predict_label_arr_b=np.round(np.asarray(predict_labels_b).reshape(-1,1)*max_label)\n",
    "\n",
    "\n",
    "'''Plot the predicted cycle lives'''\n",
    "plt.scatter(actual_label_arr_train, predict_label_arr_train,s=50,c='k')\n",
    "plt.scatter(actual_label_arr_val, predict_label_arr_val,s=50,c='b')\n",
    "plt.scatter(actual_label_arr_a, predict_label_arr_a,s=50,c='r')\n",
    "plt.scatter(actual_label_arr_b, predict_label_arr_b,s=50,c='g')\n",
    "plt.plot([100,2500],[100,2500])\n",
    "\n",
    "\n",
    "'''Evaluation metrics'''\n",
    "mpe_a=np.mean(np.abs(predict_label_arr_a-actual_label_arr_a)/actual_label_arr_a)\n",
    "mpe_b=np.mean(np.abs(predict_label_arr_b-actual_label_arr_b)/actual_label_arr_b)\n",
    "mpe_train = np.mean(np.abs(predict_label_arr_train-actual_label_arr_train)/actual_label_arr_train)\n",
    "mpe_val = np.mean(np.abs(predict_label_arr_val-actual_label_arr_val)/actual_label_arr_val)\n",
    "\n",
    "\n",
    "rmse_a=np.sqrt(np.mean((predict_label_arr_a-actual_label_arr_a)**2))\n",
    "rmse_b=np.sqrt(np.mean((predict_label_arr_b-actual_label_arr_b)**2))\n",
    "rmse_train=np.sqrt(np.mean((predict_label_arr_train-actual_label_arr_train)**2))\n",
    "rmse_val=np.sqrt(np.mean((predict_label_arr_val-actual_label_arr_val)**2))\n",
    "\n",
    "\n",
    "print ('mpe_train:',mpe_train)\n",
    "print ('mpe_val:',mpe_val)\n",
    "print ('mpe_a:',mpe_a)\n",
    "print ('mpe_b:',mpe_b)\n",
    "\n",
    "print ('rmse_train:', rmse_train)\n",
    "print ('rmse_val:', rmse_val)\n",
    "print ('rmse_a:', rmse_a)\n",
    "print ('rmse_b:', rmse_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_train: -1.334923505783081\n",
      "r2_val: -2.1382460594177246\n",
      "r2_a: -1.247219262209173\n",
      "r2_b: -0.19222578991129535\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_a = r2_score(actual_label_arr_a, predict_label_arr_a)\n",
    "r2_b = r2_score(actual_label_arr_b, predict_label_arr_b)\n",
    "r2_train = r2_score(actual_label_arr_train, predict_label_arr_train)\n",
    "r2_val = r2_score(actual_label_arr_val, predict_label_arr_val)\n",
    "\n",
    "print('r2_train:', r2_train)\n",
    "print('r2_val:', r2_val)\n",
    "print('r2_a:', r2_a)\n",
    "print('r2_b:', r2_b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
